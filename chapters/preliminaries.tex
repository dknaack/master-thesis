\chapter{Preliminaries}
\label{ch:preliminaries}

This chapter introduces key concepts needed throughout this thesis.
We begin with the most important topic first,
which is the Euclidean algorithm.
It serves as the basis for continued fractions and its generalization.
We proceed with a brief introduction to lattice theory.
Finally, the chapter ends with the basics of algebraic number theory,
which is needed for the second part of Hermite's problem.

% ==============================================================================
\section{The Euclidean Algorithm}
% ==============================================================================

The input to the algorithm is a pair of integers $(a, b)$ with $a > b$ and the
goal is to find the greatest common divisor between the two inputs.
The algorithm works in two steps.
The first step is to calculate the remainder when $a$ is divided by $b$.
We find an integer $q$ for the quotient and a remainder $r < b$ such that
\[
  a = q b + r.
\]
In the next step, $a$ is exchanged with $b$ and $b$ with $r$.
The algorithm continues with these two steps until the remainder $r$ equals zero.

\begin{example}
  Let $a = 252$ and $b = 105$.
  The Euclidean algorithm proceeds as follows:
  \begin{alignat*}{2}
    252 & = 2 · 105 + 42 \\
    105 & = 2 · 42 + 21 \\
    42 & = 2 · 21 + 0.
  \end{alignat*}
  Thus, the greatest common divisor of $252$ and $105$ is $21$.
\end{example}

\begin{lemma}
  If $a = qb + r$, then $\gcd(a, b) = \gcd(b, r)$.
\end{lemma}

\begin{proof}
  Suppose $d = \gcd(b, r)$, then $b = b'd$ and $r = r'd$ for some integers $b'$ and $r'$.
  But then $d$ must also divide $a$, since $a = qb + r = d(qb' + r')$.
  Thus, $d ≤ \gcd(a, b)$.
  Next, suppose that $d = \gcd(a, b)$.
  Because $d$ divides $a = qb + r$ and $b$,
  it must also divide $r$.
  Hence, $d ≤ \gcd(b, r)$.
  Combining both inequalities, we get $\gcd(a, b) = \gcd(b, r)$.
\end{proof}

Since $r < b$, the input decreases by at least $1$ after each iteration
and the Euclidean algorithm terminates at some point.
Therefore, it correctly calculates the greatest common divisor between the two
inputs $a$ and $b$.
In summary, the algorithm uses the following steps:
\begin{itemize}
  \item \textbf{Modulo}: $b' ← a \bmod b$.
  \item \textbf{Exchange}: $(a, b) ← (b', a)$.
  \item \textbf{Termination}: $b = 0$
\end{itemize}

The Euclidean algorithm not only works on integers,
but can be extended to any ring with a division with remainder operation.
Recall that a ring is a set $R$ equipped with two operations -- addition and
multiplication -- that behaves like the integers:
it forms an abelian group under addition and is closed under multiplication,
which is associative and distributes over addition.
A ring need not have multiplicative inverses or a multiplicative identity.
In this thesis, all rings will contain $1$ and be commutative unless stated
otherwise.

\begin{definition}
  An \emph{integral domain} is a ring $R$ in which $1 ≠ 0$ and for every $a, b ∈ R$,
  \[
    ab = 0 \implies a = 0 \text{ or } b = 0.
  \]
\end{definition}

An integral domain is a ring without zero divisors.
The Euclidean algorithm can be extended to any integral domain,
which defines an additional division with remainder operation.
Such a ring is called an Euclidean domain.

\begin{definition}
  A \emph{Euclidean domain} $(R, f)$ is an integral domain $R$ with a function $f$,
  which maps any nonzero element of $R$ to a nonnegative integer,
  such that for every two elements $a$ and $b$ of $R$, there exist elements $q$ and $r$ of $R$ with
  \[
    a = qb + r \quad \text{ and } \quad r = 0 \text{ or } f(r) < f(b).
  \]
  The element $q$ is called the \emph{quotient} and $r$ is called the \emph{remainder}.
  The function $f$ is called a \emph{Euclidean function}.
\end{definition}

\begin{example}
  \label{ex:real-divmod}
  Consider the real numbers with the Euclidean function $f(r) = r$.
  One possible division just uses the quotient $q = ab^{-1}$.
  However,
  another possible division operation would be
  \[
    a = \underbrace{\floor{\frac{a}{b}}}_q b + \underbrace{\left\{ \frac{a}{b} \right\} b}_r
  \]
\end{example}

\begin{example}
  Consider the ring $ℚ[X]$ of polynomials with rational coefficients.
  For any two polynomials $f(X), g(X) ∈ ℚ[X]$,
  we can find polynomials $q(X), r(X) ∈ ℚ[X]$
  using polynomial division such that
  \[
    f(X) = q(X) g(X) + r(X)
    \quad
    \text{ and }
    \quad
    \deg(r) ≤ \deg(f).
  \]
  In this case, $\deg(f)$ is the Euclidean function and $q(X), r(X)$ are
  the quotient and remainder, respectively.
\end{example}

% ==============================================================================
\section{Lattices}
% ==============================================================================

This section is heavily based on the lecture notes by Rothvoss
\cite{Rothvoss23} and the book by Micciancio and Goldwasser~\cite{Micciancio02}.
We begin with the introduction of lattices.

One of the fundamental structures in linear algebra is the vector space.
Given a set of vectors $A = \{A_1, …, A_n\} ∈ ℝ^d$, the span of $A$ is the set
of all linear combinations of the basis vectors $A_i$.
A lattice is similarly defined over a set of vectors $A$, but instead of linear
combinations of vectors, a lattice consists of only integral linear
combinations.

% TODO: Should we allow real vectors?
\begin{definition}
  Let $A$ be an integer matrix with column vectors $A_1, \dots, A_n ∈ ℤ^d$.
  The \emph{lattice} generated by $A$ is defined as
  \[
    \mathcal{L}(A) = A ℤ^d
    = \left\{\, z_1 A_1 + \dots + z_n A_n \mid z_1, \dots, z_n \in ℤ \,\right\}.
  \]
  The \emph{rank} of $\mathcal{L}(A)$ is defined as the rank of the matrix $A$.
  The \emph{dimension} of the lattice is $d$.
  If $\mathrm{rank}(A) = d$,
  then $\mathcal{L}(A)$ is called a \emph{full-rank lattice} in $ℝ^d$,
  and the columns of $A$ form a \emph{basis} of the lattice.
\end{definition}

Different sets of column vectors can generate the same lattice.
That is, a lattice $L$ can have multiple different bases.
If two matrices $B, B' \in \mathbb{Z}^{d \times d}$ generate the same lattice,
then they must be related by a matrix $U \in \mathbb{Z}^{d \times d}$
such that
\[
  B' = BU.
\]
To ensure that $B$ and $B'$ generate exactly the same set of integer linear combinations,
the matrix $U$ must preserve volume and invertibility over $ℤ$.
This leads to the following definition.

\begin{definition}
  A matrix $U ∈ ℤ^{n×n}$ is \emph{unimodular} if $\det(U) = ±1$.
\end{definition}

\begin{lemma}
  If $U$ is unimodular, then $U^{-1}$ is unimodular.
\end{lemma}

\begin{proof}
  We begin by showing that $U^{-1}$ consists of integer entries.
  Let $U^{(ij)}$ denote the matrix $U$ where the $i$-th column is replaced by the $j$-th unit vector $e_j$.
  Then, $\det(U^{(ij)}) ∈ ℤ$, and by Cramer's rule,
  \[
    U_{ij}^{-1} = \frac{\det(U^{(ij)})}{\det(U)}
  \]
  For the determinant, we have $\det(U^{-1}) = (\det(U))^{-1} = ±1$.
  Thus, the inverse $U^{-1}$ is unimodular.
\end{proof}

\begin{lemma}
  \label{lem:unimodular}
  Let $B$ and $B'$ be two bases.
  The lattices $\mathcal L(B)$ and $\mathcal L(B')$ are the same if and only if
  there exists a unimodular matrix $U ∈ ℤ^{n×n}$ such that $B' = BU$.
\end{lemma}

\begin{proof}
  Suppose $B' = BU$ for some unimodular matrix $U ∈ ℤ^{n×n}$.
  The function $f \colon ℤ^n → ℤ^n, f(x) = Ux$ is a bijection.
  Thus, any vector $y ∈ ℤ^n$ has a corresponding vector $x ∈ ℤ^n$ with $y = Ux$.
  Hence,
  \[
    \mathcal L(B)  = \{\, B λ \mid λ ∈ ℤ^n \,\} = \{\, B' U λ \mid λ ∈ ℤ^n \,\} = \mathcal L(B').
  \]

  Next, suppose $\mathcal L(B) = \mathcal L(B')$.
  Then, any vector in $B$ can be represented in a integral combination of the
  vectors of $B'$ and vice-versa.
  These coefficients can be combined into matrices $U, V ∈ ℤ^{n×n}$ such that $B' = BU$ and $B = B'V$.
  Thus, the determinant of $B$ is
  \[
    \det(B) = \det(BUV) = \det(B) \det(U) \det(V).
  \]
  Since $U$ and $V$ are both integer matrices,
  they must have determinant $±1$.
\end{proof}

\begin{figure}[tbp]
  \centering
  \includegraphics{build/lattice.pdf}
  \caption{
    A two-dimensional lattice $\mathcal L(B)$ with the basis vectors $B_1 = (2, 1)$
    and $B_2 = (1, 3)$.
    The fundamental parallelepiped $Π(B)$ is colored in {\color{cyan}cyan}.
  }
\end{figure}

While different bases may generate the same lattice, the geometric region the
basis spans still captures the same volume and structure.
To study this structure more concretely, we consider the region formed by all
linear combinations of the basis vectors with coefficients in the unit
interval.
This region is a geometric representation of the “unit cell” of the lattice.

\begin{definition}
  The \emph{fundamental parallelepiped} of a lattice $\mathcal{L}(B)$ with a basis $B ∈ ℤ^{d×d}$ is defined as
  \[
    Π(B) = \left\{\, B₁ x₁ + \dots + B_d x_d \mid x_1, \dots, x_d ∈ [0, 1) \,\right\}.
  \]
  The \emph{volume} of this parallelepiped is given by
  \[
    \mathrm{vol}(Π(B)) = |\det(B)|.
  \]
\end{definition}

An important property of the fundamental parallelepiped is that
for $B$ any square integer matrix, both the volume and the number of integer points
inside the parallelepiped $Π(B)$ is entirely determined by $\mathrm{det}(B)$.
Specifically,
\[
  \mathrm{vol}(Π(B)) = |Π(B) ∩ ℤ^n| = |\det(B)|.
\]

% ==============================================================================
\section{Algebraic Numbers}
% ==============================================================================

This section draws on standard results from algebraic number theory, as presented in the book by Dummit \cite{Dummit04}.
For a ring $R$,
the set $R[t]$ denotes all polynomial expressions in $t$,
i.e. expressions of the form $a₀ + a₁ t + ⋯ + aₙ t^n$ with $a₀, …, aₙ ∈ R$.
For a given field $K ⊆ L$ and an subset $S ⊆ L$,
the set $K(S)$ denotes the smallest field containing $K$ and $S$.
If $S = \{α₁, …, α_n\} ⊆ L$, then we simplify the
expression $ℚ(\{α₁, …, αₙ\})$ to $ℚ(α₁, …, αₙ)$.
In this thesis, we consider fields $ℚ(α)$ where the element $α$ is an algebraic number.

\begin{definition}
  A complex number $α$ is said to be \emph{algebraic} if its the root of some polynomial
  with integer coefficients.
  If $α$ is not algebraic, then it is said to be \emph{transcendental}.
\end{definition}

The set of algebraic numbers includes many familiar constants, such as $\sqrt{2}$ or $\frac{1}{2}$,
and plays a central role in number theory.
As it stands, the definition currently only states that it must be a root of some polynomial.
However, we can identify each algebraic number by one unique monic polynomial,
i.e. a polynomial where its leading coefficient is $1$.

\begin{lemma}
  If $α$ is algebraic, then there exists a unique monic polynomial $m_α(X) ∈ ℚ[X]$
  of smallest degree with $α$ as a root.
\end{lemma}

\begin{proof}
  For a contradiction, suppose there exists another monic polynomial $g(X) ≠
  m_α(X)$ with $\deg(g) = \deg(m_α)$.
  Then we can find polynomials $q(X), r(X) ∈ ℚ[X]$ such that
  \[
    g(X) = q(X) m_α(X) + r(X), \quad \text{ with } r(X) = 0 \text{ or } \deg(r) < \deg(m_α).
  \]
  If $r(X) = 0$, then $q(X)$ has to have degree $0$.
  However, then either $q(X) = 1$, which means $m_α(X) = g(X)$ or one of
  the two polynomials is not monic.
  Both options would contradict our assumptions.

  Therefore, we must have $r(X) ≠ 0$.
  Because $m_α(α) = 0$ and $g(α) = 0$, we must also have $r(α) = 0$.
  However, then $r(X)$ would be a polynomial with smaller degree than $f(X)$
  and it would have $α$ as a root, which is a contradiction.
  Thus, $m_α$ is the unique monic polynomial for $α$.
\end{proof}

Every algebraic number is associated with a unique monic polynomial over the rational numbers
of minimal degree, known as its \emph{minimal polynomial}.
Since $m_α(α) = 0$,
we can think of $ℚ(α)$ as the set of rational polynomials in $α$ modulo $m_α$.
Therefore, any polynomial expression in $α$ with degree higher than $\deg(m_α)$
can be replaced by an expression with lower degree.
Hence, every element in $ℚ(α)$ can be expressed as
\[
  a₀ + a₁ α + ⋯ + a_{n-1} α^{n-1},
\]
where $n$ is the degree of the minimal polynomial $m_α$
and the coefficients $a₀, a₁, …, a_{n-1}$ are rational numbers.
Thus,
we can consider the field $ℚ(α)$ as a vector space over $ℚ$
with the set $\{1, α, …, α^{n-1}\}$ as a basis.
Then,
any element in $ℚ(α)$ can be expressed as a linear combination of this basis.
The basis is also known as the \emph{power basis}.

\begin{definition}
  The \emph{degree} $[K : ℚ]$ of a field extension $K/ℚ$ is defined as the
  dimension of $K$ as a vector space over $ℚ$.
  If the dimension is finite, then $K$ is called a \emph{number field}.
\end{definition}

\begin{example}
  \hfill
  \begin{enumerate}
    \item The rational numbers form a number field and they have degree $1$.
    \item The quadratic field $ℚ(\sqrt{2})$ is a number field.
      Any element in $ ℚ(\sqrt{2})$ can be written as $a + b \sqrt{2}$ with $a,b ∈ ℚ$
      and it is therefore a number field with degree $[ℚ(\sqrt{2}) : ℚ] = 2$.
    \item The field $ℚ(\sqrt[3]{2})$ is a number field.
      It contains all elements of the form $a + b \sqrt[3]{2} + c \sqrt[3]{2^2}$ with $a,b,c ∈ ℚ$.
      Therefore, $1, \sqrt[3]{{2}}, \sqrt[3]{4}$ forms a basis for the vector space over $ℚ$
      and the field $ℚ(\sqrt[3]{2})$ has degree $[ℚ(\sqrt[3]{2}) : ℚ] = 3$.
  \end{enumerate}
\end{example}

Multiplication by a fixed element $α ∈ K$ of a number field $K$ can be viewed
as a linear transformation on its corresponding vector space.
For an element $β ∈ ℚ(α)$ we begin by evaluating the
multiplication of $β$ with one element $α^k$ of the power basis.
The resulting element can be represented as a linear combination again,
i.e.
\[
  β · α^k = \sum_{j=0}^{n-1} m_{kj} α^j
\]
for some coefficients $m_{jk} ∈ ℚ$.
This represents one row in the multiplication matrix.
Combining each row into one matrix gives us the final multiplication matrix.

\begin{example}
  \label{ex:mult-matrix}
  Consider a quadratic field $K = ℚ(\sqrt{d})$ for some non-perfect square $d$.
  Each element $α ∈ ℚ(\sqrt{d})$ can be represented as $a + b \sqrt{d}$ for some $a, b ∈ ℚ$.
  The multiplication matrix of $α$ is
  \[
    M_α =
    \begin{pmatrix}
      a & bd \\
      b & a \\
    \end{pmatrix},
  \]
  since
  $(a + b \sqrt{d}) · 1 = a + b \sqrt{d}$ and
  $(a + b \sqrt{d}) · \sqrt{d} = bd + a \sqrt{d}$,
  each of which represents one column in the multiplication matrix.
\end{example}

\begin{lemma}
  Let $α$ be algebraic and let $α₁, …, α_n$ be its conjugates.
  Then, any multiplication matrix of an element $β ∈ ℚ(α)$ has $(α_i^{n-1}, …, α_i, 1)$ as one of its eigenvectors.
\end{lemma}

\begin{proof}
  This follows from the definition.
  \[
    (M_β α)_k = \sum_{j=0}^{n-1} m_{jk} α^j = β α^k.
  \]
\end{proof}

\begin{definition}
  Let $K$ be a number field.
  The \emph{field norm} $N_{K/ℚ}(α)$ of an element $α$ of $K$ is defined as the
  determinant of its multiplication matrix $M_α$.
\end{definition}

\begin{example}
  By Example~\ref{ex:mult-matrix},
  the norm of an element $a + b \sqrt{d} ∈ ℚ(\sqrt{d})$ is
  \[
    N_{K/ℚ}(a + b \sqrt{d}) = a^2 - d b^2.
  \]
\end{example}

While the number field $K = ℚ(α)$ forms an $n$-dimensional vector space using
the power basis, the ring $ℤ[α]$ forms an $n$-dimensional lattice under the same basis.
If $ε ∈ ℤ[α]$ with $N_{K/ℚ}(ε) = 1$, then $ε^{-1} ∈ ℤ[α]$,
since its multiplication matrix is unimodular.
Thus, $ε$ is a unit in the ring $ℤ[α]$.
If we can find a nontrivial unit $ε ≠ 1$,
then we have a nontrivial transformation of the lattice $ℤ[α]$.
Finding such a nontrivial unit requires Dirichlet's unit theorem,
for which we first need the notion of integer rings and orders.

The \emph{integer ring} $\mathcal O_K$ of a number field $K$
contains all elements $x ∈ \mathcal O_K$, which are algebraic integers,
i.e. their minimal polynomial is a monic polynomial with integer coefficients.
In general, algebraic numbers which are the root of a monic polynomial with integer coefficients
are known as \emph{algebraic integers}.
The ring of integers is not necessarily equal to $ℤ[α]$.
For example, in quadratic fields $ℚ(\sqrt{d})$
the ring of integers is equal to $ℤ\left[\frac{1+\sqrt{d}}{2}\right]$ if $d ≡ 1\ (\mathrm{mod}\ 4)$.

\begin{definition}
  Let $K$ be a number field and $\mathcal O_K$ its ring of integers.
  An \emph{order} $\mathcal O$ is a subring of $\mathcal O_K$,
  which is a finitely generated $ℤ$-module,
  i.e. every element $x ∈ \mathcal O$ can be represented as an integral
  combination of a fixed, finite set of elements $x₁, x₂, …, xₙ ∈ \mathcal O$.
\end{definition}

\begin{theorem}[Dirichlet's Unit Theorem]
  \label{thm:dirichlet-unit}
  Let $K$ be a number field with $r₁$ real embeddings and $r₂$ complex embeddings.
  The unit group of an order of $K$ is finitely generated by $r₁ + r₂ - 1$
  independent generators of infinite order.
\end{theorem}

\begin{corollary}
  \label{cor:nontrivial-unit}
  There exists a nontrivial unit in $ℤ[α]$,
  unless $α$ is an imaginary quadratic irrational number.
\end{corollary}

\begin{proof}
  Theorem~\ref{thm:dirichlet-unit} only applies to orders,
  but the ring $ℤ[α]$ is not an order in general.
  If the minimal polynomial of $α$ contains rational coefficients,
  then $ℤ[α]$ cannot be an order, since $α ∈ ℤ[α]$.
  However, we can find a subring of $ℤ[α]$ which is an order.
  Suppose $m_α(x) = x^n + a_{n-1} x^{n-1} + ⋯ + a_1 x + a_0$ is the minimal polynomial of $α$.
  Let $q$ be the common denominator of its coefficients.
  Then, $q α$ is a root of the monic polynomial
  \begin{align*}
    m_{qα}(x) & = x^n + a_{n-1} q x^{n-1} + ⋯ + a_1 q^{n-1} + a_0 q^n,
  \intertext{since}
    m_{qα}(qα)
    & = (qα)^n + a_{n-1} q (qα)^{n-1} + ⋯ + a_1 q^{n-1} (q α) + a_0 q^n \\
    & = q^n \underbrace{(α^n + a_{n-1} α^{n-1} + ⋯ + a_1 α + a_0)}_{= 0}
  \end{align*}
  Thus, $ℤ[qα]$ is an order and Dirichlet's unit theorem applies.
  If $α$ is not an imaginary quadratic irrational, then there exist at least $r₁ + r₂ - 1 > 0$
  generators for the unit group of $ℤ[qα]$.
  Therefore, there exists a nontrivial unit $ε ∈ ℤ[qα] ⊆ ℤ[α]$.
\end{proof}

The corollary tells us that there always exists a unit $ε ∈ ℚ(α)$ with integral
coefficients in the power basis $\{1, α, …, α^{n-1}\}$.
The multiplication matrix of $ε$ is therefore unimodular.
This multiplication matrix actually has the power basis as one of its eigenvectors.
The other eigenvectors are similarly the power basis of the conjugates of $α$,
that is any root $β$ of $m_α(x)$ defines an eigenvector $(1, β, …, β^{n-1})$.

\begin{theorem}
  \label{thm:unimodular-algebraic}
  Let $α$ be an algebraic number and let $α_1, …, α_n$ be its conjugates.
  There exists a unimodular matrix $U ≠ I$,
  which has $(1, α_i, …, α_i^{n-1})$ as eigenvectors.
\end{theorem}

\begin{proof}
  Corollary~\ref{cor:nontrivial-unit}
  already shows that a nontrivial unimodular matrix exists,
  which is a multiplication matrix $M_β = (m_{ij})$ of some unit $β ∈ ℤ[α]$.
  It remains to be shown that the conjugate vectors are eigenvectors of this matrix.
  Let $x = (1, α_i, …, α_i^{n-1})$ and let $y = M_β x$.
  Then,
  \[
    y_j = \sum_{k=0}^{n-1} m_{jk} α^k = β α^j.
  \]
  Thus, $M_β x = β x$ and $x$ is an eigenvector of the unimodular matrix $M_β$.
\end{proof}

\begin{example}
  \label{ex:sqrt2-unit}
  Consider the quadratic irrational $\sqrt{2}$
  and its conjugate $-\sqrt{2}$.
  One nontrivial unit in $ℚ(\sqrt{2})$ is $ε = 3 + 2\sqrt{2}$
  since it has norm $3^2 - 2 · 2^2 = 1$.
  It has the unimodular multiplication matrix
  \[
    U = \begin{pmatrix}
      3 & 2 \\
      4 & 3 \\
    \end{pmatrix}.
  \]
  Furthermore, it has $(1, \sqrt{2})^⊤$ and $(1, -\sqrt{2})^⊤$ as eigenvectors,
  since
  \begin{align*}
    \begin{pmatrix}
      3 & 2 \\
      4 & 3 \\
    \end{pmatrix}
    \begin{pmatrix}
      1 \\ \sqrt{2} \\
    \end{pmatrix}
    & =
    \begin{pmatrix}
      3 + 2\sqrt{2} \\
      4 + 3\sqrt{2} \\
    \end{pmatrix}
    =
    (3 + 2\sqrt{2})
    \begin{pmatrix}
      1 \\ \sqrt{2} \\
    \end{pmatrix}, \\
    \begin{pmatrix}
      3 & 2 \\
      4 & 3 \\
    \end{pmatrix}
    \begin{pmatrix}
      1 \\ -\sqrt{2} \\
    \end{pmatrix}
    & =
    \begin{pmatrix}
      3 - 2\sqrt{2} \\
      4 - 3\sqrt{2} \\
    \end{pmatrix}
    =
    (3 - 2\sqrt{2})
    \begin{pmatrix}
      1 \\ -\sqrt{2} \\
    \end{pmatrix}.
  \end{align*}
\end{example}
