\chapter{Periodic Representation of Higher Degree Irrationals}

We have already seen that continued fractions are periodic if and only if the
value is a quadratic irrational.
We constructed the continued fraction for a given number using the Euclidean
algorithm.
Naturally, we can extend this notion of continued fractions to higher
dimensions using the generalized Euclidean algorithm.
This leads to a concept of multi-dimensional continued fractions, which could
potentially lead to an answer of Hermite's question.

This chapter introduces the concept of MDCFs.
We begin by defining what they are and deriving many properties similar to
continued fractions.
Subsequently, we look at numbers represented by periodic MDCFs and whether they
must be algebraic numbers of degree $d+1$.
Finally, we discuss the geometry behind the multi-dimensional continued fractions.
The other direction -- Whether algebraic numbers of degree $d+1$ admit periodic
MDCFs -- will be discussed in the next chapter.

% ==============================================================================
\section{Multi-Dimensional Continued Fractions}
% ==============================================================================

To derive the continued fraction for a real number, we have used the Euclidean algorithm.
In particular, we looked at the ratio $a/b$ between the two inputs $a$ and $b$,
and we have used the integer part of that ratio as a coefficient in the
continued fraction.
Iterating the Euclidean algorithm then gave us a unique representation for
every real number.
The Euclidean algorithm can also be viewed as the generalized algorithm when $d = 1$.
In this case, the ratio $a/b$ represents the solution $x$ of the linear system $bx = a$.
So the integer part of the solution $x$ also represents a coefficient in the
continued fraction.
We can then use the pivot operation to iterate over this solution and gain the
rest of the coefficients.

The multi-dimensional continued fraction can now be easily derived from the
solution vector $x$ in higher dimensions.
Specifically, given a vector $x ∈ ℝ^d$, we take the integer part of each
element $\floor{x}$ as a coefficient of the multi-dimensional continued
fraction.
Then, we get the subsequent coefficients by iterating over this vector using
the pivot operation.
This gives us a top-down construction of MDCFs, but typically continued
fractions are defined in a bottom-up fashion.
For a bottom-up definition of the MDCFs, we simply reverse the pivot operation.
The inverse operation can be derived as follows:
Let $x ∈ ℝ^d$ and $a = \floor{x}$.
If $x' = \mathrm{pivot}_ℓ(x)$ for a given index $ℓ$, then
\[
  \begin{array}{lcrlcr}
    \displaystyle x_i' & = & \displaystyle \frac{x_i - a_i}{x_ℓ - a_ℓ}, &
    \displaystyle x_ℓ' & = & \displaystyle \frac{x_i - a_i}{x_ℓ - a_ℓ} \\[1em]
  \end{array}
\]
for all $i ≠ ℓ$.
For the inverse operation, we have to derive every element of $x$ from $x'$,
which can be done by the following equations:
\[
  \begin{array}{lcrlcr}
    \displaystyle x_i & = & a_i + \displaystyle \frac{x_i'}{x_ℓ'}, &
    \displaystyle x_ℓ & = & a_ℓ + \displaystyle \frac{1}{x_ℓ'}
  \end{array}
\]
This allows us to calculate the previous vector $x$ from the next vector $x'$,
if we know the integer vector $a$.
Let $\mathrm{pivot}_ℓ^{-1}$ denote this inverse function.
We have
\[
  \mathrm{pivot}_ℓ(x) = x' \iff \mathrm{pivot}_ℓ^{-1}(a, x') = x.
\]
This operation leads directly to a definition of MDCFs.

Although, we initially used integer vectors $a ∈ ℤ^d$ for the definition of the inverse operation,
we can also look at what happens when $a$ is not necessarily an integer vector.
For subsequent lemmas, we will need a definition of MDCFs which allows rational
or even real vectors as coefficients.

\begin{definition}
  Given a sequence of $d$-dimensional real vectors $\{rₙ\}_{n ≥ 0}$ and a sequence of
  indices $\{ℓₙ\}_{n ≥ 0}$, the \emph{multi-dimensional continued fraction} $[r₀; ℓ₁, r₁; …]$
  is defined as
  \[
    [r₀; ℓ₁, r₁; …] = \lim_{n → ∞} [r₀; ℓ₁, r₁; …; ℓₙ, rₙ],
  \]
  where the finite continued fractions $[r₀; ℓ₁, r₁; …; ℓₙ, rₙ]$ are defined as
  \[
    [r₀] = r₀, \qquad [r₀; ℓ₁, r₁; …; ℓₙ, rₙ] = \mathrm{pivot}_{ℓ₁}^{-1}\big(r₀, [r₁; ℓ₂, r₂; …; ℓₙ, rₙ]\big).
  \]
\end{definition}

The terminology from one-dimensional continued fractions naturally carry over to its
multi-dimensional counterpart.
Given an infinite MDCF representation~$[a₀; ℓ_1, a_1; …]$ of a vector $x ∈ ℝ^d$, we define the following:

\begin{itemize}
  \item The \emph{$k$-th convergent} of $x$ is the finite MDCF $[a₀; ℓ₁, a₁; …; ℓ_k, a_k]$.
  \item The \emph{$k$-th complete quotient} is the MDCF $[aₖ; a_{k+1}, …]$.
  \item The MDCF is \emph{eventually periodic} if there exists an index~$n₀ ≥ 0$
    and a period~$k ≥ 1$ such that $aₙ = a_{n+k}$ and $ℓₙ = ℓ_{n+k}$
    for every $n ≥ n₀$.
    The MDCF is \emph{purely periodic} if $n₀ = 0$.
\end{itemize}

\section{Periodic Multi-Dimensional Continued Fractions}

In this section I will show that if the MDCF of a vector $x ∈ ℝ^d$ is periodic,
then the elements of $x$ must be all algebraic numbers of degree $d+1$.
The proof requires two additional lemmas, which are multi-dimensional analogues
of Lemma~\ref{lem:nesting} and Lemma~\ref{lem:wallis}.
In the following, $aₙ$ will always denote a sequence of integers and $ℓₙ$ a
sequence of indices between $1$ and $d$.
We begin with a generalization of Lemma~\ref{lem:nesting}.

\begin{lemma}[Nesting]
  \label{lem:mdcf-nesting}
  Let $x ∈ ℝ^d$, then
  \[
    [a₀; ℓ₁, a₁; …; ℓₙ, aₙ; ℓ, x]
    = [a₀; ℓ₁, a₁; \cdots; ℓₙ, \mathrm{pivot}_{ℓ}^{-1}(aₙ, x)]
  \]
\end{lemma}

\begin{proof}
  If $n = 0$, then by definition,
  \[
    [a₀; ℓ, x] = \mathrm{pivot}_{ℓ}^{-1}(a₀, [x]) = \mathrm{pivot}_{ℓ}^{-1}(a₀, x) = [\mathrm{pivot}_{ℓ}^{-1}(a₀, x)].
  \]
  Suppose the lemma holds for any $n ≥ 0$, then
  \begin{align*}
    [a₀; ℓ₁, a₁; …; ℓₙ, aₙ; ℓ, x]
    & = \mathrm{pivot}_{ℓ₁}^{-1}(a₀, [a₁; …; ℓₙ, aₙ; ℓ, x]) \\
    & = \mathrm{pivot}_{ℓ₁}^{-1}(a₀, [a₁; …; ℓₙ, \mathrm{pivot}_{ℓ}^{-1}(aₙ, x)] \\
    & = [a₀; ℓ₁, a₁; …; ℓₙ, \mathrm{pivot}_{ℓ}^{-1}(aₙ, x)]. \qedhere
  \end{align*}
\end{proof}

% TODO: Explain how to derive the sequences
The second lemma is a generalization of Lemma~\vref{lem:wallis},
where we defined the convergents of a continued fraction~$pₙ/qₙ$
based on the previous two terms~$p_{n-1}/q_{n-1}$ and $p_{n-2}/q_{n-2}$.
For MDCFs, we can similarly derive a recursive formula to derive the values of
the convergent vector $(p₁/q, \dots, p_d/q)$ using the previous convergents.
Deriving the sequence is more involved than the one-dimensional case since
there is an additional index $ℓ$ at each step.

In total, we define four sequences:
A matrix sequence $P^{(n)}$, two vector sequences $Q^{(n)}$ and $p^{(n)}$ as well as a scalar sequence $q^{(n)}$.
Their are defined as follows:
\begin{align*}
  P_{ℓₙ}^{(n)} & = P^{(n-1)} a_n + p^{(n-1)}, & P_i^{(n)} & = P_i^{(n)}, & P^{(-1)}   & = I_d, \\
  Q_{ℓₙ}^{(n)} & = Q^{(n-1)} a_n + q^{(n-1)}, & Q_i^{(n)} & = Q_i^{(n)}, & Q^{(-1)}_j & = 0,   \\
  p^{(n)}      & = P_{ℓₙ}^{(n-1)},            &           &              & p^{(-1)}_j & = 0,   \\
  q^{(n)}      & = Q_{ℓₙ}^{(n-1)},            &           &              & q^{(-1)}   & = 1.
\end{align*}
where $i ≠ ℓ_n$.
What this sequence effectively does is reconstructing the lattice from an
initial solution vector $x ∈ ℝ^d$ and its coefficient vectors $a_n$.

\begin{lemma}[Wallis]
  \label{lem:mdcf-wallis}
  Let $x ∈ ℝ^d$, then
  \[
    [a₀; ℓ₁, a₁; …; ℓ_{n-1}, a_{n-1}; ℓ, x]
    = \frac{P x + p}{Q^T x + q}.
  \]
\end{lemma}

\begin{proof}
  If $n = 0$, then
  \[
    [x] = x = \frac{I_d x + 0}{0^T x + 1}.
  \]
  Suppose the lemma holds for $n ≥ 0$, then there exists a matrix $P$, vectors
  $Q, p$ and scalar $q$ such that
  \begin{align*}
    y & = [a₀; ℓ₁, a₁; …; ℓ_{n-1}, a_{n-1}; ℓ, x]                              \\
      & = [a₀; ℓ₁, a₁; …; ℓ_{n-1}, a_{n-1} + \mathrm{pivot}_ℓ(x)]              \\
      & = \frac{P (a + \mathrm{pivot}_ℓ(x)) + p}{Q^T (aₙ + \mathrm{pivot}_ℓ(x)) + q} \\
      & = \frac{x_ℓ}{x_ℓ} · \frac{P (a + \mathrm{pivot}_ℓ(x)) + p}{Q^T (aₙ + \mathrm{pivot}_ℓ(x)) + q}.
  \end{align*}
  The numerator has the following form:
  \begin{align*}
    x_ℓ (P (a + \mathrm{pivot}(x, ℓ)) + p)
    & = x_ℓ (P a + P_ℓ \frac{1}{x_ℓ} + \sum_{i ≠ ℓ} P_i \frac{x_i}{x_ℓ} + p) \\
    & = \underbrace{(P a + p)}_{P_ℓ'} x_ℓ + \sum_{i ≠ ℓ} \underbrace{P_i}_{P_i'} x_i + \underbrace{P_ℓ}_{p'} \\
    & = P' x + p'.
  \end{align*}
  Analogously, the denominator has the following form:
  \begin{align*}
    x_ℓ (Q^T (a + \mathrm{pivot}(x, ℓ)) + q)
    & = x_ℓ (Q^T a + Q_ℓ \frac{1}{x_ℓ} + \sum_{i ≠ ℓ} Q_i \frac{x_i}{x_ℓ} + q) \\
    & = \underbrace{(Q^T a + q)}_{Q_ℓ'} x_ℓ + \sum_{i ≠ ℓ} \underbrace{Q_i}_{Q_i'} x_i + \underbrace{Q_ℓ}_{q'} \\
    & = Q' x + q'.
  \end{align*}
  Hence,
  \[
    y = \frac{P(a + \mathrm{pivot}(x, ℓ)) + p}{Q(a + \mathrm{pivot}(x, ℓ)) + q} = \frac{P' x + p'}{Q'^T x + q'}. \qedhere
  \]
\end{proof}

With these two lemmas proven, we can now turn our attention to periodic MDCFs.

\begin{proposition}
  Given $r ∈ ℝ$, let $x = (r¹, r², …, r^d)$.
  If the MDCF representation of $x$ is purely periodic, then $[ℚ(r) : ℚ] ≤ d + 1$.
\end{proposition}

\begin{proof}
  Suppose the algorithm is purely periodic on input $x$ with period $ℓ$.
  Let $y$ be the $ℓ$-th complete quotient of $x$, then $x = y$.
  By Lemma~\ref{lem:mdcf-wallis},
  \[
    rⁱ = \frac{\sum_{j=1}^d P_{ij} rʲ + pᵢ}{\sum_{j=1}^d Qⱼ rʲ + qᵢ}, \text{ for every } i ≤ d.
  \]
  Multiplying both sides with the denominator results in the polynomial equation
  \[
    \sum_{j=1}^d (Q_j r^{i+j} - P_{ij} r^j) + r^i q_i - p_i = 0.
  \]
  For $i = 1$, the maximum degree of this polynomial is $d + 1$.
  Hence, $r$ is an algebraic number of degree $d+1$.
\end{proof}

% ==============================================================================
\section{The Geometry behind Multi-Dimensional Continued Fractions}
% ==============================================================================

The pivot operation is quite cumbersome to write.
We'll always need to differentiate the cases $i = ℓ$ and $i ≠ ℓ$.
Homogeneous coordinates allow us to simplify the whole pivot operation as a single matrix.

Instead of an $d$-dimensional vector space, we project each vector into a $(d+1)$-dimensional vector space.
Each vector $x = (x₁, …, x_d) ∈ ℝ^d$ is extended by a new coordinate $x₀ = 1$.
We denote this vector as $\hat x = [1, x₁, …, x_d]$.
Two such vectors $\hat x, \hat y$ are considered equivalent if they are collinear.
Stated differently, each vector $[x₀, x₁, …, x_d]$ represents a line in the direction $(x₀, x₁, …, x_d)$.

% TODO: Explain mapping from and back to the original vector space.
\begin{center}
  \begin{tikzpicture}
    \matrix[
      column sep=2cm,
      nodes={text width=3cm, align=center},
    ] {
      \node (L0) {$\mathbb{R}^d$}; &
      \node (R0) {$\mathbb{RP}^{d+1}$}; \\
      \node (L1) {$(x₁, …, x_d)$}; &
      \node (R1) {$[1, x₁, …, x_d]$}; \\
      \node (L2) {$(x₁/x₀, …, x_d/x₀)$}; &
      \node (R2) {$[x₀, x₁, …, x_d]$}; \\
    };

    \draw[->] (L1) -- node[above] {} (R1);
    \draw[<-] (L2) -- node[above] {} (R2);
  \end{tikzpicture}
\end{center}

For example, consider the vector $[1, x₁, x₂]$ with $0 ≤ x₁, x₂ < 1$.
A pivot operation with $ℓ = 1$ would result in the vector $[1, 1/x₁, x₂/x₁]$.
This vector is equivalent to $[x₁, 1, x₂]$.
Therefore, we can reformulate this operation as a coordinate swap of $x_ℓ$ with
the new coordinate $x₀$:
\[
  \begin{bmatrix}
    0 & 1 & 0 \\
    1 & 0 & 0 \\
    0 & 0 & 1 \\
  \end{bmatrix}
  ·
  \begin{bmatrix} 1 \\ x₁ \\ x₂ \\ \end{bmatrix}
  =
  \begin{bmatrix} x₁ \\ 1 \\ x₂ \\ \end{bmatrix}
  =
  \begin{bmatrix} 1 \\ 1/x₁ \\ x₂/x₂ \\ \end{bmatrix}.
\]
Similarly, subtracting the integer part of each value in $[1, x₁, x₂]$ is
equivalent to a series of skew operations:
\[
  \begin{bmatrix}
    1 & 0 & 0 \\
    -\floor{x₁} & 1 & 0 \\
    0 & 0 & 1 \\
  \end{bmatrix}
  ·
  \begin{bmatrix}
    1 & 0 & 0 \\
    0 & 1 & 0 \\
    -\floor{x₂} & 0 & 1 \\
  \end{bmatrix}
  ·
  \begin{bmatrix} 1 \\ x₁ \\ x₂ \\ \end{bmatrix}
  =
  \begin{bmatrix} 1 \\ x₁ - \floor{x₁} \\ x₂ - \floor{x₂} \\ \end{bmatrix}.
\]
Importantly, each of those matrices with
determinant $1$.
Therefore, the whole operation can be reversed by inverting the matrix.
This is the equivalent of the inverse pivot operation in homogeneous
coordinates.

We can also reformulate the MDCF as a series of matrix multiplications.
In the following $T(a)$ denotes the translation by a vector $a ∈ ℝ^d$
and the matrix $S(ℓ)$ denotes the swap of $x_\ell$ with $x_0$.
The MDCF can then be written as
\[
  [a₀] = \hat a₀, \qquad
  [a₀; ℓ₁, a₁; …; ℓₙ, aₙ] = T(a₀) · S(ℓ_1) · [a₁; ℓ_2, a_2; …; ℓ_n, a_n].
\]

This allows us to drastically simplify Lemma~\ref{lem:mdcf-wallis}.
Now, we only have a single matrix sequence $P_n$, defined as follows:
\begin{align*}
  P_n = P_{n-1} A_n, \qquad P_0 = I_{d+1}.
\end{align*}

\begin{lemma}
  \label{lem:mdcf-wallis'}
  Let $x ∈ ℝ^d$, then
  \[
    [a₀; ℓ₁, a₁; …; ℓ_{n-1}, a_{n-1}; ℓ, x] ≡ P_{n-1} \hat x
  \]
\end{lemma}

\begin{proof}
  For $n = 0$, this is clearly true.
  Suppose the lemma is true for $n ≥ 0$, then
  \begin{align*}
    [a₀; ℓ₁, a₁; …; ℓ_n, a_n; ℓ, x]
    & ≡ [a₀; ℓ₁, a₁; …; ℓ_n, a_n + \mathrm{pivot}_ℓ(x)] \\
    & ≡ P_{n-1}
    \begin{pmatrix}
      a_n + \mathrm{pivot}_ℓ(x) \\ 1
    \end{pmatrix} \\
    & ≡ P_{n-1} A_n \hat{x} \\
    & ≡ P_n \hat{x} \qedhere
  \end{align*}
\end{proof}

\begin{lemma}
  \label{lem:mdcf-purely-periodic}
  If there exists a purely periodic MDCF for $x ∈ ℝ^d$,
  then $x_i$ is an algebraic number of degree $≤ d+1$ for every $i ≤ d$.
\end{lemma}

% TODO: Should we use x ≡ y or [x] = [y]?
\begin{proof}
  If the MDCF is purely periodic, then by Lemma~\ref{lem:mdcf-wallis'} there exists an integer matrix $P$ such that
  \[
    \hat x ≡ P \hat x \iff λ₁ \hat x = λ₂ P \hat x \iff λ \hat x = P \hat x,
  \]
  for some $λ₁, λ₂ ∈ ℝ \setminus \{0\}$ and $λ = λ₁/λ₂$.
  Therefore, we are looking for an eigenvector $\hat x$ and an eigenvalue $λ$ of $P$.
  The characteristic polynomial $\det(P - λ I)$ can have a degree of at most $d+1$,
  therefore the eigenvalue $λ$ is an algebraic number of degree $d+1$.

  % TODO: Finish this proof
  For the eigenvector $\hat x$, we have to find a nontrivial solution to the
  homogeneous linear system
  \[
    (P - λ I) \hat x = 0.
  \]

  Finally, every $x_i = \hat x_i / \hat x₀$ must be an algebraic number of degree $≤ d+1$,
  because $x_i$ is a rational expression of two algebraic numbers of degree $≤ d+1$.
\end{proof}

\begin{theorem}
  If there exists a periodic MDCF for $x ∈ ℝ^d$,
  then $x_i$ is an algebraic number of degree $≤ d+1$ for every $i ≤ d$.
\end{theorem}

\begin{proof}
  Let $x^{(k)}$ be the complete quotients of $x$.
  Suppose there exists a period $ℓ$ such that $x_k = x_{k+ℓ}$.
  By Lemma~\ref{lem:mdcf-wallis'},
  \[
    \hat x = P^{(k)} \hat x^{(k)} = P^{(k+ℓ)} \hat x^{(k+ℓ)} = P^{(k+ℓ)} \hat x^{(k)}.
  \]
  The algebraic numbers in $\hat x_k$ must have degree $≤ d+1$.
  Since every element in $x$ is a linear rational expression of the form
  \[
    x_i = \frac{∑_{j=1}^d P_{ij}^{(k)} x_j^{(k)} + P_{i0}^{(k)}}{\sum_{j=1}^d P_{0j}^{(k)} x_j^{(k)} + P_{00}^{(k)}},
  \]
  where $x_j^{(k)}$ is an algebraic number of degree $≤ d+1$ and the elements of $P^{(k)}$ are integers,
  every element in $x$ must also be an algebraic number of degree $≤ d+1$.
\end{proof}

% ==============================================================================
\section{Klein Polyhedron}
% ==============================================================================

A vector $x ∈ ℝ^d$ is smaller than another vector $y ∈ ℝ^d$, denoted as $x ≤ y$, if $xᵢ ≤ yᵢ$ for at least one index $i ≥ 1$.

\begin{definition}
  A vector $\hat x$ is a \emph{relative minimum} with respect to a line $[\hat ω]$ if
  \[
    \|\hat ω - \hat x\| ≤ \|\hat ω - \hat y\| \text{ for every } \hat y ≤ \hat x,
  \]
  or equivalently,
  \[
    \left\|ω - \frac{x}{x₀} \right\| ≤ \left\|ω - \frac{y}{y₀}\right\| \text{ for every } \hat y ≤ \hat x.
  \]
\end{definition}

\begin{lemma}
  If $p$ is an extreme point of $K$, then $p$ is a good approximation.
\end{lemma}

% TODO: There could be a point in another Klein polytope which is closer.
\begin{proof}
  Suppose a better approximation $p^* ∈ K$ exists.
  Then, $p' = p^* + 2(p - p^*)$ is inside the polytope $K$.
  But this means that $p$ is a convex combination of $p'$ and $p^*$ and
  importantly, $p$ is not an extreme point.
  This is a contradiction and therefore $p$ is a good approximation.
\end{proof}

\begin{lemma}
  If $p$ is a good approximation, then $p$ is an extreme point of a Klein polytope.
\end{lemma}

% TODO
\begin{proof}
  \textbf{Idea}: Show that if $p$ is a convex combination of two integer points $a, b ∈ ℤ^d$,
  then $a$ and $b$ are in different Klein polytopes.
\end{proof}

\begin{theorem}
  Every convergent is an extreme point of a Klein polytope.
\end{theorem}

\begin{theorem}
  Every extreme point of a Klein polytope is a convergent of a MDCF.
\end{theorem}

\[
  B_ℓ^{(n)} = B^{(n-1)} \hat a, \quad
  B_0^{(n)} = B_ℓ^{(n-1)}, \quad
  B_i^{(n)} = B_i^{(n-1)}.
\]
