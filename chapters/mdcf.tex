\chapter{Multidimensional Continued Fractions}
\label{ch:mdcf}

For quadratic irrationals, we used continued fractions to represent them as a
periodic sequence of integers.
The continued fractions were constructed using the Euclidean algorithm.
Naturally, we can generalize continued fractions to higher dimensions using the
generalized Euclidean algorithm.
This leads to a concept of Multidimensional Continued Fractions (MCFs), which could
potentially be an answer of Hermite's question.
Since they are based on the generalized Euclidean algorithm,
they extend previous generalizations of continued fractions based on the
Jacobi-Perron algorithm, like bifurcating or ternary continued fractions \cite{Gupta00}.

This chapter introduces the concept of MCFs and discusses their potential as
an answer to Hermite's question.
We begin by defining what they are and deriving many properties similar to
continued fractions.
The chapter contains two main results for MCFs.
The first is that they converge under certain conditions
and the second is that periodic MCFs always consist of algebraic numbers with degree $≤ d+1$.
For the latter, we will first analyze the geometry behind MCFs in the same
style as Klein did for continued fractions.
What is missing from this chapter is the other direction,
that MCFs containing certain algebraic numbers are always periodic.
This will be discussed in more detail in the next chapter.

% ==============================================================================
\section{Reversing the Generalized Euclidean Algorithm}
% ==============================================================================

% TODO: We are already explaining this in the other chapter, so this needs to be REMOVED.
To derive the continued fraction for a real number, we have used an algorithm
similar to the Euclidean algorithm.
In particular, we looked at the ratio $a/b$ between the two inputs $a$ and $b$,
and we have used the integer part of that ratio as a coefficient in the
continued fraction.
Iterating the algorithm then gave us a unique representation for
every real number.
Since the Euclidean algorithm is just the generalized version for $d = 1$,
we can easily extend this algorithm to higher dimensions.
The generalized algorithm already contains some notion of a ratio in the form
of the solution vector $x$.
If $d = 1$, then the solution vector $x$ is a solution to the equation $bx = a$,
where $a$ and $b$ are inputs for the classical Euclidean algorithm.
So the integer part of the solution $x$ represents the first coefficient for
the continued fraction of $a/b$ and the fractional part $\{a/b\}$ is the
inverse of the next continued fraction.

The multidimensional continued fraction can now be easily derived from the
solution vector $x$ in higher dimensions.
Specifically, given a vector $x ∈ ℝ^d$, we take the integer part of each
element $\floor{x}$ as a coefficient of the multidimensional continued
fraction.
Then, we get the subsequent coefficients by iterating over this vector using
the $\mathrm{pivot}$ operation.
This gives us a top-down construction of MCFs, but we defined continued
fractions are defined in a bottom-up fashion.
For a bottom-up definition of the MCFs, we have to reverse the pivot operation.
The inverse operation can be derived as follows:
Let $x ∈ ℝ^d$ and $a = \floor{x}$.
If $x' = \mathrm{pivot}_ℓ(x)$ for a given index $ℓ$, then
\[
  \begin{array}{lcrlcr}
    \displaystyle x_i' & = & \displaystyle \frac{x_i - a_i}{x_ℓ - a_ℓ}, &
    \displaystyle x_ℓ' & = & \displaystyle \frac{x_i - a_i}{x_ℓ - a_ℓ} \\[1em]
  \end{array}
\]
for all $i ≠ ℓ$.
For the inverse operation, we have to derive every element of $x$ from $x'$,
which can be done by the following equations:
\[
  \begin{array}{lcrlcr}
    \displaystyle x_i & = & a_i + \displaystyle \frac{x_i'}{x_ℓ'}, &
    \displaystyle x_ℓ & = & a_ℓ + \displaystyle \frac{1}{x_ℓ'}
  \end{array}
\]
This allows us to calculate the previous vector $x$ from the next vector $x'$,
if we know the integer vector $a$.
What we do not need for the inverse function is the index $ℓ$.
The reason is that $x_ℓ' = 1/\{x_ℓ\}$ is always the largest element,
since $\{x_i\} < 1$ for every element.
So we can derive $ℓ$ from the vector $x'$ by finding the index of the largest element.
We will denote the inverse function as $\mathrm{pivot}^{-1}$,
it takes a vector $x' ∈ ℝ^d$ and an integer vector $a$
and then calculates $x$ using the equations above.
In summary, we have
\[
  \mathrm{pivot}_ℓ(x) = x' \iff \mathrm{pivot}^{-1}(a, x') = x.
\]

Using this inverse operation we can directly derive the bottom-up definition for MCFs.
So far we have only used integer vectors $a ∈ ℤ^d$,
however, in the definition we will allow any real vector, just like with the continued fractions.
Again this is for subsequent lemmas, where we will need rational or even real vectors coefficients.

\begin{definition}
  Given a sequence of $d$-dimensional real vectors $(r^{(n)})_{n ≥ 0}$,
  the \emph{$d$-dimensional continued fraction} $[r^{(0)}; r^{(1)}, …]$ is defined as
  \[
    [r^{(0)}; r^{(1)}, …] = \lim_{n → ∞} [r^{(0)}; r^{(1)}, …, r^{(n)}],
  \]
  where the finite continued fractions $[r^{(0)}; r^{(1)}, …, r^{(n)}]$
  are defined inductively as
  \[
    [r^{(0)}] = r^{(0)},
    \qquad
    [r^{(0)}, r^{(1)}, …, r^{(n)}]
    = \mathrm{pivot}^{-1}\big(r^{(0)}, [r^{(1)}, r^{(2)}, …, r^{(n)}]\big).
  \]
\end{definition}

For the representation to be correct, we require $\max_i r_i^{(n)} ≠ 0$ for $n ≥ 1$.
This is similar to the continued fractions, where only the first value could be zero,
while all subsequent values had to be positive.
For the multidimensional counterpart we only require that the pivot element is not zero.
The other values in the vector $r^{(n)}$ can assume any non-negative value.

The terminology from one-dimensional continued fractions naturally carry over to its
multidimensional counterpart.
Given an infinite MCF representation~$[a₀; a_1, …]$ of a vector $x ∈ ℝ^d$, we define the following:

\begin{itemize}
  \item The \emph{$k$-th convergent} of $x$ is the finite MCF $[r^{(0)}; r^{(1)}, …, r^{(n)}]$.
  \item The \emph{$k$-th complete quotient} is the MCF $[r^{(n)}; r^{(n+1)}, …]$.
  \item The MCF is \emph{eventually periodic} if there exists an index~$n₀ ≥ 0$
    and a period~$k ≥ 1$ such that $aₙ = a_{n+k}$ and $ℓₙ = ℓ_{n+k}$
    for every $n ≥ n₀$.
    The MCF is \emph{purely periodic} if $n₀ = 0$.
\end{itemize}

For the analysis of MCFs,
we begin with two lemmas which generalize Lemma~\ref{lem:cf-nesting} and
Lemma~\vref{lem:cf-wallis}.
The first allows us to merge the last two coefficients of an MCF.
The second gives us a formula for calculating the convergents.

\begin{lemma}
  \label{lem:mdcf-nesting}
  Let $x ∈ ℝ^d$, then
  \[
    [r^{(0)}; r^{(1)}, …, r^{(n)}, x]
    = [r^{(0)}; r^{(1)}, …, r^{(n-1)}, \mathrm{pivot}^{-1}(r^{(n)}, x)]
  \]
\end{lemma}

\begin{proof}
  If $n = 0$, then by definition,
  \[
    [r^{(0)}; x] = \mathrm{pivot}^{-1}(r^{(0)}, [x]) = \mathrm{pivot}^{-1}(r^{(0)}, x) = [\mathrm{pivot}^{-1}(r^{(0)}, x)].
  \]
  Suppose the lemma holds for any $n ≥ 0$, then
  \begin{align*}
    [r^{(0)}; r^{(1)}, …, r^{(n+1)}, x]
    & = \mathrm{pivot}^{-1}(r^{(0)}, [r^{(1)}; r^{(2)}, …, r^{(n+1)}, x]) \\
    & = \mathrm{pivot}^{-1}(r^{(0)}, [r^{(1)}; r^{(2)}, …, r^{(n)}, \mathrm{pivot}^{-1}(r^{(n)}, x)] \\
    & = [r^{(0)}; r^{(1)}, …, r^{(n)}, \mathrm{pivot}^{-1}(r^{(n+1)}, x)]. \qedhere
  \end{align*}
\end{proof}

% TODO: Explain how to derive the sequences
The second lemma is more complicated.
In the lemma for continued fractions,
we defined the convergents of a continued fraction~$pₙ/qₙ$
using a fractional transformation based on the previous two
terms~$p_{n-1}/q_{n-1}$ and $p_{n-2}/q_{n-2}$.
For MCFs, we can similarly derive a recursive formula to derive the values of
the convergent vector $(p₁/q, \dots, p_d/q)$ using the previous convergents.
Deriving the sequence is more involved than the one-dimensional case since
there is an additional index $ℓ$ at each step.

The sequence is essentially the generalized Euclidean algorithm, but in reverse.
Just like the MCF is the application of the inverse pivot operation.
In the algorithm, we begin with a basis $B ∈ ℤ^{d×d}$ and a vector $c ∈ ℤ^d$.
First, we find a solution $x$ to $Bx = c$ and then we exchange $c$ with $B_ℓ$
and $B_ℓ$ with the remainder $B\{x\} = Bx - Ba_i$.
We continue this process until $x$ is entirely integral.
For the sequence, we reverse this process.
We begin with an already reduced basis $B'$ and a vector $c'$, which is an
integral combination of $B'$.
Then, we exchange $B'_{ℓ}$ with $c'$ and $c'$ with $B' a_i + B'_{ℓ}$.
We continue this process until $B x = c$.

In total, there are two types of sequences:
A sequence of $d+1$ vectors $P_0^{(n)}, P_1^{(n)}, …, P_d^{(n)} ∈ ℤ^{d+1}$ and a sequence
of $d+1$ scalars $Q_0^{(n)}, Q_1^{(n)}, …, Q_d^{(n)} ∈ ℤ$,
which represent the denominators of the convergents.
The sequences begin with
\begin{align*}
  P_0^{(-1)} & = 0, & P_i^{(-1)} & = e_i, \\
  Q_0^{(-1)} & = 1, & Q_i^{(-1)} & = 0,
\end{align*}
for every $i ∈ \{1, …, d\}$ and the sequences are updated according to the
following recurrences:
\begin{align*}
  P_ℓ^{(n)} & = P_0^{(n-1)} + P_1^{(n-1)} r_1^{(n)} + ⋯ + P_d^{(n-1)} r_d^{(n)}, &
  P_i^{(n)} & = P_i^{(n-1)}, &
  P_0^{(n)} & = P_{ℓₙ}^{(n-1)} \\
  Q_ℓ^{(n)} & = Q_0^{(n-1)} + Q_1^{(n-1)} r_1^{(n)} + ⋯ + Q_d^{(n-1)} r_d^{(n)}, &
  Q_i^{(n)} & = Q_i^{(n-1)}, &
  Q_0^{(n)} & = Q_{ℓₙ}^{(n-1)},
\end{align*}
where $i ≠ ℓ$ and $ℓ$ is the index of the maximum element in the complete
quotient $x^{(n)}$. % TODO: n or n - 1?
What this sequence effectively does is reconstructing the lattice from an
initial solution vector $x ∈ ℝ^d$ and its coefficient vectors $a_n$.

Modelling this back to the Euclidean algorithm,
the vectors $P_1^{(n)}, …, P_d^{(n)}$ represent the basis and $P_0^{(n)}$ is
the additional vector, which is reduced during a run of the algorithm.
This matches the behavior of the algorithm in reverse.
We begin with the vector $P_0^{(-1)} = 0$ since the Euclidean algorithm
would end with a zero vector.
Then, the formula calculates a new vector using an integral combination of the
old vectors and stores it in $P_ℓ^{(n)}$.
This corresponds directly to the modulo and exchange operation of the
generalized Euclidean algorithm.
As the vectors $P_0^{(n)}, P_1^{(n)}, …, P_d^{(n)}$ would grow infinitely, the
values $Q_0^{(n)}, Q_1^{(n)}, …, Q_d^{(n)}$ scale the vectors back down and as
such they ensure that they converge to a limit as $n$ increases.

% TODO: Ensure that this is correct for the first index!
\begin{lemma}
  \label{lem:mdcf-wallis}
  Let $r^{(0)}, r^{(1)}, …, r^{(n-1)}, x ∈ ℝ^d$, then
  \[
    [r^{(0)}; r^{(1)}, …, r^{(n-1)}, x]
    = \frac{P_0^{(n-1)} + P_1^{(n-1)} x_1 + ⋯ + P_d^{(n-1)} x_d}{Q_0^{(n-1)} + Q_1^{(n-1)} x_1 + ⋯ + Q_d^{(n-1)} x_d}.
  \]
\end{lemma}

\begin{proof}
  If $n = 0$, then
  \[
    [x]
    = x
    = \frac{x}{1}
    = \frac{0 + e₁ x₁ + ⋯ + e_d x_d}{1 + 0 x₁ + ⋯ + 0 x_d}
    = \frac{P₀^{(0)} + P₁^{(0)} x₁ + ⋯ + P_d^{(0)} x_d}{Q_0^{(0)} + Q_1^{(0)} x₁ + ⋯ + Q_d^{(0)} x_d}.
  \]
  Suppose the lemma holds for $n ≥ 0$,
  we show that it also holds for $n+1$.
  From the previous lemma, it follows that
  \begin{align*}
    [r^{(0)}; r^{(1)}; …, r^{(n)}, x] & = [r^{(0)}; r^{(1)}, …, r^{(n-1)}, \mathrm{pivot}^{-1}(r^{(n)}, x)].
  \end{align*}
  Let $y = \mathrm{pivot}^{-1}(r^{(n)}, x)$ and $ℓ = \argmax_i x_i$.
  By the induction hypothesis,
  \begin{align*}
    [r^{(0)}; r^{(1)}; …, r^{(n)}, x] & = \frac{x_ℓ}{x_ℓ} · \frac{P_0^{(n-1)} + P_1^{(n-1)} y_1 + ⋯ + P_d^{(n-1)} y_d}{Q_0^{(n-1)} + Q_1^{(n-1)} y_1 + ⋯ + Q_d^{(n-1)} y_d},
  \end{align*}
  where the fraction is expanded with $x_ℓ/x_ℓ$ such that the numerator and denominator are each multiplied by $x_ℓ$.
  The numerator can then be simplified as follows:
  \begin{align*}
    & \hphantom{{} = {}} x_ℓ \left( P_0^{(n-1)} + P_ℓ^{(n-1)} y_ℓ + \sum_{i ∉ \{0,ℓ\}} P_i^{(n-1)} y_i \right) \\
    & = x_ℓ \left( P_0^{(n-1)} + P_ℓ^{(n-1)} \left( r_ℓ^{(n)} + \frac{1}{x_ℓ} \right) + \sum_{i ∉ \{0,ℓ\}} P_i^{(n-1)} \left(r_i^{(n)} + \frac{x_i}{x_ℓ} \right) \right) \\
    & = P_0^{(n-1)} x_ℓ + P_ℓ^{(n-1)} r_ℓ^{(n)} x_ℓ + P_ℓ^{(n-1)} + \sum_{i ∉ \{0,ℓ\}} P_i^{(n-1)} r_i^{(n)} x_ℓ + P_i^{(n-1)} x_i \\
    & = \underbrace{\left( P_0^{(n-1)} + P_ℓ^{(n-1)} r_ℓ^{(n)} + \sum_{i ∉ \{0,ℓ\}} P_i^{(n-1)} r_i^{(n)} \right)}_{P_ℓ^{(n)}} x_ℓ
      + \underbrace{P_ℓ^{(n-1)}}_{P_0^{(n)}}
      + \sum_{i ∉ \{0,ℓ\}} \underbrace{P_i^{(n)}}_{P_i^{(n)}} x_i \\
    & = P_0^{(n)} + P_1^{(n)} x_1 + ⋯ + P_d^{(n)} x_d.
  \end{align*}
  The simplification for the denominator is identical.
  Therefore,
  \[
    [r^{(0)}; r^{(1)}, …, r^{(n)}, x]
    = \frac{P_0^{(n)} + P_1^{(n)} x_1 + ⋯ + P_d^{(n)} x_d}{Q_0^{(n)} + Q_1^{(n)} x_1 + ⋯ + Q_d^{(n)} x_d}.
    \qedhere
  \]
\end{proof}

% ==============================================================================
\section{Convergence of Multidimensional Continued Fractions}
% ==============================================================================

% TODO: I don't like how we say that the requirement is from Perron, when it's
% not really from him, but just based on his version.
% TODO: The indices here are wrong...
So far in our analysis, we have implicitly assumed that the MCF $[a^{(0)}; a^{(1)}, a^{(2)} …]$
constructed using the generalized Euclidean algorithm always converges to the
original input vector $x ∈ ℝ^d$.
The aim of this section is to show that the convergents actually live up to
their name and converge towards the vector $x$ as $n$ increases.
Since we have used the Euclidean algorithm to construct the MCF,
we can assume that all vectors $a^{(n)}$ are positive integers even the first
one $a^{(0)}$.
Although the first coefficient can be negative, we can safely assume that its
not since the second coefficient is always positive.
Therefore, we simply prove the convergence for the second complete quotient $x^{(1)} =
[a^{(1)}; a^{(2)}, …]$ which leads to the convergence of the whole MCF.

Finally, we assume that the target vector $x = (x₁, …, x_d)$ is irrational,
which means that the MCF is infinite.
We denote with $x^{(n)}$ the $n$-th complete quotient of $x$
and if $ℓ$ is the index of the largest element in $x^{(n)}$,
then the $n$-th convergent of $x$ is denoted as
\[
  r^{(n)}
  = (r_1^{(n)}, …, r_d^{(n)})
  = \left( \frac{P_{1ℓ}^{(n)}}{Q_ℓ^{(n)}}, \dots, \frac{P_{dℓ}^{(n)}}{Q_ℓ^{(n)}} \right).
\]

The convergence proof is based on Perron's proof \cite{Perron07} for the convergence of his algorithm.
For the proof we need two more requirements.
The first comes from Perron's original proof.
In his version, he required that there exists some constant $A > 0$ such that
\[
  0 < \frac{1}{a_ℓ^{(n)}} ≤ A
  \quad \text{ and } \quad
  0 ≤ \frac{a_i^{(n)}}{a_ℓ^{(n)}} ≤ A \quad \text{ for every } i ≠ ℓ,
\]
where $ℓ$ is the index of the largest element in $x^{(n)}$.
This condition is always satisfied by MCFs.
Because $x_ℓ^{(n)}$ is the largest element
and the integer part of every element in the complete quotient is determined by $a_i^{(n)}$,
the element $a_ℓ^{(n)}$ must also be the largest element in $a^{(n)}$.
Furthermore $a_ℓ^{(n)}$ cannot be zero due to the requirements.
Hence, this condition is satisfied for $A = 1$.

The second requirement is specifically for MCFs.
Each MCF is constructed using the generalized Euclidean algorithm and one
possible choice of indices $ℓ₁, ℓ₂, …$ between $1$ and $d$.
In the opposite direction, this means that the complete quotients can have different elements as their maximum.
The second requirement then states that during the construction of the MCF
we use every index infinitely often.
Again, in the opposite direction, this means that for each $i ∈ \{1, …, d\}$,
there are infinitely many complete quotients which have $x_i^{(n)}$ as their
largest element.
This requirement is already given in the Jacobi-Perron algorithm,
but not in the generalized Euclidean algorithm.
So we need this specifically for MCFs.

\begin{example}
  Consider the MCF $[(2, 1); \overline{(2, 1)}]$.
  The maximum in the first complete quotient is $x^{(1)}_1$,
  because the coefficient $a^{(1)} = (2, 1)$ determines the integer part
  for all elements in $x^{(1)}$ and the next complete quotient $x^{(2)}$
  only determines the fractional part.
  Therefore, the first element must be the largest.
  However, then it does not satisfy the second requirement.
  Therefore, the following proof won't apply to this MCF.
\end{example}

The vector $r^{(n)}$ is only one possible convergent out of several.
If $n$ is large enough, then we can consider the other vectors
$P_i^{(n)}/Q_i^{(n)}$ with $i ≠ ℓ$ as convergent vectors,
since $x_i^{(m)}$ must have been the largest element at some index $m < n$.
We will call $r^{(n)}$ the \emph{primary convergent} and the other ones
\emph{secondary convergents}.
The first step for the proof is to show that the next primary convergent $r^{(n)}$ is a
convex combination of the previous secondary convergents.
This shows that the primary convergent always lies in the convex hull of the
secondary convergents.

% TODO: We should probably add superscripts to the lambdas as they depend on n.
\begin{lemma}
  \label{lem:conv-conv}
  There exists $λ₀^{(n)}, λ₁^{(n)}, …, λ_d^{(n)} ≥ 0$ with $λ₀^{(n)} + λ₁^{(n)} + ⋯ + λ_d^{(n)} = 1$ such that
  \[
    r_i^{(n)} = λ₀^{(n)} \frac{P_{i0}^{(n-1)}}{Q_0^{(n-1)}} + λ₁^{(n)} \frac{P_{i1}^{(n-1)}}{Q_1^{(n-1)}} + ⋯ + λ_d^{(n)} \frac{P_{id}^{(n-1)}}{Q_d^{(n-1)}}.
  \]
\end{lemma}

\begin{proof}
  We choose $n ≥ 0$ such that every element was the maximum at least once.
  In particular, this means that $Q_i^{(n-1)} > 0$ for every $i ∈ \{1, …, d\}$.
  Let $ℓ$ be the index of the largest element in $x^{(n)}$.
  By Lemma~\ref{lem:mdcf-wallis}, we can calculate $P_{iℓ}^{(n)}$ using the previous values as follows:
  \begin{align*}
    P_{iℓ}^{(n)} = \sum_{k = 1}^d P_{ik}^{(n-1)} a_k^{(n)} + P_{i0}^{(n-1)}.
  \end{align*}
  Dividing by $Q_ℓ^{(n)}$ gives us
  \begin{align*}
    \frac{P_{iℓ}^{(n)}}{Q_ℓ^{(n)}} = \sum_{k = 1}^d \frac{P_{ik}^{(n-1)}}{Q_ℓ^{(n)}} a_k^{(n)} + \frac{P_{i0}^{(n-1)}}{Q_ℓ^{(n)}}.
  \end{align*}
  Using $λ_k = a_k^{(n)} \frac{Q_k^{(n-1)}}{Q_ℓ^{(n)}}$ for $1 ≤ k ≤ d$ and $λ₀ = \frac{Q_0^{(n-1)}}{Q_ℓ^{(n)}}$,
  we can reformulate the convergent as the convex combination for this lemma.
  Because of the requirement that every index has occurred at least once,
  the denominators $Q_k^{(n-1)}$ of the convex combination cannot be zero.
  Therefore, this is a valid representation of the convergent $r_i^{(n)}$.
  For the coefficients themselves, we require $λ₀ + λ₁ + ⋯ + λ_d = 1$ and $0 ≤ λᵢ ≤ 1$ for every index $i$.
  The first property follows from the definition of $Q_ℓ^{(n)}$:
  \[
    Q_ℓ^{(n)} = Q_0^{(n-1)} + Q_1^{(n-1)} a_1^{(n)} + ⋯ + Q_d^{(n-1)} a_d^{(n)}
  \]
  which is equivalent to
  \[
    1 = \frac{Q_0^{(n-1)}}{Q_ℓ^{(n)}} + \frac{Q_1^{(n-1)}}{Q_ℓ^{(n)}} a_1^{(n)} + ⋯ + \frac{Q_d^{(n-1)}}{Q_ℓ^{(n)}} a_d^{(n)} = λ₀^{(n)} + λ₁^{(n)} + ⋯ + λ_d^{(n)}.
  \]
  The second property follows from the fact that every vector $a^{(n)}$ is nonnegative.
  Therefore, the denominator $Q_ℓ^{(n)}$ is always less than or equal to $a_i^{(n)} Q_i^{(n-1)}$ and
  $λ_i$ is always bounded between $0$ and $1$.
\end{proof}

Next, we enclose the secondary convergents inside an axis-aligned bounding box.
At each iteration, we define the box by its minimum and maximum corner points using the two sequences
$s^{(n)} = (s_1^{(n)}, …, s_d^{(n)})$ and $t^{(n)} = (t_1^{(n)}, …, t_d^{(n)})$ which are defined as
\[
  s_i^{(n)} = \min\left\{\frac{P_{i0}^{(n)}}{Q_0^{(n)}}, \frac{P_{i1}^{(n)}}{Q_1^{(n)}}, …, \frac{P_{id}^{(n)}}{Q_d^{(n)}}\right\}
\]
and
\[
  t_i^{(n)} = \max\left\{\frac{P_{i0}^{(n)}}{Q_0^{(n)}}, \frac{P_{i1}^{(n)}}{Q_1^{(n)}}, …, \frac{P_{id}^{(n)}}{Q_d^{(n)}}\right\}.
\]
We use this box to show the convergence via the squeeze theorem.
The primary convergent $r^{(n)}$ lies inside the box since it is one of the
secondary convergent vectors used in the definition of the sequences.
So if $s^{(n)}$ and $t^{(n)}$ converge to the same limit, then $r^{(n)}$ must
also converge to the same limit.
For the convergence of $s^{(n)}$ and $t^{(n)}$, we show that each of them is
monotone and bounded.
By the monotone-convergence theorem, the sequences must converge.

\begin{lemma}
  The sequences $s_i^{(n)}$ and $t_i^{(n)}$ are monotone and bounded.
\end{lemma}

\begin{proof}
  We can bound the new convergent $r^{(n)}$ from below using the previous term $s^{(n-1)}$.
  For the previous iteration, we already have $P_{ij}^{(n-1)}/Q_j^{(n-1)} ≥ s_i^{(n-1)}$
  for every $j ∈ \{0, …, d\}$ by construction.
  Using Lemma~\ref{lem:conv-conv},
  \begin{align*}
    \frac{P_{iℓ}^{(n)}}{Q_ℓ^{(n)}}
    & = λ₀^{(n)} \frac{P_{i0}^{(n-1)}}{Q_0^{(n-1)}} + λ₁^{(n)} \frac{P_{i1}^{(n-1)}}{Q_1^{(n-1)}} + ⋯ + λ_d^{(n)} \frac{P_{id}^{(n-1)}}{Q_d^{(n-1)}} \\
    & ≥ λ₀^{(n)} s_i^{(n-1)} + λ₁^{(n)} s_i^{(n-1)} + ⋯ + λ_d^{(n)} s_i^{(n-1)}
      = s_i^{(n-1)}.
  \end{align*}
  The bound for the other convergents $r_j^{(n)}$ with $j ≠ ℓ$ is even easier since
  \[
    \frac{P_{ij}^{(n)}}{Q_j^{(n)}} = \frac{P_{ij}^{(n-1)}}{Q_j^{(n-1)}} ≥ s_i^{(n-1)}.
  \]
  Using the same argument, we can bound each convergent from above by $t_i^{(n-1)}$.
  Therefore, in each iteration all secondary convergents are
  bounded between previous minimum~$s_i^{(n-1)}$ and previous maximum~$t_i^{(n-1)}$.
  Hence, the next minimum~$s_i^{(n)}$ and the next maximum~$t_i^{(n)}$ must
  also be bounded between the two terms.
  In summary, we have
  \[
    s_i^{(n-1)} ≤ s_i^{(n)} ≤ r_i^{(n)} ≤ t_i^{(n)} ≤ t_i^{(n-1)}. \qedhere
  \]
\end{proof}

In order to show that the sequences $s^{(n)}$ and $t^{(n)}$ are actually
converging to the same limit, we first need this crucial lemma about the
coefficients $λ₀^{(n)}, λ₁^{(n)}, …, λ_d^{(n)}$ from Lemma~\ref{lem:conv-conv}.
% TODO: Actually add the figure here. Or do we wanna use the combined one, which is already here?
%The main idea behind the lemma is illustrated in Figure~\ref{fig:lambda-pos}.
It states that one of the coefficients is always greater than some constant
independently of $n$ and importantly that coefficient is for the previous convergent $r^{(n-1)}$.
From the recurrence for the convergents,
it follows that we always carry over the primary convergent $r^{(n-1)}$ as one
of the secondary convergents in the next iteration.
Therefore, we cannot change its position.
However, we can change one of the other convergents.
But the area available for the next convergent $r^{(n)}$ is restricted by this lemma
such that the convex hull always shrinks by a constant amount.

% TODO: We could maybe save this by only stating that this occurs infinitely often.
% I think so, because if this cannot happen less than $d$ times. Otherwise, we must have a duplicate index.
% -> This should also work if we're doing this for any index.
\begin{lemma}
  \label{lem:lambda-pos}
  There exists one index $ℓ^+ ∈ \{0, …, d\}$ with $λ_{ℓ^+}^{(n)} > 1/C$ for some integer $C > 0$.
\end{lemma}

% TODO: Show that it is not equal to 1!
\begin{proof}
  Let $ℓ^+$ be the index of the largest element in the previous complete quotient $x^{(n-1)}$.
  Using the initial requirements for the coefficients $a_i^{(n)}$ and the fact
  that
  \[
    Q_{ℓ^+}^{(n-1)} > Q_i^{(n-1)}
  \]
  for every $i ≠ ℓ$.
  It follows that
  \[
    \frac{λ_i^{(n)}}{λ_{ℓ^+}^{(n)}}
    = \frac{a_i^{(n)}}{a_{ℓ^+}^{(n)}} · \frac{Q_i^{(n-1)}}{Q_{ℓ^+}^{(n-1)}}
    ≤ \frac{a_i^{(n)}}{a_{ℓ^+}^{(n)}}
    ≤ A,
  \]
  or equivalently $λᵢ^{(n)} ≤ A λ_{ℓ^+}^{(n)}$.
  But then,
  \[
    1 = λ₀^{(n)} + λ₁^{(n)} + ⋯ + λ_d^{(n)} ≤ λ_{ℓ^+}^{(n)} (1 + dA).
  \]
  Therefore, $λ_{ℓ^+}^{(n)} ≥ 1/C$ with $C = 1 + dA > 0$.
\end{proof}

\begin{figure}[tbp]
  \centering
  \includegraphics{build/convergence.pdf}
  \caption{
    Illustration of the proof for the convergence of MCFs.
    The points $r^{(i)}, r^{(j)}$ and $r^{(k)}$ represent the convergents and $x$ is
    the vector, which is approximated by them.
    If $r^{(k)}$ is the convergent of the current iteration,
    then either $r^{(i)}$ or $r^{(j)}$ has to be moved in the next iteration.
    However, neither can go in the red triangle,
    since $λ_k^{(n)} > 1/M$.
  }
  \label{fig:convergence}
\end{figure}

If the sequences $s^{(n)}$ and $t^{(n)}$ converge to the same limit,
then that means that the bounding box shrinks to a point.
Therefore, the convergent $r^{(n)}$, which is inside this box, converges to the
same point.
However, the box could also turn out to be nonempty,
if the sequences approach different limits, i.e.
\[
  \lim_{n → ∞} s_i^{(n)} < \lim_{n → ∞} t_i^{(n)}.
\]
But the previous lemma contradicts this assumption.
The area of the convex hull always shrinks by a at least a constant proportion.
So if the sequences would approach different limits, then we can always find a
point at which all convergents step over the box and all of them are contained
in the supposed limit.
This is the main idea behind the following proof.

% TODO: Should we add the requirements, like every index occurs infinitely
% often (but the correct version)?
\begin{lemma}
  \label{lem:min-max-conv}
  The minimum $s_i^{(n)}$ and maximum $t_i^{(n)}$ are converging to the same
  limit.
\end{lemma}

\begin{proof}
  Let $s_i = \lim_{n → ∞} s_i^{(n)}$
  and $t_i = \lim_{n → ∞} t_i^{(n)}$ for every $i ≤ d$.
  Suppose $s_i < t_i$.
  For the minimum~$s_i$, there must exist an $ε > 0$ and an index $N ≥ 0$ such
  that for every $n ≥ N$,
  \[
    \frac{P_{ij}^{(n)}}{Q_j^{(n)}} ≥ s_i^{(n)} > s_i - ε.
  \]
  Let $ℓ$ be the index of the largest element in the previous complete quotient $x^{(n-1)}$.
  Since the limit $s_i - ε$ bounds the secondary convergents,
  we can use this to bound the primary convergent
  %$Q_i^{(n-1)} = Q_i^{(n-2)}$ and $Q_k^{(n-1)} = Q_0^{(n-2)} + Q_1^{(n-2)} a_1^{(n-1)} + ⋯ + Q_d^{(n-2)} a_d^{(n-1)}$. % TODO: Why was this here?
  \begin{align*}
    r_i^{(n)}
    & = λ₀^{(n)} \frac{P_{i0}^{(n-1)}}{Q_0^{(n-1)}} + λ₁^{(n)} \frac{P_{i1}^{(n-1)}}{Q_1^{(n-1)}} + ⋯ + λ_d^{(n)} \frac{P_{id}^{(n-1)}}{Q_d^{(n-1)}} \\
    & > λ_{ℓ}^{(n)} \frac{P_{iℓ}^{(n-1)}}{Q_{ℓ}^{(n-1)}} + \sum_{i ≠ k} λ_i^{(n)} (s_i - ε) \\
    & = λ_{ℓ}^{(n)} r_i^{(n-1)} + (1 - λ_ℓ^{(n)}) (s_i - ε),
  \end{align*}
  or equivalently
  \begin{align*}
    r_i^{(n)} - s_i > λ_{ℓ}^{(n)} \left( r_i^{(n-1)} - s_i \right) - ε.
  \end{align*}
  Lemma~\ref{lem:lambda-pos} tells us that there is a positive constant $C$
  which bounds $λ_{ℓ}^{(n)}$ from below.
  It follows that
  \begin{align*}
    r_i^{(n)} - s_i > \frac{1}{C} \left( r_i^{(n-1)} - s_i \right) - ε
  \end{align*}
  for some constant $C > 0$.
  Advancing this inequality from $n$ to $n+1, n+2, …, n+k$ results in the new
  inequality
  \begin{align*}
    r_i^{(n+k)} - s_i > \frac{1}{C^k} \left( r_i^{(n-1)} - s_i \right) - ε\left( \frac{1}{C} + \frac{1}{C^2} + ⋯ + \frac{1}{C^{k-1}} \right).
  \end{align*}
  Since every index occurs infinitely often,
  there must be one index $n$ where $r_i^{(n-1)} ≤ t_i$
  and another index $n+k$ where $r_i^{(n+k)} ≥ s_i$.
  \begin{align*}
    0 > \frac{1}{C^k} \left( t_i - s_i \right) - ε\left( \frac{1}{C} + \frac{1}{C^2} + ⋯ + \frac{1}{C^{k-1}} \right).
  \end{align*}
  But $ε$ can be chosen arbitrarily small,
  which is a contradiction to the fact that $t_i - s_i > 0$.
  Therefore, $t_i$ and $s_i$ converge to the same limit.
\end{proof}

We have shown that $s^{(n)}$ and $t^{(n)}$ converge to the same limit
and that $r^{(n)}$ therefore also converges to that limit.
What remains to be shown is what they converge to,
which is the original vector $x$ used for construction of the MCF.

% TODO: Fix statement, i.e. ℓₙ no longer exists...
\begin{theorem}
  \label{thm:mdcf-conv}
  The sequence $r^{(n)}$ converges to $x$.
\end{theorem}

% TODO: We should improve the last section of this proof,
% because I don't think this is correctly showing that it converges to the same
% limit. Or rather, we're already assuming that we are approaching x_i in the
% limit.
\begin{proof}
  Let $x^{(n)}$ denote the $n$-th complete quotient of $x$.
  By Lemma~\ref{lem:mdcf-wallis}, we can represent each element in $x$ as
  \[
    x_i = \frac{P_{i0}^{(n-1)} + P_{i1}^{(n-1)} x_1^{(n)} + ⋯ + P_{id}^{(n-1)} x_d^{(n)}}{Q_{i0}^{(n-1)} + Q_{i1}^{(n-1)} x_1^{(n)} + ⋯ + Q_{id}^{(n-1)} x_d^{(n)}}.
  \]
  Using a similar argument as Lemma~\ref{lem:conv-conv}, we can represent this
  as a convex combination
  \begin{align*}
    x_i & = μ₀^{(n)} \frac{P_{i0}^{(n-1)}}{Q_0^{(n-1)}}  + μ₁^{(n)} \frac{P_{i1}^{(n-1)}}{Q_1^{(n-1)}} + μ_d^{(n)} \frac{P_{id}^{(n-1)}}{Q_d^{(n-1)}}
    \\
    &
    \text{ with }
    \quad
    μ_i^{(n)} = x_i^{(n)} \frac{Q_i^{(n-1)}}{Q_0^{(n-1)} + Q_d^{(n)} x_1^{(n)} + ⋯ + Q_d^{(n-1)} x_d^{(n)}}.
  \end{align*}
  From the previous lemma, we know that $r^{(n)}$ converges to some limit $x' ∈ ℝ^d$.
  Since every index occurs infinitely often,
  we can find an index $m ≤ n - 1$ such that the primary convergent $r_i^{(m)}$ is
  \[
    \frac{P_{ij}^{(n-1)}}{Q_j^{(n-1)}} = \frac{P_{ij}^{(m)}}{Q_j^{(m)}}.
  \]
  As $n$ increases there are infinitely many such convergents, so each term converges to $x_i'$.
  Thus, for each secondary convergent there are sufficiently small values $ε₀, ε₁, …, ε_d$ such that
  \begin{align*}
    x_i
    & = μ₀^{(n)} \frac{P_{i0}^{(n-1)}}{Q_0^{(n-1)}}  + μ₁^{(n)} \frac{P_{i1}^{(n-1)}}{Q_1^{(n-1)}} + μ_d^{(n)} \frac{P_{id}^{(n-1)}}{Q_d^{(n-1)}} \\
    & = μ₀^{(n)} (x_i' - ε₀) + μ₁^{(n)} (x_i - ε₁) + ⋯ + μ_d^{(n)} (x_d - ε_d) \\
    & = x_i' - (μ₀^{(n)} ε₀ + μ₁^{(n)} ε₁ + ⋯ + μ_d^{(n)} ε_d).
  \end{align*}
  However, as $n$ increases the values $εᵢ$ must become arbitrarily small
  and because the coefficients $μ₀^{(n)}, μ₁^{(n)}, …, μ_d^{(n)}$ all lie between $0$ and $1$,
  we can conclude that $x_i = x_i'$.
\end{proof}

% ==============================================================================
\section{Geometrical Interpretation}
\label{sec:mdcf-geometry}
% ==============================================================================

% TODO: I'm not sold on the square brackets. With the list notation for the
% continued fraction, they're kind of ambiguous. Maybe we should just switch to
% regular parentheses instead.
In the geometrical interpretation of continued fractions,
we represented each convergent $pₙ/qₙ$ as a two-dimensional vector $(pₙ, qₙ)$.
These vectors approached an irrational line spanned by the vector $(1, α)$
where $α$ is some irrational number.
For the generalization to multidimensional continued fractions,
we represent each convergent,
which is a $d$-dimensional rational vector,
as a $(d+1)$-dimensional integer vector.
Specifically, given a vector $r^{(n)} = (p₁/q₁, …, p_d/q_d) ∈ ℚ^d$,
we first find a common denominator $(p₁'/q, …, p_d'/q)$ and
then we map it to the vector $\hat r = (q, p₁', …, p_d') ∈ ℤ^{d+1}$.
We can go back from the integer vector to a rational vector
by dividing each coordinate with the first and
removing the first coordinate from the integer vector,
i.e. given $(x₀, x₁, …, x_d) ∈ ℤ^{d+1}$, we map it back to $(x₁/x₀, …, x_d/x₀) ∈ ℚ^d$.

In this space, the representation for a particular convergent is not unique,
there can be multiple integer vectors representing the same convergent.
For example, if we have a vector $r ∈ ℤ^{d+1}$ for a convergent,
then we can multiply with some scalar $λ ∈ ℤ$ and get a new vector $r' = λ r$
which represents the same convergent.
This is because the scalar is eliminated when mapping it back to the rational vector:
\[
  λ (c₀, c₁, …, c_d)
  ↦ \left(\frac{λ c₁}{λ c₀}, …, \frac{λ c_d}{λ c_0} \right)
  = \left(\frac{c₁}{c₀}, …, \frac{c_d}{c_0} \right).
\]
Therefore, two nonzero vectors $a, b ∈ ℝ^{d+1}$ are equivalent,
denoted as $a \sim b$, if $a = λ b$ for some scalar $λ ∈ ℝ$.
This relation then defines the equivalence class of an element $a ∈ ℝ^{d+1}$ as
\[
  [a] = \mathrm{span}(a) = \{ λ a \mid λ ∈ ℝ, λ ≠ 0 \}.
\]
Formally, this is known as a real projective space, denoted as $\mathbb{RP}^{d+1}$.
It is the set of equivalence classes $ℝ^{d+1} \setminus \{0\}$ defined by the
equivalence relation $\sim$.
An element $x$ of this space is denoted as $[x₀, x₁, …, x_d]$,
where the square brackets indicate that this element is an equivalence
class.
In summary, we have the following mappings from $ℝ^d$ to $\mathbb{RP}^{d+1}$
and vice-versa:

\begin{center}
  \begin{tikzpicture}
    \matrix[
      column sep=2cm,
      nodes={text width=3cm, align=center},
    ] {
      \node (L0) {$\mathbb{R}^d$}; &
      \node (R0) {$\mathbb{RP}^{d+1}$}; \\
      \node (L1) {$(x₁, …, x_d)$}; &
      \node (R1) {$[1, x₁, …, x_d]$}; \\
      \node (L2) {$(x₁/x₀, …, x_d/x₀)$}; &
      \node (R2) {$[x₀, x₁, …, x_d]$}; \\
    };

    \draw[->] (L1) -- node[above] {} (R1);
    \draw[<-] (L2) -- node[above] {} (R2);
  \end{tikzpicture}
\end{center}

For example, consider the vector $[1, x₁, x₂]$ and suppose that $0 ≤ x₁, x₂ < 1$.
A pivot operation with $ℓ = 1$ would result in the vector $[1, 1/x₁, x₂/x₁]$.
This vector is equivalent to $[x₁, 1, x₂]$.
Therefore, we can reformulate this operation as a coordinate swap of $x_ℓ$ with
the new coordinate $x₀$:
\[
  \begin{bmatrix}
    0 & 1 & 0 \\
    1 & 0 & 0 \\
    0 & 0 & 1 \\
  \end{bmatrix}
  ·
  \begin{bmatrix} 1 \\ x₁ \\ x₂ \\ \end{bmatrix}
  =
  \begin{bmatrix} x₁ \\ 1 \\ x₂ \\ \end{bmatrix}
  =
  \begin{bmatrix} 1 \\ 1/x₁ \\ x₂/x₂ \\ \end{bmatrix}.
\]
If $x₁$ and $x₂$ are greater than $1$,
then we first have to subtract the integer part from the vector $x$.
In the projective space, this is equivalent to a series of skew operations:
\[
  \begin{bmatrix}
    1 & 0 & 0 \\
    -\floor{x₁} & 1 & 0 \\
    0 & 0 & 1 \\
  \end{bmatrix}
  ·
  \begin{bmatrix}
    1 & 0 & 0 \\
    0 & 1 & 0 \\
    -\floor{x₂} & 0 & 1 \\
  \end{bmatrix}
  ·
  \begin{bmatrix} 1 \\ x₁ \\ x₂ \\ \end{bmatrix}
  =
  \begin{bmatrix} 1 \\ x₁ - \floor{x₁} \\ x₂ - \floor{x₂} \\ \end{bmatrix}.
\]
Importantly, each of those matrices has
determinant $±1$.
Therefore, the whole operation can be easily reversed by inverting the matrix.
This is the equivalent of the inverse pivot operation in
the projective space $\mathbb{RP}^{d+1}$.
Using this notion, we can reformulate the MCF as a series of matrix multiplications.
In the following $S(a)$ denotes the translation by a vector $a ∈ ℝ^d$
and the matrix $R(ℓ)$ denotes the swap of $x_ℓ$ with $x_0$.
The definition of the MCFs can then be written as
\[
  [a^{(0)}] = \hat a^{(0)}, \qquad
  [a^{(0)}; a^{(1)}, …, a^{(n)}] = T(a₀) · S(ℓ) · [a^{(1)}; a^{(2)}, …, a^{(n)}],
\]
where $ℓ$ is the index of the largest element in $[a^{(1)}; a^{(2)}, …, a^{(n)}]$ and $\hat a^{(0)} = [1, a_1^{(0)}, …, a_d^{(0)}]$.

We can also use the projective space to dramatically simplify Lemma~\ref{lem:mdcf-wallis}.
Instead of two different sequences $P_i^{(n)}$ and $Q_i^{(n)}$, we simplify it to a single matrix sequence $(B^{(n)})_{n ≥ 0}$,
where one matrix $B^{(n)}$ consists of the column vectors $B₀^{(n)}, B₁^{(n)}, …, B_d^{(n)}$.
We begin with the identity matrix, $B^{(0)} = I_d$, and update the matrix according to
\begin{align*}
  B_{ℓₙ}^{(n)} = B^{(n-1)} \hat a^{(n)},
  \qquad B_i^{(n)} = B_i^{(n-1)},
  \qquad B_0^{(n)} = B_{ℓₙ}^{(n-1)},
\end{align*}
where $\hat a^{(n)} = [1, a_1^{(n)}, …, a_d^{(n)}]$.
By construction, $B^{(n)}$ is the combined matrix of the original sequences
$P_i^{(n)}$ and $Q_i^{(n)}$ defined for Lemma~\vref{lem:mdcf-wallis}:
\[
  B^{(n)} = \begin{bmatrix}
    Q_0^{(n)} & Q_1^{(n)} & ⋯ & Q_d^{(n)} \\
    P_0^{(n)} & P_1^{(n)} & ⋯ & P_d^{(n)} \\
  \end{bmatrix}.
\]
In fact, we can prove an equivalent statement from this lemma using the new sequence.

\begin{lemma}
  \label{lem:mdcf-wallis'}
  Let $x ∈ ℝ^d$ and $\hat x = (1, x₁, …, x_d)$, then
  \[
    [r^{(0)}; r^{(1)}, …, r^{(n-1)}, x] = [B^{(n-1)} \hat x]
  \]
\end{lemma}

% TODO
\begin{proof}
  By construction of $B^{(n-1)}$, we have
  \begin{align*}
    B^{(n-1)} \hat x
    & = B_0^{(n-1)} \hat x_0 + B_1^{(n-1)} \hat x_1 + ⋯ + B_d^{(n-1)} x_d \\
    & =
    \begin{bmatrix}
      P_0^{(n-1)} \\
      Q_0^{(n-1)} \\
    \end{bmatrix} \hat x_0
    + \begin{bmatrix}
      P_1^{(n-1)} \\
      Q_1^{(n-1)} \\
    \end{bmatrix} \hat x_1
    + ⋯ + \begin{bmatrix}
      P_d^{(n-1)} \\
      Q_d^{(n-1)} \\
    \end{bmatrix} \hat x_d \\
    & = \begin{bmatrix}
      P_0^{(n-1)} \hat x_0 + P_1^{(n-1)} \hat x_1 + ⋯ + P_d^{(n-1)} \hat x_d \\
      Q_0^{(n-1)} \hat x_0 + Q_1^{(n-1)} \hat x_1 + ⋯ + Q_d^{(n-1)} \hat x_d \\
    \end{bmatrix}.
  \end{align*}
  Projecting this vector back to $ℚ^d$ results exactly in the vector
  \[
    r^{(n)} = \frac{P_0^{(n-1)} + P_1^{(n-1)} x_1 + ⋯ + P_d^{(n-1)} x_d}{Q_0^{(n-1)} + Q_1^{(n-1)} x_1 + ⋯ + Q_d^{(n-1)} x_d}
  \]
  from
  Lemma~\ref{lem:mdcf-wallis}.
\end{proof}

\iffalse
% TODO: Klein polyhedra?
Last but not least,
there also exists a generalization of Klein polygons to higher dimensions.
For three dimensions, they are known as Klein polyhedra
and in general they are known as Klein polytopes.

\begin{definition}
  Let $B = \{b₁, …, b_d\} ⊆ ℝ^d$ be a basis and let $C = \{ λ₁ b₁ + ⋯ + λ_d b_d \mid λ_i ≥ 0 \}$.
  The \emph{Klein polytope} $K$ generated by $B$ is defined as
  \[
    K = \mathrm{conv}(C ∩ ℤ^d \setminus \{\symbf 0\}).
  \]
\end{definition}

The connection between Klein polytopes and the convergents is not clear to me, however.
As before, we can show that the area between the convergents is empty.
The idea for a Klein polyhedra is visualized in Figure~\ref{fig:klein-polytope}.
This time, we consider the parallelepiped between the secondary convergents of the
current iteration and the previous iteration.
The number of integer points inside this parallelepiped can be calculated using
the determinant between the convergents.
Although the parallelepiped is not empty,
all of its integer points must be its the boundary.
Therefore, the volume between the convergents is empty.

Similarly,
Equation~\ref{eq:??} already shows that the line lies inside the convex hull of
the secondary convergents
and the convergence shows that the area of the convergents decreases towards zero.
\fi

% ==============================================================================
\section{Algebraic Numbers and Periodicity}
% ==============================================================================

The proof for periodic MCFs is based on the same theorem for the Jacobi-Perron
algorithm, originally proven by Perron \cite{Perron07}.
We begin with the purely periodic case.
The idea behind this proof is that in a purely periodic MCF of a vector $x ∈ ℝ^d$,
the vector itself is an eigenvector for one of the matrices $B^{(k)}$.
Furthermore, the elements of this eigenvector can only be algebraic numbers with degree $≤ d+1$.

\begin{lemma}
  \label{lem:mdcf-purely-periodic}
  If there exists a purely periodic MCF for $x ∈ ℝ^d$,
  then $[ℚ(x₁, …, x_d) : ℚ] ≤ d+1$.
\end{lemma}

% TODO: Should we use x ≡ y or [x] = [y]?
\begin{proof}
  If the MCF is purely periodic, then there is some index $n ≥ 1$ such that $x = x^{(n)}$.
  Let $\hat x = [1, x₁, …, x_d]$ and $\hat x^{(n)} = [1, x_1^{(n)}, …, x_d^{(n)}]$.
  By Lemma~\ref{lem:mdcf-wallis'},
  \[
    [\hat x] = [B^{(n)} \hat x^{(n)}] = [B^{(n)} \hat x] \iff λ \hat x = B^{(n)} \hat x,
  \]
  for some nonzero $λ ∈ ℝ$.
  Therefore, we are looking for an eigenvector $\hat x$ and an eigenvalue $λ$ of $B^{(n)}$.
  The characteristic polynomial $\det(B^{(n)} - λ I)$ can have a degree of at most $d+1$,
  therefore the eigenvalue $λ$ is an algebraic number of degree $d+1$.
  For the eigenvector $\hat x$, we have to find a nontrivial solution to the
  homogeneous linear system
  \[
    (B^{(n)} - λ I) \hat x = 0.
  \]
  Each coefficient in this linear system is either an integer or $λ$ and is
  therefore contained in the field $ℚ(λ)$.
  Hence, we have $[ℚ(\hat x_0, \hat x_1, …, \hat x_d) : ℚ] ≤ d+1$.

  Finally, the eigenvector $\hat x$ has to be projected back from homogeneous coordinates $x$.
  Since $xᵢ = \hat xᵢ / \hat x₀$ and the values $\hat xᵢ$ and $\hat x₀$ are members of the field $ℚ(λ)$,
  the projected value $xᵢ$ must also be contained in the same field.
  Therefore, each element in $x$ is an algebraic number
  and we have $[ℚ(x₁, …, x_d) : ℚ] ≤ d+1$.
\end{proof}

\begin{theorem}
  \label{thm:mdcf-periodic}
  If there exists a periodic MCF for $x ∈ ℝ^d$,
  then $[ℚ(x₁, …, x_d) : ℚ] ≤ d + 1$.
\end{theorem}

\begin{proof}
  Given such a MCF for $x$, let $x^{(k)}$ denote the $k$-th complete quotient
  of this fraction.
  Suppose that the MCF is periodic after $K ≥ 0$ with period $ℓ ≥ 0$, i.e.
  $x^{(k)} = x^{(k+ℓ)}$ for every $k ≥ K$.
  By Lemma~\ref{lem:mdcf-wallis'},
  \[
    [\hat x] = [B^{(k)} \hat x^{(k)}],
  \]
  which means that very element in $x$ can be represented
  as a rational expression of $x^{(k)}$:
  \[
    x_i = \frac{∑_{j=1}^d B_{ij}^{(k)} x_j^{(k)} + B_{i0}^{(k)}}{\sum_{j=1}^d B_{0j}^{(k)} x_j^{(k)} + B_{00}^{(k)}},
  \]
  % TODO: I think we should be more precise here since the elements could be
  % inside different fields. They are not, but this sentence does not indicate
  % that.
  From the Lemma~\ref{lem:mdcf-purely-periodic},
  it follows that the elements of $\hat x^{(k)}$
  are contained in a field $ℚ(λ)$ with degree $[ℚ(λ) : ℚ] ≤ d+1$.
  Since $B^{(k)}$ consists solely of integers, every element in $x$ is contained in the same field $ℚ(λ)$.
  Therefore, they must also be algebraic numbers
  and we have $[ℚ(x₁, …, x_d) : ℚ] ≤ d+1$.
\end{proof}

% TODO: There should be a discussion about the potential for answering
% Hermite's question here... We could use thm:unimodular-algebraic, which links algebraic numbers with a unimodular matrix. Using the multidimensional generalization of Lagrange's theorem, we have a periodic chain
