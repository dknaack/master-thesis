\chapter{Multidimensional Continued Fractions}
\label{ch:mdcf}

% TODO: This needs to be rewritten since we have already introduced a
% representation in the previous chapter on the generalized Euclidean algorithm
For quadratic irrationals, we used continued fractions to represent them as a
periodic sequence of integers.
The continued fractions were constructed using the Euclidean algorithm.
Naturally, we can generalize continued fractions to higher dimensions using the
generalized Euclidean algorithm.
This leads to a concept of Multidimensional Continued Fractions (MCFs), which could
potentially be an answer of Hermite's question.
Since they are based on the generalized Euclidean algorithm,
they extend previous generalizations of continued fractions based on the
Jacobi-Perron algorithm, like bifurcating or ternary continued fractions \cite{Gupta00}.

This chapter introduces the concept of MCFs and discusses their potential as
an answer to Hermite's question.
We begin by defining what they are and deriving many properties similar to
continued fractions.
The chapter contains two main results for MCFs.
The first is that they converge under certain conditions
and the second is that periodic MCFs always consist of algebraic numbers with degree $≤ d+1$.
For the latter, we will first analyze the geometry behind MCFs in the same
style as Klein did for continued fractions.
What is missing from this chapter is the other direction,
that MCFs containing certain algebraic numbers are always periodic.
This will be discussed in more detail in the next chapter.

% ==============================================================================
\section{Construction Using the Generalized Euclidean Algorithm}
% ==============================================================================

% TODO: Why do we need a bottom-up definition? Because the construction only
% associates the integer sequence with a real number, we don't have any way to
% calculate which number it corresponds to.
% Also, the top-down construction gives us no notion of convergents.
The construction of MCFs using the generalized Euclidean algorithm gives us a
top-down definition, where we start with a vector $x$ and derive its
representation using the algorithm.
The continued fraction defined on page~\pageref{def:cont-frac}
use a bottom-up definition:
We begin with the continued fraction $[a₀]$ of a single coefficent
and then we inductively define the continued fraction $[a₀; a₁, …, aₙ]$
based on the smaller continued fraction $[a₁; a₂, …, aₙ]$.
For MCFs, we can similarly derive a bottom-up definition based on the inverse
pivot operation.

Let $x ∈ ℝ^d$ and $a = \floor{x}$.
Suppose that $x' = \mathrm{pivot}_ℓ(x)$ for a given index $ℓ ∈ \{1, …, d\}$.
We can derive $x$ from the vectors $x'$ and $a$ as follows:
By definition,
\[
  x_ℓ' = \frac{1}{x_ℓ - a_ℓ}
  \; \text{ and } \;
  x_i' = \frac{x_i - a_i}{x_ℓ - a_ℓ}
  \; \text{ for all } i ≠ ℓ.
\]
By rearranging these equations, we can calculate $x$ from $x'$ and $a$ using
\[
  x_ℓ = a_ℓ + \frac{1}{x_ℓ'}
  \; \text{ and } \;
  x_i = a_i + \frac{x_i'}{x_ℓ'}
  \; \text{ for all } i ≠ ℓ.
\]
Thus, we have an inverse function of the pivot operation.

The inverse function does not require the index $ℓ$ used in $x' = \mathrm{pivot}_ℓ(x)$.
The reason is that $x_ℓ' = 1/\{x_ℓ\}$ is always the largest element, since $\{x_i\} < 1$ for every element.
So we can derive $ℓ$ from the vector $x'$ by finding the index of the largest element.
Therefore, the inverse function $\mathrm{pivot}^{-1}$ only takes
a vector $x' ∈ ℝ^d$ and a vector $a ∈ ℤ^d$ as input.
It calculates the vector $x$ according to the equations above.
In summary, we have
\[
  \mathrm{pivot}_ℓ(x) = x' \iff \mathrm{pivot}^{-1}(a, x') = x.
\]

Using this inverse operation we can directly derive the bottom-up definition for MCFs.
So far we have only used integer vectors $a ∈ ℤ^d$,
however, in the definition we will allow any real vector, just like with the continued fractions.
Again this is for subsequent lemmas, where we will need rational or even real vectors coefficients.

\begin{definition}
  Given a sequence of $d$-dimensional real vectors $(r^{(n)})_{n ≥ 0}$,
  the \emph{multidimensional continued fraction} $[r^{(0)}; r^{(1)}, …]$ is defined as
  \[
    [r^{(0)}; r^{(1)}, …] = \lim_{n → ∞} [r^{(0)}; r^{(1)}, …, r^{(n)}],
  \]
  where the finite continued fractions $[r^{(0)}; r^{(1)}, …, r^{(n)}]$
  are defined inductively as
  \[
    [r^{(0)}] = r^{(0)},
    \qquad
    [r^{(0)}, r^{(1)}, …, r^{(n)}]
    = \mathrm{pivot}^{-1}\big(r^{(0)}, [r^{(1)}, r^{(2)}, …, r^{(n)}]\big).
  \]
\end{definition}

For the representation to be correct, we require $\max_i r_i^{(n)} ≠ 0$ for $n ≥ 1$.
This is similar to the continued fractions, where only the first value could be zero,
while all subsequent values had to be positive.
For the multidimensional counterpart we only require that the pivot element is not zero.
The other values in the coefficients $r^{(n)}$ can assume any non-negative value, including zero.

\begin{example}
  Consider the MCF $x = [(1,\, 2); (3,\, 2),\, (4,\, 5)]$.
  By definition,
  \begin{align*}
    x & = \mathrm{pivot}^{-1}\Bigl((1,\, 2),\, [(3,\, 2); (3,\, 5)]\Bigr) \\
      & = \mathrm{pivot}^{-1}\Bigl((1,\, 2),\, \mathrm{pivot}^{-1}\bigl((3,\, 2),\, [(3,\, 5)]\bigr)\Bigr) \\
      & = \mathrm{pivot}^{-1}\Bigl((1,\, 2),\, \mathrm{pivot}^{-1}\bigl((3,\, 2),\, (3,\, 5)\bigr)\Bigr).
  \end{align*}
  We start with the inner most pivot operation,
  where the largest element in $(4,\, 5)$ is $5$.
  Therefore, we invert the second element and divide the first element by $5$
  and we add the vector $(3,\, 2)$ to the result, which leads to
  \begin{align*}
    x & = \mathrm{pivot}^{-1}\bigl((1,\, 2),\, (3,\, 2) + (3/5,\, 1/5)\bigr)
        = \mathrm{pivot}^{-1}\bigl((1,\, 2),\, (18/5,\, 11/5)\bigr).
  \end{align*}
  In the next iteration, $18/5$ is the largest element.
  Therefore, we invert of the first element and divide the second element by $18/5$,
  resulting in
  \begin{align*}
    x & = (1,\, 2) + (5/18,\, 11/5 · 5/18) = (23/18,\, 41/18).
  \end{align*}
  Thus, $[(1,\, 2); (3,\, 2),\, (3,\, 5)] = (23/18,\, 41/18)$.
\end{example}

The terminology from one-dimensional continued fractions naturally carry over to its
multidimensional counterpart.
Given an infinite MCF representation~$[r^{(0)}; r^{(1)}, …]$ of a vector $x ∈ ℝ^d$, we define the following:

\begin{itemize}
  \item The \emph{$k$-th convergent} of $x$ is the finite MCF $[r^{(0)}; r^{(1)}, …, r^{(n)}]$.
  \item The \emph{$k$-th complete quotient} is the MCF $[r^{(n)}; r^{(n+1)}, …]$.
  \item The MCF is \emph{eventually periodic} if there exists an index~$n₀ ≥ 0$
    and a period~$k ≥ 1$ such that $aₙ = a_{n+k}$ and $ℓₙ = ℓ_{n+k}$
    for every $n ≥ n₀$.
    The MCF is \emph{purely periodic} if $n₀ = 0$.
\end{itemize}

For the analysis of MCFs,
we begin with two lemmas which generalize Lemma~\ref{lem:cf-nesting} and
Lemma~\vref{lem:cf-wallis}.
The first allows us to merge the last two coefficients of an MCF.
The second gives us a formula for calculating the convergents.

\begin{lemma}
  \label{lem:mdcf-nesting}
  Let $x ∈ ℝ^d$, then
  \[
    [r^{(0)}; r^{(1)}, …, r^{(n)}, x]
    = [r^{(0)}; r^{(1)}, …, r^{(n-1)}, \mathrm{pivot}^{-1}(r^{(n)}, x)]
  \]
\end{lemma}

\begin{proof}
  If $n = 0$, then by definition,
  \[
    [r^{(0)}; x] = \mathrm{pivot}^{-1}(r^{(0)}, [x]) = \mathrm{pivot}^{-1}(r^{(0)}, x) = [\mathrm{pivot}^{-1}(r^{(0)}, x)].
  \]
  Suppose the lemma holds for any $n ≥ 0$, then
  \begin{align*}
    [r^{(0)}; r^{(1)}, …, r^{(n+1)}, x]
    & = \mathrm{pivot}^{-1}(r^{(0)}, [r^{(1)}; r^{(2)}, …, r^{(n+1)}, x]) \\
    & = \mathrm{pivot}^{-1}(r^{(0)}, [r^{(1)}; r^{(2)}, …, r^{(n)}, \mathrm{pivot}^{-1}(r^{(n)}, x)] \\
    & = [r^{(0)}; r^{(1)}, …, r^{(n)}, \mathrm{pivot}^{-1}(r^{(n+1)}, x)]. \qedhere
  \end{align*}
\end{proof}

% TODO: Explain how to derive the sequences
In the lemma for continued fractions,
we defined the convergents of a continued fraction~$pₙ/qₙ$
using a linear recurrence based on the previous two terms~$p_{n-1}/q_{n-1}$ and $p_{n-2}/q_{n-2}$.
For MCFs, we can similarly derive a recursive formula to derive the values of
the convergent vector $(p₁/q, \dots, p_d/q)$ using the previous convergents.
Deriving the sequence is more involved than the one-dimensional case,
since we have an additional pivot index $ℓ$ at each step.

There are two types of sequences:
A sequence of vectors $P_0^{(n)}, P_1^{(n)}, …, P_d^{(n)} ∈ ℤ^{d+1}$ and a sequence
of scalars $Q_0^{(n)}\!,\, Q_1^{(n)}\!,\, …, Q_d^{(n)} ∈ ℤ$.
The initial terms are
\[
  \begin{aligned}
    P_0^{(-1)} & = 0, & P_i^{(-1)} & = e_i, \\
    Q_0^{(-1)} & = 1, & Q_i^{(-1)} & = 0,
  \end{aligned}
\]
where $e_i$ is the $i$-th unit vector.
For the remaining terms,
Let $ℓ$ be the index of the maximum element in the complete quotient $x^{(n)}$.
Then, the next terms in the sequences are:
\[
  \begin{aligned}
    P_ℓ^{(n)} & = P_0^{(n-1)} + P_1^{(n-1)} r_1^{(n)} + ⋯ + P_d^{(n-1)} r_d^{(n)}, &
    P_0^{(n)} & = P_{ℓₙ}^{(n-1)}, \\
    Q_ℓ^{(n)} & = Q_0^{(n-1)} + Q_1^{(n-1)} r_1^{(n)} + ⋯ + Q_d^{(n-1)} r_d^{(n)}, &
    Q_0^{(n)} & = Q_{ℓₙ}^{(n-1)}.
  \end{aligned}
\]
The terms $P_i^{(n)}$ and $Q_i^{(n)}$ where $i ≠ ℓ$ are carried over from the previous iteration,
i.e.
\[
  P_i^{(n)} = P_i^{(n-1)}, Q_i^{(n)} = Q_i^{(n-1)}.
\]

The idea behind these sequences is that they behave like the generalized
Euclidean algorithm, but in reverse.
We can consider the vectors $P_0^{(n)}, P_1^{(n)}, …, P_d^{(n)}$ as the basis,
which is reduced by the algorithm.
The Euclidean algorithm terminates when one vector is an integral combination
of the other vectors, because then the remainder is zero.
The sequence $P_0^{(n)}$ starts with the zero vector,
i.e. when the basis has been fully reduced.
Therefore, $P_0^{(n)}$ represents the remainder $c$ and the vectors $P_1^{(n)},
…, P_d^{(n)}$ represent the basis $B$.
Then, the formula calculates a new vector using an integral combination of the
old vectors and stores it in $P_ℓ^{(n)}$.
This corresponds directly to the modulo and exchange operation of the
generalized Euclidean algorithm.
As the vectors $P_0^{(n)}, P_1^{(n)}, …, P_d^{(n)}$ would grow infinitely, we
divide them by the scalars $Q_0^{(n)}, Q_1^{(n)}, …, Q_d^{(n)}$ to ensure that
they converge to a limit as $n$ increases.

% TODO: Ensure that this is correct for the first index!
\begin{lemma}
  \label{lem:mdcf-wallis}
  Let $r^{(0)}, r^{(1)}, …, r^{(n-1)}, x ∈ ℝ^d$, then
  \[
    [r^{(0)}; r^{(1)}, …, r^{(n-1)}, x]
    = \frac{P_0^{(n-1)} + P_1^{(n-1)} x_1 + ⋯ + P_d^{(n-1)} x_d}{Q_0^{(n-1)} + Q_1^{(n-1)} x_1 + ⋯ + Q_d^{(n-1)} x_d}.
  \]
\end{lemma}

\begin{proof}
  If $n = 0$, then
  \[
    [x]
    = x
    = \frac{x}{1}
    = \frac{0 + e₁ x₁ + ⋯ + e_d x_d}{1 + 0 x₁ + ⋯ + 0 x_d}
    = \frac{P₀^{(0)} + P₁^{(0)} x₁ + ⋯ + P_d^{(0)} x_d}{Q_0^{(0)} + Q_1^{(0)} x₁ + ⋯ + Q_d^{(0)} x_d}.
  \]
  Suppose the lemma holds for $n ≥ 0$,
  we show that it also holds for $n+1$.
  From the previous lemma, it follows that
  \begin{align*}
    [r^{(0)}; r^{(1)}; …, r^{(n)}, x] & = [r^{(0)}; r^{(1)}, …, r^{(n-1)}, \mathrm{pivot}^{-1}(r^{(n)}, x)].
  \end{align*}
  Let $y = \mathrm{pivot}^{-1}(r^{(n)}, x)$ and $ℓ = \argmax_i x_i$.
  By the induction hypothesis,
  \begin{align*}
    [r^{(0)}; r^{(1)}; …, r^{(n)}, x] & = \frac{x_ℓ}{x_ℓ} · \frac{P_0^{(n-1)} + P_1^{(n-1)} y_1 + ⋯ + P_d^{(n-1)} y_d}{Q_0^{(n-1)} + Q_1^{(n-1)} y_1 + ⋯ + Q_d^{(n-1)} y_d},
  \end{align*}
  where the fraction is expanded with $x_ℓ/x_ℓ$ such that the numerator and denominator are each multiplied by $x_ℓ$.
  The numerator can then be simplified as follows:
  \begin{align*}
    & \hphantom{{} = {}} x_ℓ \left( P_0^{(n-1)} + P_ℓ^{(n-1)} y_ℓ + \sum_{i ∉ \{0,ℓ\}} P_i^{(n-1)} y_i \right) \\
    & = x_ℓ \left( P_0^{(n-1)} + P_ℓ^{(n-1)} \left( r_ℓ^{(n)} + \frac{1}{x_ℓ} \right) + \sum_{i ∉ \{0,ℓ\}} P_i^{(n-1)} \left(r_i^{(n)} + \frac{x_i}{x_ℓ} \right) \right) \\
    & = P_0^{(n-1)} x_ℓ + P_ℓ^{(n-1)} r_ℓ^{(n)} x_ℓ + P_ℓ^{(n-1)} + \sum_{i ∉ \{0,ℓ\}} P_i^{(n-1)} r_i^{(n)} x_ℓ + P_i^{(n-1)} x_i \\
    & = \underbrace{\left( P_0^{(n-1)} + P_ℓ^{(n-1)} r_ℓ^{(n)} + \sum_{i ∉ \{0,ℓ\}} P_i^{(n-1)} r_i^{(n)} \right)}_{P_ℓ^{(n)}} x_ℓ
      + \underbrace{P_ℓ^{(n-1)}}_{P_0^{(n)}}
      + \sum_{i ∉ \{0,ℓ\}} \underbrace{P_i^{(n)}}_{P_i^{(n)}} x_i \\
    & = P_0^{(n)} + P_1^{(n)} x_1 + ⋯ + P_d^{(n)} x_d.
  \end{align*}
  The simplification for the denominator is identical.
  Therefore,
  \[
    [r^{(0)}; r^{(1)}, …, r^{(n)}, x]
    = \frac{P_0^{(n)} + P_1^{(n)} x_1 + ⋯ + P_d^{(n)} x_d}{Q_0^{(n)} + Q_1^{(n)} x_1 + ⋯ + Q_d^{(n)} x_d}.
    \qedhere
  \]
\end{proof}

% ==============================================================================
\section{Infinite Multidimensional Continued Fractions and their Convergence}
% ==============================================================================

% TODO: I don't like how we say that the requirement is from Perron, when it's
% not really from him, but just based on his version.
% TODO: The indices here are wrong...
So far in our analysis, we have implicitly assumed that the MCF $[a^{(0)}; a^{(1)}, a^{(2)} …]$
constructed using the generalized Euclidean algorithm always converges to the
original input vector $x ∈ ℝ^d$.
The aim of this section is to show that the convergents actually live up to
their name and converge towards the vector $x$ as $n$ increases.

Let $x ∈ ℝ$ and let $[a^{(0)}; a^{(1)}, …]$ be its MCF expansion,
constructed using the generalized Euclidean algorithm.
The vector $x^{(n)}$ denotes the $n$-th complete quotient of $x$
and $r^{(n)}$ denotes the $n$-th convergent.
We say that $ℓ ∈ \{1, …, d\}$ is the \emph{pivot index} of $x^{(n)}$,
if $x^{(n)} = \mathrm{pivot}_ℓ(x^{(n-1)})$.
With this index $ℓ$, the $n$-th convergent is defined as
\[
  r^{(n)}
  = (r_1^{(n)}, …, r_d^{(n)})
  = \left( \frac{P_{1ℓ}^{(n)}}{Q_ℓ^{(n)}}, \dots, \frac{P_{dℓ}^{(n)}}{Q_ℓ^{(n)}} \right)
  = \frac{P_ℓ^{(n)}}{Q_ℓ^{(n)}}.
\]
We say that $r^{(n)}$ converges towards $x$ if
\[
  x_i = \lim_{n → ∞} r_i^{(n)} \text{ for every } i ∈ \{1, …, d\}.
\]
The proof for this is based on Perron's original proof \cite{Perron07} for the
convergence of his algorithm.
For the proof we need three additional requirements:
\begin{enumerate}
  \item
    For every $n ≥ 0$,
    \[
      0 < \frac{1}{a_ℓ^{(n)}} ≤ A
      \quad \text{ and } \quad
      0 ≤ \frac{a_i^{(n)}}{a_ℓ^{(n)}} ≤ A \quad \text{ for every } i ≠ ℓ,
    \]
    where $ℓ$ is the index of the largest element in the complete quotient $x^{(n)}$.
  \item
    During the construction of the MCF,
    every index $ℓ ∈ \{1, …, d\}$ is used infinitely often.
    Formally, for every $ℓ ∈ \{1, …, d\}$ and $N ≥ 0$,
    we can find an index $n ≥ N$ such that $ℓ$ is the pivot index of $x^{(n)}$.
  \item
    The distance between the same index is bounded by some constant $L$,
    i.e. for every $n ≥ 0$ we can find a index $m ∈ \{n+1, …, n+L\}$ such that
    the pivot indices of $x^{(m)}$ and $x^{(n)}$ are the same.
\end{enumerate}

The first requirement is already satisfied by the generalized Euclidean algorithm for $A = 1$.
Because $x_ℓ^{(n)}$ is the largest element
and the integer part of every element in the complete quotient is determined by $a_i^{(n)}$,
the element $a_ℓ^{(n)}$ must also be the largest element in $a^{(n)}$.
Furthermore $a_ℓ^{(n)}$ cannot be zero due to the requirements.
Hence, this condition is satisfied for $A = 1$.
Nevertheless,
this condition can be used when replacing the floor function with a different function.
If one can guarantee that the new function satisfies the first requirement,
then the convergence will still hold.

The last two requirements are specifically for MCFs.
The vector $r^{(n)}$ is only one possible convergent out of several.
If $n$ is large enough, then we can consider the other vectors
$P_i^{(n)}/Q_i^{(n)}$ with $i ≠ ℓ$ as convergent vectors,
since $x_i^{(m)}$ must have been the largest element at some index $m < n$.
We will call $r^{(n)}$ the \emph{primary convergent} and the other ones
\emph{secondary convergents}.
When updating the secondary convergents,
we exchange $P_0^{(n)} / Q_0^{(n)}$ with $P_ℓ^{(n)}/Q_ℓ^{(n)}$
and replace  $P_ℓ^{(n)}/Q_ℓ^{(n)}$ with a new vector.
Thus, we only move one of the secondary convergents.
The second requirement guarantees that we move every secondary convergent
and the last requirement guarantees that we have moved every convergent after at most $L$ iterations.

\begin{example}
  Consider the MCF $x = [(2, 1); \overline{(2, 1)}]$,
  where the vector $(2, 1)$ repeats periodically.
  This MCF does not meet the requirements for this section.
  In this case, the first complete quotient is $x^{(1)}$, and the pivot index is $\ell = 1$,
  since the coefficient $a^{(1)} = (2, 1)$ determines the integer part
  of each coordinate in $x^{(1)}$, and $2$ is the largest entry.
  The following complete quotient $x^{(2)}$ only affects the fractional part
  of each coordinate, so the first coordinate continues to be the pivot.

  However, this violates the second requirement of the proof,
  which states that every index $\ell \in \{1, \dots, d\}$ must occur
  as a pivot index infinitely often.
  In this example, the pivot index is always $\ell = 1$,
  so the other index (in this case, $2$) is never selected.
  Therefore, the convergence proof presented in this section does not apply to this example.
\end{example}

Since we use the Euclidean algorithm to construct an MCF,
we can assume that all vectors $a^{(n)}$ are positive integers,
including the initial coefficient $a^{(0)}$.
Although the first coefficient could be negative,
the second coefficient is always positive.
If we can prove the convergence for the second complete quotient $x^{(1)} = [a^{(1)}; a^{(2)}, …]$,
then this implies the convergence for the whole MCF.
Thus, it suffices to show the convergence for the second complete quotient,
which is positive.
Finally, we assume that the target vector $x = (x₁, …, x_d)$ is irrational,
which means that the MCF is infinite.

\begin{lemma}
  \label{lem:conv-conv}
  There exists an integer $N ≥ 0$ such that for all $n ≥ N$,
  there are nonnegative coefficients $λ₀^{(n)}, λ₁^{(n)}, …, λ_d^{(n)}$
  satisfying $λ₀^{(n)} + λ₁^{(n)} + ⋯ + λ_d^{(n)} = 1$ and
  \[
    r_i^{(n)} = λ₀^{(n)} \frac{P_{i0}^{(n-1)}}{Q_0^{(n-1)}} + λ₁^{(n)} \frac{P_{i1}^{(n-1)}}{Q_1^{(n-1)}} + ⋯ + λ_d^{(n)} \frac{P_{id}^{(n-1)}}{Q_d^{(n-1)}}.
  \]
\end{lemma}

\begin{proof}
  We choose $N$ such that every index in the construction has been used at least once.
  In particular, we choose $N$ such that all denominators $Q_i^{(n-1)}$ are not zero.
  Let $ℓ$ be the index of the largest element in $x^{(n)}$.
  By Lemma~\ref{lem:mdcf-wallis}, we can calculate $P_{iℓ}^{(n)}$ using the previous values as follows:
  \begin{align*}
    P_{iℓ}^{(n)} = \sum_{k = 1}^d P_{ik}^{(n-1)} a_k^{(n)} + P_{i0}^{(n-1)}.
  \end{align*}
  Dividing by $Q_ℓ^{(n)}$ gives us
  \begin{align*}
    \frac{P_{iℓ}^{(n)}}{Q_ℓ^{(n)}} = \sum_{k = 1}^d \frac{P_{ik}^{(n-1)}}{Q_ℓ^{(n)}} a_k^{(n)} + \frac{P_{i0}^{(n-1)}}{Q_ℓ^{(n)}}.
  \end{align*}
  Using the coefficients $λ_k^{(n)} = a_k^{(n)} \frac{Q_k^{(n-1)}}{Q_ℓ^{(n)}}$ for $k ∈ \{1, …, d\}$
  and $λ₀^{(n)} = \frac{Q_0^{(n-1)}}{Q_ℓ^{(n)}}$,
  we can reformulate the convergent $r^{(n)}$ as
  \[
    λ₀^{(n)} \frac{P_{i0}^{(n-1)}}{Q_0^{(n-1)}} + λ₁^{(n)} \frac{P_{i1}^{(n-1)}}{Q_1^{(n-1)}} + ⋯ + λ_d^{(n)} \frac{P_{id}^{(n-1)}}{Q_d^{(n-1)}}.
  \]
  Because $N$ was chosen large enough such that every index has occurred at least once,
  the denominators $Q_i^{(n-1)}$ cannot be zero.
  Therefore, this is a valid representation of the convergent $r_i^{(n)}$.
  For the coefficients themselves, we require $λ₀ + λ₁ + ⋯ + λ_d = 1$ and $0 ≤ λᵢ ≤ 1$ for every index $i$.
  The first property follows from the definition of $Q_ℓ^{(n)}$:
  \[
    Q_ℓ^{(n)} = Q_0^{(n-1)} + Q_1^{(n-1)} a_1^{(n)} + ⋯ + Q_d^{(n-1)} a_d^{(n)}
  \]
  which is equivalent to
  \[
    1 = \frac{Q_0^{(n-1)}}{Q_ℓ^{(n)}} + \frac{Q_1^{(n-1)}}{Q_ℓ^{(n)}} a_1^{(n)} + ⋯ + \frac{Q_d^{(n-1)}}{Q_ℓ^{(n)}} a_d^{(n)} = λ₀^{(n)} + λ₁^{(n)} + ⋯ + λ_d^{(n)}.
  \]
  The second property follows from the fact that every vector $a^{(n)}$ is nonnegative.
  Therefore, the denominator $Q_ℓ^{(n)}$ is always less than or equal to $a_i^{(n)} Q_i^{(n-1)}$ and
  $λ_i$ is always bounded between $0$ and $1$.
\end{proof}

The lemma shows that the next convergent lies inside the convex hull of the secondary convergents.
We enclose the entire hull inside an axis-aligned bounding box
and we show that this box converges to a single point,
which implies the convergence of the original convergent sequence $r^{(n)}$.
At each iteration, the bounding box is characterized by its minimum and maximum corner,
which are defined as $s^{(n)} = (s_1^{(n)}, …, s_d^{(n)})$ and $t^{(n)} = (t_1^{(n)}, …, t_d^{(n)})$ with
\[
  s_i^{(n)} = \min\left\{\frac{P_{i0}^{(n)}}{Q_0^{(n)}}, \frac{P_{i1}^{(n)}}{Q_1^{(n)}}, …, \frac{P_{id}^{(n)}}{Q_d^{(n)}}\right\}
\]
and
\[
  t_i^{(n)} = \max\left\{\frac{P_{i0}^{(n)}}{Q_0^{(n)}}, \frac{P_{i1}^{(n)}}{Q_1^{(n)}}, …, \frac{P_{id}^{(n)}}{Q_d^{(n)}}\right\}.
\]
The primary convergent $r^{(n)}$ lies inside the box,
since it is one of the secondary convergent vectors
used in the definition of $s^{(n)}$ and $t^{(n)}$.
Therefore, if $s^{(n)}$ and $t^{(n)}$ converge,
then the sequence $r^{(n)}$ must converge, too.

\begin{lemma}
  The sequences $s_i^{(n)}$ and $t_i^{(n)}$ converge.
\end{lemma}

\begin{proof}
  We show that the sequences are monotone and bounded, which implies convergence.
  We begin with $s^{(n)}$ and show that this sequence is non-decreasing.
  The sequence is non-decreasing if every secondary convergent at iteration $n$
  is greater than the previous minimum $s^{(n-1)}$.
  Let $ℓ$ be the pivot index in iteration $n$.
  From the previous iteration, we already have for every $j ≠ ℓ$:
  \[
    \frac{P_{ij}^{(n)}}{Q_j^{(n)}} = \frac{P_{ij}^{(n-1)}}{Q_j^{(n-1)}} ≥ s_i^{(n-1)}.
  \]
  We can bound the primary convergent $r^{(n)}$ using Lemma~\ref{lem:conv-conv}, since
  \begin{align*}
    \frac{P_{iℓ}^{(n)}}{Q_ℓ^{(n)}}
    & = λ₀^{(n)} \frac{P_{i0}^{(n-1)}}{Q_0^{(n-1)}} + λ₁^{(n)} \frac{P_{i1}^{(n-1)}}{Q_1^{(n-1)}} + ⋯ + λ_d^{(n)} \frac{P_{id}^{(n-1)}}{Q_d^{(n-1)}} \\
    & ≥ λ₀^{(n)} s_i^{(n-1)} + λ₁^{(n)} s_i^{(n-1)} + ⋯ + λ_d^{(n)} s_i^{(n-1)}
      = s_i^{(n-1)}.
  \end{align*}
  Thus, $s_i^{(n)} ≥ s_i^{(n-1)}$ and $s^{(n)}$ is non-decreasing.
  We can show $t_i^{(n)} ≤ t_i^{(n-1)}$ by bounding the convergents from above using a similar argument.
  Futhermore, $s_i^{(n)} ≤ t_i^{(n)}$ for every index $n ≥ 0$.
  Thus, both sequences must converge.
\end{proof}

In order to show that the sequences $s^{(n)}$ and $t^{(n)}$ are actually
converging to the same limit, we first need the following crucial lemma about the
coefficients $λ₀^{(n)}, λ₁^{(n)}, …, λ_d^{(n)}$ from Lemma~\ref{lem:conv-conv}.
% TODO: Actually add the figure here. Or do we wanna use the combined one, which is already here?
%The main idea behind the lemma is illustrated in Figure~\ref{fig:lambda-pos}.
It states that one of the coefficients is always greater than some constant
independently of $n$ and importantly that coefficient is for the previous convergent $r^{(n-1)}$.
From the recurrence for the convergents,
it follows that we always carry over the primary convergent $r^{(n-1)}$ as one
of the secondary convergents in the next iteration.
Therefore, we cannot change its position.
However, we can change one of the other convergents.
But the area available for the next convergent $r^{(n)}$ is restricted by this lemma
such that the convex hull always shrinks by a constant amount.

% TODO: We could maybe save this by only stating that this occurs infinitely often.
% I think so, because if this cannot happen less than $d$ times. Otherwise, we must have a duplicate index.
% -> This should also work if we're doing this for any index.
\begin{lemma}
  \label{lem:lambda-pos}
  Let $ℓ$ be the pivot index in $x^{(n)}$,
  then $λ_ℓ^{(n)} > 1/C$ for some integer $C > 0$.
\end{lemma}

% TODO: Show that it is not equal to 1!
\begin{proof}
  The ratio between the coefficients $λ_i^{(n)}$ and $λ_ℓ^{(n)}$ is
  \begin{equation}
    \label{eq:lambda-ratio}
    \frac{λ_i^{(n)}}{λ_ℓ^{(n)}}
    = \frac{a_i^{(n)}}{a_ℓ^{(n)}} · \frac{Q_i^{(n-1)}}{Q_ℓ^{(n-1)}}
    ≤ A · \frac{Q_i^{(n-1)}}{Q_ℓ^{(n-1)}}.
  \end{equation}
  If $Q_i^{(n-1)} < Q_ℓ^{(n-1)}$,
  then we can guarantee that $λ_ℓ^{(n)} ≥ 1/C$.
  For $Q_0^{(n-1)} = Q_ℓ^{(n-2)}$, this is straightforward.
  But for the other values the issue is that $Q_i^{(n-1)}$ might be larger than $Q_ℓ^{(n-1)}$,
  if $i$ is the pivot index, for example.

  We solve this issue using the initial requirements.
  Specifically, the third requirement,
  which states that after at most $L$ iterations,
  we must have used $ℓ$ as the pivot index again.
  Therefore, there must have been some index $m$ between $n$ and $n - L$
  where we used $ℓ = \argmax_i x_i^{(m)}$ such that $Q_ℓ^{(n-1)} = Q_ℓ^{(m)}$.
  If $x^{(m)} = \mathrm{pivot}_ℓ(x^{(m-1)})$,
  then we must have $x_ℓ^{(m+1)} = 1/\{x_ℓ^{(m)}\} > 1$
  and therefore the integer part $a_ℓ^{(m+1)}$ must be at least $1$.
  Furthermore, if $k$ is the pivot index in the next iteration $m+1$,
  then
  \[
    Q_k^{(m+1)}
    = Q_0^{(m)} + Q_1^{(m)} a_1^{(m+1)} + ⋯ + Q_d^{(m)} a_d^{(m+1)}
    ≥ a_ℓ^{(m+1)} Q_ℓ^{(m)}
    ≥ \frac{1}{A} Q_ℓ^{(m)}.
  \]
  We can repeat this step for every pivot index from $m$ to $n$
  tracing the bound back from $Q_ℓ^{(m)}$ to $Q_i^{(n-1)}$.
  This path consists of at most $L$ steps.
  Thus, we can bound $Q_i^{(n-1)}$ from below by $Q_ℓ^{(n-1)}$ according to
  \[
    Q_i^{(n-1)} ≥ \frac{1}{A^L} Q_ℓ^{(m)} = \frac{1}{A^L} Q_ℓ^{(n-1)},
  \]
  which we can finally use to bound the fraction $Q_i^{(n-1)}/Q_ℓ^{(n-1)}$
  from Equation~\ref{eq:lambda-ratio}.
  The equation leads to the bound $λᵢ^{(n)} ≤ A^{L-1} λ_ℓ^{(n)}$,
  from which it follows that
  \[
    1 = λ₀^{(n)} + λ₁^{(n)} + ⋯ + λ_d^{(n)} ≤ λ_ℓ^{(n)} (1 + dA^{L-1}).
  \]
  Finally, if we set $C = 1 + dA^{L-1} > 0$, then $λ_ℓ^{(n)} > 1/C$.
\end{proof}

\begin{figure}[tbp]
  \centering
  \includestandalone{figures/convergence}
  \caption{
    Illustration of the proof for the convergence of MCFs.
    The points $r^{(i)}, r^{(j)}$ and $r^{(k)}$ represent the convergents and $x$ is
    the vector, which is approximated by them.
    If $r^{(k)}$ is the convergent of the current iteration,
    then either $r^{(i)}$ or $r^{(j)}$ has to be moved in the next iteration.
    However, neither can go in the red portion, since $λ_k^{(n)} > 1/C$.
  }
  \label{fig:convergence}
\end{figure}

If the sequences $s^{(n)}$ and $t^{(n)}$ converge to the same limit,
then that means that the bounding box shrinks to a point.
Therefore, the convergent $r^{(n)}$, which is inside this box, converges to the
same point.
However, the box could also turn out to be nonempty,
if the sequences approach different limits, i.e.
\[
  \lim_{n → ∞} s_i^{(n)} < \lim_{n → ∞} t_i^{(n)}.
\]
But the previous lemma contradicts this assumption.
The area of the convex hull always shrinks by a at least a constant proportion.
So if the sequences would approach different limits, then we can always find a
point at which all convergents step over the box and all of them are contained
in the supposed limit.
This is the main idea behind the following proof.

% TODO: Should we add the requirements, like every index occurs infinitely
% often (but the correct version)?
\begin{lemma}
  \label{lem:min-max-conv}
  The minimum $s_i^{(n)}$ and maximum $t_i^{(n)}$ are converging to the same
  limit.
\end{lemma}

\begin{proof}
  Let $s_i = \lim_{n → ∞} s_i^{(n)}$
  and $t_i = \lim_{n → ∞} t_i^{(n)}$ for every $i ≤ d$.
  Suppose $s_i < t_i$.
  For the minimum~$s_i$, there must exist an $ε > 0$ and an index $N ≥ 0$ such
  that for every $n ≥ N$,
  \[
    \frac{P_{ij}^{(n)}}{Q_j^{(n)}} ≥ s_i^{(n)} > s_i - ε.
  \]
  Let $ℓ$ be the index of the largest element in the previous complete quotient $x^{(n-1)}$.
  Since the limit $s_i - ε$ bounds the secondary convergents,
  we can use this to bound the primary convergent
  %$Q_i^{(n-1)} = Q_i^{(n-2)}$ and $Q_k^{(n-1)} = Q_0^{(n-2)} + Q_1^{(n-2)} a_1^{(n-1)} + ⋯ + Q_d^{(n-2)} a_d^{(n-1)}$. % TODO: Why was this here?
  \begin{align*}
    r_i^{(n)}
    & = λ₀^{(n)} \frac{P_{i0}^{(n-1)}}{Q_0^{(n-1)}} + λ₁^{(n)} \frac{P_{i1}^{(n-1)}}{Q_1^{(n-1)}} + ⋯ + λ_d^{(n)} \frac{P_{id}^{(n-1)}}{Q_d^{(n-1)}} \\
    & > λ_ℓ^{(n)} \frac{P_{iℓ}^{(n-1)}}{Q_ℓ^{(n-1)}} + \sum_{i ≠ ℓ} λ_i^{(n)} (s_i - ε) \\
    & = λ_ℓ^{(n)} r_i^{(n-1)} + (1 - λ_ℓ^{(n)}) (s_i - ε),
  \end{align*}
  or equivalently
  \begin{align*}
    r_i^{(n)} - s_i > λ_ℓ^{(n)} \left( r_i^{(n-1)} - s_i \right) - ε.
  \end{align*}
  Lemma~\ref{lem:lambda-pos} tells us that there is a positive constant $C$
  which bounds $λ_ℓ^{(n)}$ from below.
  It follows that
  \begin{align*}
    r_i^{(n)} - s_i > \frac{1}{C} \left( r_i^{(n-1)} - s_i \right) - ε
  \end{align*}
  for some constant $C > 0$.
  This inequality holds for all $n ≥ N$.
  Therefore, we can advance $n$ to some point $n + k$
  such that
  \begin{align*}
    r_i^{(n+k)} - s_i
    & > \frac{1}{C} \left( r_i^{(n+k-1)} - s_i \right) - ε \\
    & > \frac{1}{C} \left(\frac{1}{C} \left( r_i^{(n+k-2)} - s_i \right) - ε\right) - ε \\
    & = \frac{1}{C^2} \left(r_i^{(n+k-2)} - s_i \right) - ε\left(1 + \frac{1}{C}\right) \\
    & \, ⋮ \\
    & > \frac{1}{C^k} \left( r_i^{(n-1)} - s_i \right) - ε\left( \frac{1}{C} + \frac{1}{C^2} + ⋯ + \frac{1}{C^{k-1}} \right).
  \end{align*}
  Since every index occurs infinitely often,
  we can find one index $n$ where $r_i^{(n-1)} ≤ t_i$
  and another index $n+k$ where $r_i^{(n+k)} ≥ s_i$.
  Thus,
  \begin{align*}
    0 > \frac{1}{C^k} \left( t_i - s_i \right) - ε\left( \frac{1}{C} + \frac{1}{C^2} + ⋯ + \frac{1}{C^{k-1}} \right).
  \end{align*}
  But $ε$ can be chosen arbitrarily small,
  which is a contradiction to the fact that $t_i - s_i > 0$.
  Therefore, $t_i$ and $s_i$ converge to the same limit.
\end{proof}

We have shown that $s^{(n)}$ and $t^{(n)}$ converge to the same limit
and that $r^{(n)}$ therefore also converges to that limit.
What remains to be shown is what they converge to,
which is the original vector $x$ used for construction of the MCF.

% TODO: Fix statement, i.e. ℓₙ no longer exists...
\begin{theorem}
  \label{thm:mdcf-conv}
  The sequence $r^{(n)}$ converges to $x$.
\end{theorem}

% TODO: We should improve the last section of this proof,
% because I don't think this is correctly showing that it converges to the same
% limit. Or rather, we're already assuming that we are approaching x_i in the
% limit.
\begin{proof}
  Let $x^{(n)}$ denote the $n$-th complete quotient of $x$.
  By Lemma~\ref{lem:mdcf-wallis}, we can represent each element in $x$ as
  \[
    x_i = \frac{P_{i0}^{(n-1)} + P_{i1}^{(n-1)} x_1^{(n)} + ⋯ + P_{id}^{(n-1)} x_d^{(n)}}{Q_{i0}^{(n-1)} + Q_{i1}^{(n-1)} x_1^{(n)} + ⋯ + Q_{id}^{(n-1)} x_d^{(n)}}.
  \]
  Using a similar argument as in Lemma~\ref{lem:conv-conv}, we can represent this
  as a convex combination
  \begin{align*}
    x_i = μ₀^{(n)} \frac{P_{i0}^{(n-1)}}{Q_0^{(n-1)}}  + μ₁^{(n)} \frac{P_{i1}^{(n-1)}}{Q_1^{(n-1)}} + μ_d^{(n)} \frac{P_{id}^{(n-1)}}{Q_d^{(n-1)}}
  \intertext{with}
    μ_i^{(n)} = x_i^{(n)} \frac{Q_i^{(n-1)}}{Q_0^{(n-1)} + Q_d^{(n)} x_1^{(n)} + ⋯ + Q_d^{(n-1)} x_d^{(n)}}.
  \end{align*}
  From the previous lemma, we know that $r^{(n)}$ converges to some limit $x' ∈ ℝ^d$.
  Since every index occurs infinitely often,
  we can find an index $m ≤ n - 1$ such that the primary convergent $r_i^{(m)}$ is
  \[
    \frac{P_{ij}^{(n-1)}}{Q_j^{(n-1)}} = \frac{P_{ij}^{(m)}}{Q_j^{(m)}}.
  \]
  As $n$ increases there are infinitely many such convergents, so each term converges to $x_i'$.
  Thus, for each secondary convergent there are sufficiently small values $ε₀, ε₁, …, ε_d$ such that
  \begin{align*}
    x_i
    & = μ₀^{(n)} \frac{P_{i0}^{(n-1)}}{Q_0^{(n-1)}}  + μ₁^{(n)} \frac{P_{i1}^{(n-1)}}{Q_1^{(n-1)}} + μ_d^{(n)} \frac{P_{id}^{(n-1)}}{Q_d^{(n-1)}} \\
    & = μ₀^{(n)} (x_i' - ε₀) + μ₁^{(n)} (x_i' - ε₁) + ⋯ + μ_d^{(n)} (x_d' - ε_d) \\
    & = x_i' - (μ₀^{(n)} ε₀ + μ₁^{(n)} ε₁ + ⋯ + μ_d^{(n)} ε_d).
  \end{align*}
  However, as $n$ increases the values $εᵢ$ must become arbitrarily small
  and because the coefficients $μ₀^{(n)}, μ₁^{(n)}, …, μ_d^{(n)}$ all lie between $0$ and $1$,
  we can conclude that $x_i = x_i'$.
\end{proof}

One important example where this theorem applies is for periodic MCFs,
where the period contains every index as a pivot index.
Since the period is constant,
the distance between the same pivot indices is also constant.
Thus, they satisfy the requirements of this theorem.
Besides periodic MCFs, the theorem also includes other JPA-like algorithms.
For example, an algorithm may construct an MCF based on a fixed list of indices $[ℓ₁, ℓ₂, …, ℓₘ]$,
which is repeated throughout the construction.
If this list contains every possible index,
then this theorem would guarantee the convergence.

% ==============================================================================
\section{Geometrical Interpretation Based on Projective Spaces}
\label{sec:mdcf-geometry}
% ==============================================================================

% TODO: I'm not sold on the square brackets. With the list notation for the
% continued fraction, they're kind of ambiguous. Maybe we should just switch to
% regular parentheses instead.
In the geometrical interpretation of continued fractions,
each convergent $pₙ/qₙ$ is represented as a two-dimensional vector $(pₙ, qₙ)$.
These vectors approach an irrational line spanned by the vector $(1, α)$
where $α$ is some irrational number.
For the generalization to multidimensional continued fractions,
each convergent, which is a $d$-dimensional rational vector,
as a $(d+1)$-dimensional integer vector.
Specifically, given a convergent $r^{(n)} = (p₁/q₁, …, p_d/q_d) ∈ ℚ^d$,
we first find a common denominator $(p₁'/q, …, p_d'/q)$ and
then we map it to the vector $\hat r = (q, p₁', …, p_d') ∈ ℤ^{d+1}$.
Similarly, if we have a vector $(x₀, x₁, …, x_d) ∈ ℤ^{d+1}$,
then we map it back to $(x₁/x₀, …, x_d/x₀) ∈ ℚ^d$.

In this space, the representation for a particular convergent is not unique,
there can be multiple integer vectors representing the same convergent.
For example, if we have a vector $r ∈ ℤ^{d+1}$ for a convergent,
then we can multiply with some scalar $λ ∈ ℤ$ and get a new vector $r' = λ r$
which represents the same convergent.
This is because the scalar is eliminated when mapping it back to the rational vector:
\[
  λ (c₀, c₁, …, c_d)
  ↦ \left(\frac{λ c₁}{λ c₀}, …, \frac{λ c_d}{λ c_0} \right)
  = \left(\frac{c₁}{c₀}, …, \frac{c_d}{c_0} \right).
\]

We can extend this to any real vector in $ℝ^{d+1}$:
Two nonzero vectors $a, b ∈ ℝ^{d+1}$ are equivalent,
denoted as $a \sim b$, if $a = λ b$ for some scalar $λ ∈ ℝ$.
This relation then defines the equivalence class of an element $a ∈ ℝ^{d+1}$ as
\[
  [a] = \mathrm{span}(a) = \{ λ a \mid λ ∈ ℝ, λ ≠ 0 \}.
\]
Formally, this is known as a real \emph{projective space}, denoted as $\mathbb{RP}^d$.
It is the set of equivalence classes in $ℝ^{d+1} \setminus \{0\}$ defined by the
equivalence relation $\sim$.
An element $x$ of this space is denoted as $[x₀, x₁, …, x_d]$,
where the square brackets indicate that this element is an equivalence
class.
In summary, we have the following mappings from $ℝ^d$ to $\mathbb{RP}^d$
and vice-versa:

\begin{center}
  \begin{tikzpicture}
    \matrix[
      column sep=2cm,
      nodes={text width=3cm, align=center},
    ] {
      \node (L0) {$\mathbb{R}^d$}; &
      \node (R0) {$\mathbb{RP}^d$}; \\
      \node (L1) {$(x₁, …, x_d)$}; &
      \node (R1) {$[1, x₁, …, x_d]$}; \\
      \node (L2) {$(x₁/x₀, …, x_d/x₀)$}; &
      \node (R2) {$[x₀, x₁, …, x_d]$}; \\
    };

    \draw[->] (L1) -- node[above] {} (R1);
    \draw[<-] (L2) -- node[above] {} (R2);
  \end{tikzpicture}
\end{center}

\begin{figure}[tbp]
  \centering
  \includestandalone{figures/projective-space}
  \caption{
    The convergents as vectors in a $d$-dimensional projective space.
    The ordinary convergents are projections at the $x₀ = 1$ plane.
  }
  \label{fig:projective-space}
\end{figure}

Next, we consider the pivot operation in a projective space.
Before we had to differentiate to cases to define the pivot operation,
now the pivot operation is just a linear operation on the projective coordinates.
For example, consider the vector $[1, x₁, x₂]$ and suppose that $0 ≤ x₁, x₂ < 1$.
A pivot operation with $ℓ = 1$ would result in the vector $[1, 1/x₁, x₂/x₁]$.
This vector is equivalent to $[x₁, 1, x₂]$.
Therefore, we can reformulate this operation as a coordinate swap of $x_ℓ$ with
the new coordinate $x₀$:
\[
  \begin{bmatrix}
    0 & 1 & 0 \\
    1 & 0 & 0 \\
    0 & 0 & 1 \\
  \end{bmatrix}
  ·
  \begin{bmatrix} 1 \\ x₁ \\ x₂ \\ \end{bmatrix}
  =
  \begin{bmatrix} x₁ \\ 1 \\ x₂ \\ \end{bmatrix}
  =
  \begin{bmatrix} 1 \\ 1/x₁ \\ x₂/x₂ \\ \end{bmatrix}.
\]
If $x₁$ and $x₂$ have a nonzero integer part,
then we first have to subtract this part from the vector $x$.
In the projective space, this is equivalent to a series of skew operations:
\[
  \begin{bmatrix}
    1 & 0 & 0 \\
    -\floor{x₁} & 1 & 0 \\
    0 & 0 & 1 \\
  \end{bmatrix}
  ·
  \begin{bmatrix}
    1 & 0 & 0 \\
    0 & 1 & 0 \\
    -\floor{x₂} & 0 & 1 \\
  \end{bmatrix}
  ·
  \begin{bmatrix} 1 \\ x₁ \\ x₂ \\ \end{bmatrix}
  =
  \begin{bmatrix} 1 \\ x₁ - \floor{x₁} \\ x₂ - \floor{x₂} \\ \end{bmatrix}.
\]
In general,
let $S(a)$ denote the skew matrix by a vector $a ∈ ℝ^d$,
i.e. the identity matrix with zeros in the first column swapped with $a$,
and let $R(ℓ)$ denote the permutation matrix,
which swaps $x_ℓ$ with $x_0$.
Then, we can define the pivot operation as
\[
  \mathrm{pivot}_ℓ(x) = R(ℓ) S(-\floor{x}) \hat x,
\]
where $\hat x = [1, x₁, …, x_d]$.

Importantly, we can invert each matrix.
For the matrix $S(a)$, we simply skew in the opposite direction
and the matrix $R(ℓ)$ is its own inverse, since swapping the same coordinate
twice yields the same vector.
Therefore, the whole operation can be easily reversed by inverting the matrix.
This is the equivalent of the inverse pivot operation in the projective space $\mathbb{RP}^d$.
Thus, we can reformulate MCFs as a series of matrix multiplications.
The projective definition of an MCF can be written as
\[
  [a^{(0)}] = \hat a^{(0)}, \qquad
  [a^{(0)}; a^{(1)}, …, a^{(n)}] = S(a₀) · R(ℓ) · [a^{(1)}; a^{(2)}, …, a^{(n)}],
\]
where $ℓ$ is the pivot index of $[a^{(1)}; a^{(2)}, …, a^{(n)}]$
and $\hat a^{(0)} = [1, a_1^{(0)}, …, a_d^{(0)}]$.

We can also use the projective space to dramatically simplify Lemma~\ref{lem:mdcf-wallis}.
Instead of two different sequences $P_i^{(n)}$ and $Q_i^{(n)}$, we simplify it to a single matrix sequence $(B^{(n)})_{n ≥ 0}$.
Each matrix $B^{(n)}$ consists of the column vectors $B₀^{(n)}, B₁^{(n)}, …, B_d^{(n)}$.
The sequence begins with $B^{(0)} = I_d$
and the remaining terms are calculated according to the recurrence
\begin{align*}
  B_ℓ^{(n)} = B^{(n-1)} \hat a^{(n)},
  \qquad B_i^{(n)} = B_i^{(n-1)},
  \qquad B_0^{(n)} = B_ℓ^{(n-1)},
\end{align*}
where $ℓ$ is the pivot index and $\hat a^{(n)} = [1, a_1^{(n)}, …, a_d^{(n)}]$.
By construction, $B^{(n)}$ is the combined matrix of the original sequences
$P_i^{(n)}$ and $Q_i^{(n)}$ defined for Lemma~\vref{lem:mdcf-wallis}:
\[
  B^{(n)} = \begin{bmatrix}
    Q_0^{(n)} & Q_1^{(n)} & ⋯ & Q_d^{(n)} \\
    P_0^{(n)} & P_1^{(n)} & ⋯ & P_d^{(n)} \\
  \end{bmatrix}.
\]
In fact, we can prove an equivalent statement from this lemma using the new sequence.

\begin{lemma}
  \label{lem:mdcf-wallis'}
  Let $x ∈ ℝ^d$ and $\hat x = (1, x₁, …, x_d)$, then
  \[
    [r^{(0)}; r^{(1)}, …, r^{(n-1)}, x] \sim B^{(n-1)} \hat x.
  \]
\end{lemma}

% TODO
\begin{proof}
  By construction of $B^{(n-1)}$, we have
  \begin{align*}
    B^{(n-1)} \hat x
    & = B_0^{(n-1)} \hat x_0 + B_1^{(n-1)} \hat x_1 + ⋯ + B_d^{(n-1)} x_d \\
    & =
    \begin{bmatrix}
      P_0^{(n-1)} \\
      Q_0^{(n-1)} \\
    \end{bmatrix} \hat x_0
    + \begin{bmatrix}
      P_1^{(n-1)} \\
      Q_1^{(n-1)} \\
    \end{bmatrix} \hat x_1
    + ⋯ + \begin{bmatrix}
      P_d^{(n-1)} \\
      Q_d^{(n-1)} \\
    \end{bmatrix} \hat x_d \\
    & = \begin{bmatrix}
      P_0^{(n-1)} \hat x_0 + P_1^{(n-1)} \hat x_1 + ⋯ + P_d^{(n-1)} \hat x_d \\
      Q_0^{(n-1)} \hat x_0 + Q_1^{(n-1)} \hat x_1 + ⋯ + Q_d^{(n-1)} \hat x_d \\
    \end{bmatrix}.
  \end{align*}
  Projecting this vector back to $ℚ^d$ results exactly in the vector
  \[
    r^{(n)} = \frac{P_0^{(n-1)} + P_1^{(n-1)} x_1 + ⋯ + P_d^{(n-1)} x_d}{Q_0^{(n-1)} + Q_1^{(n-1)} x_1 + ⋯ + Q_d^{(n-1)} x_d}
  \]
  from
  Lemma~\ref{lem:mdcf-wallis}.
\end{proof}

\iffalse
% TODO: Klein polyhedra?
Last but not least,
there also exists a generalization of Klein polygons to higher dimensions.
For three dimensions, they are known as Klein polyhedra
and in general they are known as Klein polytopes.

\begin{definition}
  Let $B = \{b₁, …, b_d\} ⊆ ℝ^d$ be a basis and let $C = \{ λ₁ b₁ + ⋯ + λ_d b_d \mid λ_i ≥ 0 \}$.
  The \emph{Klein polytope} $K$ generated by $B$ is defined as
  \[
    K = \mathrm{conv}(C ∩ ℤ^d \setminus \{\symbf 0\}).
  \]
\end{definition}

The connection between Klein polytopes and the convergents is not clear to me, however.
As before, we can show that the area between the convergents is empty.
The idea for a Klein polyhedra is visualized in Figure~\ref{fig:klein-polytope}.
This time, we consider the parallelepiped between the secondary convergents of the
current iteration and the previous iteration.
The number of integer points inside this parallelepiped can be calculated using
the determinant between the convergents.
Although the parallelepiped is not empty,
all of its integer points must be its the boundary.
Therefore, the volume between the convergents is empty.

Similarly,
Equation~\ref{eq:??} already shows that the line lies inside the convex hull of
the secondary convergents
and the convergence shows that the area of the convergents decreases towards zero.
\fi

% ==============================================================================
\section{Algebraic Numbers and Periodicity}
\label{sec:mcf-periodic}
% ==============================================================================

The proof for periodic MCFs is based on the same theorem for the Jacobi-Perron
algorithm, originally proven by Perron \cite{Perron07}.
We begin with the purely periodic case.
The idea behind this proof is that in a purely periodic MCF of a vector $x ∈ ℝ^d$,
the vector itself is an eigenvector for one of the matrices $B^{(k)}$.
Furthermore, the elements of this eigenvector can only be algebraic numbers with degree $≤ d+1$.

\begin{lemma}
  \label{lem:mdcf-purely-periodic}
  If there exists a purely periodic MCF for $x ∈ ℝ^d$,
  then $[ℚ(x₁, …, x_d) : ℚ] ≤ d+1$.
\end{lemma}

% TODO: Should we use x ≡ y or [x] = [y]?
\begin{proof}
  If the MCF is purely periodic, then there is some index $n ≥ 1$ such that $x = x^{(n)}$.
  Let $\hat x = [1, x₁, …, x_d]$ and $\hat x^{(n)} = [1, x_1^{(n)}, …, x_d^{(n)}]$.
  By Lemma~\ref{lem:mdcf-wallis'},
  \[
    \hat x \sim B^{(n)} \hat x^{(n)} \sim B^{(n)} \hat x \iff λ \hat x = B^{(n)} \hat x,
  \]
  for some nonzero $λ ∈ ℝ$.
  Therefore, we are looking for an eigenvector $\hat x$ and an eigenvalue $λ$ of $B^{(n)}$.
  The characteristic polynomial $\det(B^{(n)} - λ I)$ can have a degree of at most $d+1$,
  therefore the eigenvalue $λ$ is an algebraic number of degree $d+1$.
  For the eigenvector $\hat x$, we have to find a nontrivial solution to the
  homogeneous linear system
  \[
    (B^{(n)} - λ I) \hat x = 0.
  \]
  Each coefficient in this linear system is either an integer or $λ$ and is
  therefore contained in the field $ℚ(λ)$.
  Hence, we have $[ℚ(\hat x_0, \hat x_1, …, \hat x_d) : ℚ] ≤ d+1$.

  Finally, the eigenvector $\hat x$ has to be projected back from homogeneous coordinates $x$.
  Since $xᵢ = \hat xᵢ / \hat x₀$ is a rational expression and the values $\hat xᵢ$ and $\hat x₀$ are members of the same field $ℚ(λ)$,
  the projected value $xᵢ$ must also be contained in the same field.
  Therefore, each element in $x$ is an algebraic number
  and we have $[ℚ(x₁, …, x_d) : ℚ] ≤ d+1$.
\end{proof}

\begin{theorem}
  \label{thm:mdcf-periodic}
  If there exists a periodic MCF for $x ∈ ℝ^d$,
  then $[ℚ(x₁, …, x_d) : ℚ] ≤ d + 1$.
\end{theorem}

\begin{proof}
  Given such a MCF for $x$, let $x^{(k)}$ denote the $k$-th complete quotient
  of this fraction.
  Suppose that the MCF is periodic after $K ≥ 0$ with period $ℓ ≥ 0$, i.e.
  $x^{(k)} = x^{(k+ℓ)}$ for every $k ≥ K$.
  By Lemma~\ref{lem:mdcf-wallis'}, $\hat x \sim B^{(k)} \hat x^{(k)}$,
  which means that very element in the projection $x$ can be represented
  as a rational expression of $x^{(k)}$:
  \[
    x_i = \frac{∑_{j=1}^d B_{ij}^{(k)} x_j^{(k)} + B_{i0}^{(k)}}{\sum_{j=1}^d B_{0j}^{(k)} x_j^{(k)} + B_{00}^{(k)}}.
  \]
  % TODO: I think we should be more precise here since the elements could be
  % inside different fields. They are not, but this sentence does not indicate
  % that.
  From Lemma~\ref{lem:mdcf-purely-periodic},
  it follows that the elements of $\hat x^{(k)}$
  are contained in a field $ℚ(λ)$ with degree $[ℚ(λ) : ℚ] ≤ d+1$.
  Since $B^{(k)}$ consists solely of integers, every element in $x$ is contained in the same field $ℚ(λ)$.
  Therefore, they must also be algebraic numbers
  and we have $[ℚ(x₁, …, x_d) : ℚ] ≤ d+1$.
\end{proof}

This section has shown that a purely periodic multidimensional continued fraction must represent a vector of algebraic numbers.
More precisely, the components of the vector lie in a number field of degree at
most $d + 1$, where d is the dimension of the continued fraction.
This result establishes one direction of Hermite's question in higher dimensions.
The converse direction, however, remains open.

Although Theorem~\ref{thm:unimodular-algebraic} shows that for any algebraic
number $α$ there exists a unimodular matrix $U$ with eigenvector $(1, α, …, α^d)$,
it remains unclear whether the existence of this matrix implies a periodic MCF.
For two dimensions, we were able to show that the convergents and the vertices of a Klein polygon are equivalent.
Since $U$ preserves the Klein polygon, it implies that the continued fraction is periodic.
In higher dimensions the Klein polygon generalises to a Klein polytope.
While there exists a multidimensional analogue of Lagrange's theorem \cite{German08},
the connection between the convergents and the vertices of Klein polytopes is not known yet.
