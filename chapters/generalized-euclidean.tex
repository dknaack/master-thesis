\chapter{The Generalized Euclidean Algorithm}

In this chapter, we look at the generalized version of the Euclidean algorithm \cite{Klein24}.
While the original algorithm works on numbers,
the generalized version works with vectors.
More specifically, the generalized version works on lattices.
For this chapter, we proceed analogously to the Euclidean algorithm.
First, we look at how the generalized algorithm works and then use it to find a
higher-dimensional analogue to the Fibonacci numbers and the golden ratio.
Using the golden ratio, we can naturally extend this generalized algorithm to
the real numbers, just like the original single-dimensional algorithm.

\section{Basics of Lattice Theory}

\begin{figure}[b]
  \centering
  \includestandalone{figures/lattice}
  \caption{A two-dimensional lattice with vectors $B_1 = (2, 1)$ and $B_2 = (1, 3)$.}
\end{figure}

\begin{itemize}
  \item Vector space as the linear combination over a basis
  \item Lattices as an integral combination over a basis
\end{itemize}

\begin{definition}
  Given a basis $B ∈ ℤ^{d × n}$, the \emph{lattice} over the basis $B$ is defined as
  \[
    \mathcal{L}(B) = \left\{\, B₁z₁ + \dots + B_n z_n \mid z_1, \dots, z_n ∈ ℤ^d \,\right\}.
  \]
  The \emph{rank} of $\mathcal{L}(B)$ is $n$ and its \emph{dimension} is $d$.
  If $n = d$, then $\mathcal{L}(B)$ is a \emph{full rank} lattice.
\end{definition}

\begin{problem}[Lattice Basis Reduction]~
  \begin{itemize}
    \item \textbf{Input}: A matrix $A ∈ ℤ^{d × n}$ with $\text{rank}(A) = d$.
    \item \textbf{Output}: A matrix $B ∈ ℤ^{d × d}$ with $\mathcal{L}(B) = \mathcal{L}(A)$.
  \end{itemize}
\end{problem}

In this thesis, I only consider the case for one additional vector, i.e. $n = d + 1$.

% TODO: Example for an over-defined basis and what the reduced basis is.
\begin{example}
  Consider $A = \begin{pmatrix}
    2 & 1 & 3 \\
    1 & 3 & 4 \\
  \end{pmatrix}$.
  The matrix $B = \begin{pmatrix}
    2 & 1 \\
    1 & 3 \\
  \end{pmatrix}$
  spans the same lattice,
  since $A_3 = A_1 + A_2$.
  Therefore, $B$ would is the reduced basis of $\mathcal L(A)$.
\end{example}

% TODO: Another example which shows that you can't just take a submatrix of the
% original matrix.

\begin{definition}
  The \emph{fundamental parallelepiped} of a lattice $\mathcal{L}(B)$ with $B ∈ ℤ^{d × n}$ is defined as
  \[
    Π(B) = \left\{\, B₁ x₁ + \dots + B_n x_n \mid x_1, \dots, x_n ∈ [0, 1) \,\right\}
  \]
\end{definition}

A useful fact about the fundamental parallelepiped of a lattice $\mathcal L(B)$ is that
if $B$ is a square integer matrix,
then the volume of the parallelepiped $Π(B)$ and
the number of integer points $ℤ^n$ contained in $Π(B)$ is determined by $\mathrm{det}(B)$,
i.e.
\[
  \mathrm{vol}(Π(B)) = |Π(B) ∩ ℤ^n| = |\det(B)|.
\]

\section{Description of the Algorithm}

In the previous example,
we saw that we could represent the last column vector as an integral
combination of the previous two,
which allows us to reduce the basis for the lattice to only those two column vectors.
However, in general it is not as easy as this.
Consider the matrix $A = ?$.
In this case, $A_3 = ? + ?$, which is clearly not an integral combination.
So $A' = ?$ does not span the same lattice as $A$.

Each point $x ∈ ℝ^d$ can be represented as a combination of a lattice point $z
∈ \mathcal{L}(B)$ and a point in the fundamental parallelepiped $r ∈ Π(B)$.
Specifically,
\[
  x = z + r = B\floor{x} + B\{x\}.
\]

\[
  x \pmod{Π(B)} := x - B\floor{x}.
\]

\begin{Pseudocode}[float=tb,caption={The Generalized Euclidean Algorithm \cite{Klein24}.}]
solve $Bx = c$
while $x$ is not integral do
  find $x_ℓ$ which is not integral
  $c ← B_ℓ$
  $B_ℓ ← B\{x\}$
  solve $Bx = c$
end
\end{Pseudocode}

The algorithm requires solving a linear system in each iteration.
However, we do not have to do this in every iteration.
We only have to do this in the first iteration and in the following iterations
we simply update this solution from the old solution.
If $x = (x₁, …, x_d)$ is the solution in the previous iteration,
then $x' = (x₁', …, x_d')$ with
\begin{align*}
  x_i' =
  \begin{cases}
    \frac{1}{\{x_ℓ\}},  & \text{ if } i = ℓ, \\
    -\frac{\{x_i\}}{\{x_ℓ\}} & \text{ otherwise,}
  \end{cases}
\end{align*}
is the solution in the next iteration.
This update rule follows from
\[
  B_ℓ \{x_ℓ\} + \sum_{i ≠ ℓ} B_i \{x_i\} = r
  \iff
  r - \sum_{i ≠ ℓ} B_i \{x_i\} = B_ℓ \{x_ℓ\}
  \iff
  r \frac{1}{\{x_ℓ\}} - \sum_{i ≠ ℓ} B_i \frac{\{x_i\}}{\{x_ℓ\}} = B_ℓ.
\]

% TODO: Should we add a citation for Northshield and explain that continued
% fractions map positive to positive values which seems to be a fundamental
% requirement for the continued fractions to be periodic?

% I think a better wording would be, that the update rule makes the negation
% visible, which is not optimal. The update rule itself doesn't negate the
% variables, even without the update rule we would still have negated
% variables, since the update rule is just an improvement of the original
% algorithm.

Although the update rule speeds up the algorithm considerably, it is not
optimal for the analysis in the following sections.
The rule flips the sign of all elements inside the solution vector in each
iteration.
Instead, I propose a slight modification to the generalized algorithm which
maps each $xᵢ$ to another positive value.
After we replace $B_ℓ$ with $c$, we flip the signs of all vectors $B_i$ with $i ≠ ℓ$.
This leads to the modified update rule, where the values $x_i$ for $i ≠ ℓ$ are
no longer negated:
\begin{align*}
  x_i' =
  \begin{cases}
    \frac{1}{\{x_ℓ\}},  & \text{ if } i = ℓ, \\
    \frac{\{x_i\}}{\{x_ℓ\}} & \text{ otherwise.}
  \end{cases}
\end{align*}
By $\mathrm{pivot}_ℓ(x) = x'$, we denote this modified update rule.
The modified algorithm can be seen in Listing~\ref{lst:modified-generalized-euclidean}.
In the algorithm, first $B_ℓ$ is flipped and then the whole matrix $B$ is flipped,
This is the same as only flipping the vectors $B_i$ for $i ≠ ℓ$.

\begin{Pseudocode}[float=tb, caption={The Modified Algorithm.}, label={lst:modified-generalized-euclidean}]
solve $Bx = c$
while $x$ is not integral do
  find index $ℓ$ for which $x_ℓ$ is not integral
  $c ← B_ℓ$
  $B_ℓ ← -B\{x\}$
  $B ← -B$
  $x ← \mathrm{pivot}_ℓ(x)$
end
\end{Pseudocode}

\begin{lemma}
  The determinant of $B$ decreases by $\{x_ℓ\}$ in each iteration.
\end{lemma}

\begin{theorem}
  The generalized Euclidean algorithm terminates in at most $\det(B)$ steps.
\end{theorem}

\begin{figure}[t]
  \centering
  \includestandalone{figures/pivot-choice}
  \caption{
    Different choices for the remainder of vector $c$. The original algorithm
    always uses $r$ as the remainder, but the modified update rule would also consider $r'$.}
\end{figure}

\section{Higher-Order Fibonacci Numbers and Their Golden Ratios}

We have already seen that the worst-case input for the one-dimensional
Euclidean algorithm are the Fibonacci numbers.
Plugging in two Fibonacci numbers always requires at least n steps for the
algorithm.
This leads to the question whether such numbers also exist in higher dimensions
and what their golden ratios look like.

% I would like a better explanation of what the goal of this section is

The answer to this question does not lead to a single definition of the
Fibonacci numbers per dimension, but many different types of Fibonacci numbers.
The generalized Euclidean algorithm allows for one additional degree of freedom
by choosing which column vector we swap with.
Therefore, there cannot be just one definitive Fibonacci number, there are
different ones depending on the choice of our swap/pivot.

The first strategy one may think of is to choose the index ell with the
smallest fractional value.
After all, this gives us the largest decrease in the determinant over one
iteration.
So locally, this would be the highest decrease we can achieve. But what would a
Fibonacci number look like in this case?

First, we are indeed talking about just numbers and not vectors.
The Euclidean algorithm takes one-dimensional integers as input, so one would
expect that the generalized algorithm would take Fibonacci vectors as input.
But the numbers of steps that the algorithm requires only depends on the
initial solution vector x.
In fact, the entire execution of the algorithm only depends on this vector.
There are infinitely many possible linear systems which have the same solution
vector x, and hence there would be infinitely many "Fibonacci vectors".
Therefore, we look instead only for the numbers inside the rational vector.

% TODO: Actually explain how we derive the Fibonacci numbers for this strategy.

The Fibonacci numbers for this strategy are defined as
\begin{align*}
  F(0) = F(1) = ⋯ = F(d) = 1, \qquad F(n + 1) = F(n) + F(n - 1) + ⋯ + F(n - d).
\end{align*}
We choose our initial input as
\begin{align*}
  B & =
  \begin{pmatrix}
    F(n + 1) & 0        & ⋯ & 0 \\
    0        & F(n + 1) & ⋯ & 0 \\
    ⋮        & ⋮        & ⋱ & ⋮ \\
    0 & 0 & ⋯ & F(n + 1) \\
  \end{pmatrix}, \\
  c & =
  \begin{pmatrix}
    F(n) \\
    F(n) + F(n - 1) \\
    ⋮ \\
    F(n) + F(n - 1) + ⋯ + F(n + 1 - d) \\
  \end{pmatrix},
\end{align*}
which gives us the solution vector
\[
  x =
  \left(
    \frac{F(n)}{F(n + 1)},\;
    \frac{F(n) + F(n - 1)}{F(n + 1)},\;
    ⋯,\;
    \frac{F(n) + F(n - 1) + ⋯ + F(n + 1 - d)}{F(n + 1)}\;
  \right).
\]
The smallest fractional value in this vector is $x₁$, so we pivot with $ℓ = 1$ first.
\begin{align*}
  \{x₁'\}
  & = \left\{\frac{1}{\{x₁\}}\right\}
  = \left\{\frac{F(n + 1)}{F(n)}\right\}
  = \frac{F(n - 1) + ⋯ + F(n - d)}{F(n)}.
\end{align*}
This gives us the value for $x_d$, if we would have started with $F(n)$ instead of $F(n+1)$.
The other values in our input vector $x$ are calculated as follows:
\begin{align*}
  \{xᵢ'\}
  & = \left\{\frac{\{xᵢ\}}{\{x₁\}}\right\} \\
  & = \left\{\frac{F(n) + F(n - 1) + ⋯ + F(n + 1 - i)}{F(n + 1)} · \frac{F(n + 1)}{F(n)}\right\} \\
  & = \frac{F(n - 1) + ⋯ + F(n - d)}{F(n)}.
\end{align*}
So in the next iteration the value $x_i$ has the same value as $x_{i+1}$ if we
would have started with $F(n)$.
Therefore, in the next iteration the smallest fractional value must be $x_2$.
We continue this until we have cycled through all variables.

Another example would be the opposite strategy: Choosing the maximum in each iteration.
In this case, the Fibonacci numbers are defined as
\begin{align*}
  F(0) = \dots = F(d) = 1, \qquad F(n + 1) = F(n) + F(n - d).
\end{align*}

The golden ratios for each definition is the limit of consecutive Fibonacci numbers
\[
  φ = \lim_{n → ∞} \frac{F(n + 1)}{F(n)},
\]
where $F(n)$ can be any of the previously defined Fibonacci numbers.

\section{Extension to Real Numbers}
