\chapter{The Generalized Euclidean Algorithm}

In this chapter, we look at the generalized version of the Euclidean algorithm \cite{Klein24}.
While the original algorithm works on numbers,
the generalized version works with vectors.
More specifically, the generalized version works on lattices.
For this chapter, we proceed analogously to the Euclidean algorithm.
First, we look at how the generalized algorithm works and then use it to find a
higher-dimensional analogue to the Fibonacci numbers and the golden ratio.
Using the golden ratio, we can naturally extend this generalized algorithm to
the real numbers, just like the original single-dimensional algorithm.

\section{Basics of Lattice Theory}

\begin{figure}[b]
  \centering
  \includestandalone{figures/lattice}
  \caption{A two-dimensional lattice with vectors $B_1 = (2, 1)$ and $B_2 = (1, 3)$.}
\end{figure}

\begin{itemize}
  \item Vector space as the linear combination over a basis
  \item Lattices as an integral combination over a basis
\end{itemize}

\begin{definition}
  Given a basis $B ∈ ℤ^{d × n}$, the \emph{lattice} over the basis $B$ is defined as
  \[
    \mathcal{L}(B) = \left\{\, B₁z₁ + \dots + B_n z_n \mid z_1, \dots, z_n ∈ ℤ^d \,\right\}.
  \]
  The \emph{rank} of $\mathcal{L}(B)$ is $n$ and its \emph{dimension} is $d$.
  If $n = d$, then $\mathcal{L}(B)$ is a \emph{full rank} lattice.
\end{definition}

\begin{problem}[Lattice Basis Reduction]~
  \begin{itemize}
    \item \textbf{Input}: A matrix $A ∈ ℤ^{d × n}$ with $\text{rank}(A) = d$.
    \item \textbf{Output}: A matrix $B ∈ ℤ^{d × d}$ with $\mathcal{L}(B) = \mathcal{L}(A)$.
  \end{itemize}
\end{problem}

In this thesis, I only consider the case for one additional vector, i.e. $n = d + 1$.

% TODO: Example for an over-defined basis and what the reduced basis is.
\begin{example}
  Consider $A = \begin{pmatrix}
    2 & 1 & 3 \\
    1 & 3 & 4 \\
  \end{pmatrix}$.
  The matrix $B = \begin{pmatrix}
    2 & 1 \\
    1 & 3 \\
  \end{pmatrix}$
  spans the same lattice,
  since $A_3 = A_1 + A_2$.
  Therefore, $B$ would is the reduced basis of $\mathcal L(A)$.
\end{example}

% TODO: Another example which shows that you can't just take a submatrix of the
% original matrix.

\begin{definition}
  The \emph{fundamental parallelepiped} of a lattice $\mathcal{L}(B)$ with $B ∈ ℤ^{d × n}$ is defined as
  \[
    Π(B) = \left\{\, B₁ x₁ + \dots + B_n x_n \mid x_1, \dots, x_n ∈ [0, 1) \,\right\}
  \]
\end{definition}

A useful fact about the fundamental parallelepiped of a lattice $\mathcal L(B)$ is that
if $B$ is a square integer matrix,
then the volume of the parallelepiped $Π(B)$ and
the number of integer points $ℤ^n$ contained in $Π(B)$ is determined by $\mathrm{det}(B)$,
i.e.
\[
  \mathrm{vol}(Π(B)) = |Π(B) ∩ ℤ^n| = |\det(B)|.
\]

\section{Description of the Algorithm}

\begin{Pseudocode}[float=tb,caption={The Generalized Euclidean Algorithm \cite{Klein24}.}]
solve $Bx = c$
while $x$ is not integral do
  find $x_ℓ$ which is not integral
  $c ← B_ℓ$
  $B_ℓ ← B\{x\}$
  solve $Bx = c$
end
\end{Pseudocode}

In the previous example,
we saw that we could represent the last column vector as an integral
combination of the previous two,
which allows us to reduce the basis for the lattice to only those two column vectors.
However, in general it is not as easy as this.
Consider the matrix $A = ?$.
In this case, $A_3 = ? + ?$, which is clearly not an integral combination.
So $A' = ?$ does not span the same lattice as $A$.

Each point $a ∈ ℝ^d$ can be represented as a combination of a lattice point $z
∈ \mathcal{L}(B)$ and a point in the fundamental parallelepiped $r ∈ Π(B)$.
Specifically,
\[
  a = z + r = B\floor{x} + B\{x\}.
\]
This is essentially a division with remainder inside a lattice.
It allows us to define a modulo operation on the lattice:
\[
  a \pmod{Π(B)} := a - B\floor{B^{-1} x}.
\]

The algorithm requires solving a linear system in each iteration.
However, we do not have to do this in every iteration.
We only have to do this in the first iteration and in the following iterations
we simply update this solution from the old solution.
If $x = (x₁, …, x_d)$ is the solution in the previous iteration,
then $x' = (x₁', …, x_d')$ with
\begin{align*}
  x_i' =
  \begin{cases}
    \frac{1}{\{x_ℓ\}},  & \text{ if } i = ℓ, \\
    -\frac{\{x_i\}}{\{x_ℓ\}} & \text{ otherwise,}
  \end{cases}
\end{align*}
is the solution in the next iteration.
This update rule follows from
\[
  B_ℓ \{x_ℓ\} + \sum_{i ≠ ℓ} B_i \{x_i\} = r
  \iff
  r - \sum_{i ≠ ℓ} B_i \{x_i\} = B_ℓ \{x_ℓ\}
  \iff
  r \frac{1}{\{x_ℓ\}} - \sum_{i ≠ ℓ} B_i \frac{\{x_i\}}{\{x_ℓ\}} = B_ℓ.
\]

% TODO: Should we add a citation for Northshield and explain that continued
% fractions map positive to positive values which seems to be a fundamental
% requirement for the continued fractions to be periodic?

% I think a better wording would be, that the update rule makes the negation
% visible, which is not optimal. The update rule itself doesn't negate the
% variables, even without the update rule we would still have negated
% variables, since the update rule is just an improvement of the original
% algorithm.

Although the update rule speeds up the algorithm considerably, it is not
optimal for the analysis in the following sections.
The rule flips the sign of all elements inside the solution vector in each
iteration.
Instead, I propose a slight modification to the generalized algorithm which
maps each $xᵢ$ to another positive value.
After we replace $B_ℓ$ with $c$, we flip the signs of all vectors $B_i$ with $i ≠ ℓ$.
This leads to the modified update rule, where the values $x_i$ for $i ≠ ℓ$ are
no longer negated:
\begin{align*}
  x_i' =
  \begin{cases}
    \frac{1}{\{x_ℓ\}},  & \text{ if } i = ℓ, \\
    \frac{\{x_i\}}{\{x_ℓ\}} & \text{ otherwise.}
  \end{cases}
\end{align*}
By $\mathrm{pivot}_ℓ(x) = x'$, we denote this modified update rule.
The modified algorithm can be seen in Listing~\ref{lst:modified-generalized-euclidean}.
In the algorithm, first $B_ℓ$ is flipped and then the whole matrix $B$ is flipped,
This is the same as only flipping the vectors $B_i$ for $i ≠ ℓ$.

\begin{Pseudocode}[float=tb, caption={The Modified Algorithm.}, label={lst:modified-generalized-euclidean}]
solve $Bx = c$
while $x$ is not integral do
  find index $ℓ$ for which $x_ℓ$ is not integral
  $c ← B_ℓ$
  $B_ℓ ← -B\{x\}$
  $B ← -B$
  $x ← \mathrm{pivot}_ℓ(x)$
end
\end{Pseudocode}

\begin{lemma}
  The algorithm terminates in at most $\det(B)$ steps.
\end{lemma}

\begin{proof}

\end{proof}

\begin{lemma}
  In each iteration, $\mathcal L(B ∪ c) = \mathcal L(B' ∪ c')$.
\end{lemma}

\begin{proof}

\end{proof}

\begin{theorem}
  The generalized Euclidean algorithm solves the lattice basis reduction problem.
\end{theorem}

\begin{figure}[t]
  \centering
  \includestandalone{figures/pivot-choice}
  \caption{
    Different choices for the remainder of vector $c$. The original algorithm
    always uses $r$ as the remainder, but the modified update rule would also consider $r'$.}
\end{figure}

\section{Higher-Order Fibonacci Numbers and Their Golden Ratios}

We have already seen that the worst-case input for the one-dimensional
Euclidean algorithm are the Fibonacci numbers.
Plugging in two Fibonacci numbers always requires at least n steps for the
algorithm.
This leads to the question whether such numbers also exist in higher dimensions
and what their golden ratios look like.

% TODO: There should be a discussion on what it even means to have a Fibonacci number in higher dimensions

First, we have to understand what Fibonacci numbers in higher dimensions would
look like.
Fibonacci numbers have two properties which make them special for the Euclidean algorithm.
The first is that applying one iteration of the Euclidean algorithm on two
consecutive Fibonacci numbers~$(F(n + 1), F(n))$ yields the previous Fibonacci numbers~$(F(n), F(n - 1))$.
So the Euclidean algorithm requires exactly $n$ steps on this input.

The second property is that they are minimal with respect to this.
There are other sequences, which fulfill the first property, but the Fibonacci
numbers are special, in that they fit exactly once inside the next number.
This means that in the Euclidean algorithm there is a multiplicative factor of $1$ at each step (except the last):
\[
  \begin{array}{rcl}
    F(n + 1) & = & 1 · F(n) + F(n - 1),     \\
    F(n)     & = & 1 · F(n - 1) + F(n - 2), \\
             & ⋮ &                          \\
    F(2)     & = & 2 · F(1).
  \end{array}
\]
Other numbers may have higher factors -- for example, the silver ratio has a
factor of $2$ at each step -- but the Fibonacci numbers have the smallest factor.

This property is also reflected in the fractions $a/b$ for a given input $(a, b)$.
At each step (except the last) the fraction always has an integer part of $1$:
\[
  \begin{array}{rcl}
    \frac{F(n + 1)}{F(n)} & = & 1 + \frac{F(n - 1)}{F(n)},     \\
    \frac{F(n)}{F(n - 1)} & = & 1 + \frac{F(n - 2)}{F(n - 1)}, \\
                          & ⋮ &                                \\
    \frac{F(2)}{F(1)}     & = & 2.                              \\
  \end{array}
\]
So, a higher-dimensional Fibonacci number would also need to have a fraction
with integer part $1$ at each step.

% TODO: We should also discuss the thing about idempotence under the choice of the pivot.
% TODO: Should we have a discussion about why we choose this particular linear system.

First, we are indeed talking about just numbers and not vectors.
The Euclidean algorithm takes one-dimensional integers as input, so one would
expect that the generalized algorithm would take Fibonacci vectors as input.
But the numbers of steps that the algorithm requires only depends on the
initial solution vector x.
In fact, the entire execution of the algorithm only depends on this vector.
There are infinitely many possible linear systems which have the same solution
vector x, and hence there would be infinitely many "Fibonacci vectors".
Therefore, we look instead only for the numbers inside the rational vector.

There are many different possibilities for choosing a linear system which has the solution $x$.
We use a simple construction, which
given a rational vector $x = \left(\frac{p₁}{q}, \frac{p₂}{q}, …, \frac{p_d}{q}\right)$,
constructs the linear system $Bx = c$ with
\begin{equation}
  \label{eq:linear-system-construction}
  B =
  \begin{pmatrix}
    q & 0 & ⋯ & 0 \\
    0 & q & ⋯ & 0 \\
    ⋮ & ⋮ & ⋱ & ⋮ \\
    0 & 0 & ⋯ & q \\
  \end{pmatrix},
  \quad
  c =
  \begin{pmatrix}
    p₁ \\
    p₂ \\
    ⋮ \\
    p_d
  \end{pmatrix}.
\end{equation}

% I would like a better explanation of what the goal of this section is

Although we have reduced the problem just to the vector $x$, there is still
some ambiguity left, when extending Fibonacci numbers to higher dimensions.
The generalized Euclidean algorithm allows for an additional degree of freedom
by choosing which column vector $B_ℓ$ we swap our vector $c$ with.
Therefore, there cannot be just one definitive Fibonacci number, there are
different ones depending on the choice of our index $ℓ$.

The first strategy one may think of is to choose the index $ℓ$ with the
smallest fractional value.
After all, this gives us the largest decrease in the determinant over one
iteration.
Locally, this would be the highest decrease we can achieve.
So we begin with this strategy and try to find a generalization of Fibonacci
numbers under this strategy.

% TODO: Actually explain how we derive the Fibonacci numbers for this strategy.
% TODO: Should we have a table for the Fibonacci numbers?
% TODO: What about adding references to their OEIS number?

The Fibonacci numbers for this strategy are defined as
\begin{align*}
  F(0) = F(1) = ⋯ = F(d) = 1, \qquad F(n + 1) = F(n) + F(n - 1) + ⋯ + F(n - d).
\end{align*}
For $d = 2, 3, 4$, they are also called the Tribonacci, Tetranacci and Pentanacci numbers.
In general, they are known as the $d$-bonacci numbers.
For these numbers,
We use the solution vector
\[
  x =
  \left(
    \frac{F(n)}{F(n + 1)},\;
    \frac{F(n) + F(n - 1)}{F(n + 1)},\;
    ⋯,\;
    \frac{F(n) + F(n - 1) + ⋯ + F(n + 1 - d)}{F(n + 1)}\;
  \right)
\]
and we can use the construction from Equation~\ref{eq:linear-system-construction}
for the actual input to the generalized Euclidean algorithm.

The smallest fractional value in this vector is $x₁$, so we pivot with $ℓ = 1$ first.
\begin{align*}
  \{x₁'\}
  & = \left\{\frac{1}{\{x₁\}}\right\}
  = \left\{\frac{F(n + 1)}{F(n)}\right\}
  = \frac{F(n - 1) + ⋯ + F(n - d)}{F(n)}.
\end{align*}
This gives us the value for $x_d$, if we would have started with $F(n)$ instead of $F(n+1)$.
The other values in our input vector $x$ are calculated as follows:
\begin{align*}
  \{xᵢ'\}
  & = \left\{\frac{\{xᵢ\}}{\{x₁\}}\right\} \\
  & = \left\{\frac{F(n) + F(n - 1) + ⋯ + F(n + 1 - i)}{F(n + 1)} · \frac{F(n + 1)}{F(n)}\right\} \\
  & = \frac{F(n - 1) + ⋯ + F(n - d)}{F(n)}.
\end{align*}
So in the next iteration the value $x_i$ has the same value as $x_{i+1}$ if we
would have started with $F(n)$.
Therefore, in the next iteration the smallest fractional value must be $x_2$.
We continue this until we have cycled through all variables.

Another example would be the opposite strategy: Choosing the maximum in each iteration.
In this case, the Fibonacci numbers are defined as
\begin{align*}
  F(0) = \dots = F(d) = 1, \qquad F(n + 1) = F(n) + F(n - d).
\end{align*}

The golden ratios for each definition is the limit of consecutive Fibonacci numbers
\[
  φ = \lim_{n → ∞} \frac{F(n + 1)}{F(n)},
\]
where $F(n)$ can be any of the previously defined Fibonacci numbers.

\section{Extension to Real Numbers}

% ==============================================================================
\section{Comparison to the Jacobi-Perron Algorithm}
% ==============================================================================

Many generalizations to the Euclidean algorithm have been considered.
One of them was proposed by Jacobi to answer Hermite's question.
In his version, he computes the GCD of three numbers by successively dividing
the smallest number from the larger numbers.
This algorithm was later extended by Oskar Perron to arbitrarily many numbers.
The algorithm works as follows:

Given a list of positive integers $a₀, a₁, …, aₙ$, take the smallest number $a_ℓ$
and compute the remainder $a_i'$ resulting from the division of $a_i$ with $a_ℓ$.
The value $a_ℓ$ is kept until the next iteration, i.e. $a_ℓ' = a_ℓ$.
Continue this process until all but one value remains.
\begin{align*}
  a₀' = a₀ \bmod a_ℓ, a₁ = a₁ \bmod a_ℓ, …, a_ℓ' = a_ℓ, …, aₙ' = aₙ \bmod a_ℓ; \\
\end{align*}

Perron modified this algorithm for the purposes of his analysis.
The integers $a₁, …, aₙ$ are kept in a list.
We remove the first element from the list, calculate the remainders for each
remaining element and append the element to the end of the list.
One iteration in this modified version produces the values:
\begin{align*}
  a₀' = a₁ \bmod a₀, a₁' = a₂ \bmod a₀, …, a_{n-1}' = a_n \bmod a₀, aₙ = a₀. \\
\end{align*}
This process is repeated until the first element is zero.

Of course, the termination condition is not sufficient.
When this algorithm terminates, the remaining elements might not all be zero.
Therefore, we remove the first element from the list and continue with the
remaining list.

By allowing real numbers as inputs, this algorithm proceeds infinitely but
always converges to zero.

The Jacobi-Perron algorithm is actually a subset of the generalized Euclidean algorithm.
The generalized Euclidean algorithm is periodic for all real numbers where the Jacobi-Perron algorithm is periodic.
This comes from the fact, that the Jacobi-Perron algorithm is really the
generalized Euclidean algorithm with the specific sequence of pivots $L = \overline{12…d}$.
So in the $i$th iteration, we are choosing index $(i \bmod d) + 1$ as our pivot.

This has the convenient property that if the all inputs which are periodic for
the Jacobi-Perron algorithm must also be periodic for the brute-force algorithm.

\begin{theorem}
  The brute-force algorithm is periodic on input $(1, r, r^2)$ if
  \[
    r = \sqrt[n]{D + d}, \text{ where } d | D.
  \]
\end{theorem}
