\chapter{The Generalized Euclidean Algorithm}

In this chapter, we look at the generalized version of the Euclidean algorithm \cite{Klein24}.
While the original algorithm works on numbers,
the generalized version works with vectors.
More specifically, the generalized version works on lattices.
For this chapter, we proceed analogously to the Euclidean algorithm.
First, we look at how the generalized algorithm works and then use it to find a
higher-dimensional analogue to the Fibonacci numbers and the golden ratio.
Using the golden ratio, we can naturally extend this generalized algorithm to
the real numbers, just like the original single-dimensional algorithm.

% ==============================================================================
\section{Basics of Lattice Theory}
% ==============================================================================

\begin{figure}[b]
  \centering
  \includestandalone{figures/lattice}
  \caption{A two-dimensional lattice with vectors $B_1 = (2, 1)$ and $B_2 = (1, 3)$.}
\end{figure}

\begin{itemize}
  \item Vector space as the linear combination over a basis
  \item Lattices as an integral combination over a basis
\end{itemize}

\begin{definition}
  Given a basis $B ∈ ℤ^{d × n}$, the \emph{lattice} over the basis $B$ is defined as
  \[
    \mathcal{L}(B) = \left\{\, B₁z₁ + \dots + B_n z_n \mid z_1, \dots, z_n ∈ ℤ^d \,\right\}.
  \]
  The \emph{rank} of $\mathcal{L}(B)$ is $n$ and its \emph{dimension} is $d$.
  If $n = d$, then $\mathcal{L}(B)$ is a \emph{full rank} lattice.
\end{definition}

\begin{problem}[Lattice Basis Reduction]~
  \begin{itemize}
    \item \textbf{Input}: A matrix $A ∈ ℤ^{d × n}$ with $\text{rank}(A) = d$.
    \item \textbf{Output}: A matrix $B ∈ ℤ^{d × d}$ with $\mathcal{L}(B) = \mathcal{L}(A)$.
  \end{itemize}
\end{problem}

In this thesis, I only consider the case for one additional vector, i.e. $n = d + 1$.

% TODO: Example for an over-defined basis and what the reduced basis is.
\begin{example}
  Consider $A = \begin{pmatrix}
    2 & 1 & 3 \\
    1 & 3 & 4 \\
  \end{pmatrix}$.
  The matrix $B = \begin{pmatrix}
    2 & 1 \\
    1 & 3 \\
  \end{pmatrix}$
  spans the same lattice,
  since $A_3 = A_1 + A_2$.
  Therefore, $B$ would is the reduced basis of $\mathcal L(A)$.
\end{example}

% TODO: Another example which shows that you can't just take a submatrix of the
% original matrix.

\begin{definition}
  The \emph{fundamental parallelepiped} of a lattice $\mathcal{L}(B)$ with $B ∈ ℤ^{d × n}$ is defined as
  \[
    Π(B) = \left\{\, B₁ x₁ + \dots + B_n x_n \mid x_1, \dots, x_n ∈ [0, 1) \,\right\}
  \]
\end{definition}

A useful fact about the fundamental parallelepiped of a lattice $\mathcal L(B)$ is that
if $B$ is a square integer matrix,
then the volume of the parallelepiped $Π(B)$ and
the number of integer points $ℤ^n$ contained in $Π(B)$ is determined by $\mathrm{det}(B)$,
i.e.
\[
  \mathrm{vol}(Π(B)) = |Π(B) ∩ ℤ^n| = |\det(B)|.
\]

% ==============================================================================
\section{Description of the Algorithm}
% ==============================================================================

\begin{Pseudocode}[float=tb,caption={The Generalized Euclidean Algorithm \cite{Klein24}.}]
solve $Bx = c$
while $x$ is not integral do
  find $x_ℓ$ which is not integral
  $c ← B_ℓ$
  $B_ℓ ← B\{x\}$
  solve $Bx = c$
end
\end{Pseudocode}

In the previous example,
we saw that we could represent the last column vector as an integral
combination of the previous two,
which allows us to reduce the basis for the lattice to only those two column vectors.
However, in general it is not as easy as this.
Consider the matrix $A = ?$.
In this case, $A_3 = ? + ?$, which is clearly not an integral combination.
So $A' = ?$ does not span the same lattice as $A$.

Each point $a ∈ ℝ^d$ can be represented as a combination of a lattice point $z
∈ \mathcal{L}(B)$ and a point in the fundamental parallelepiped $r ∈ Π(B)$.
Specifically,
\[
  a = z + r = B\floor{x} + B\{x\}.
\]
This is essentially a division with remainder inside a lattice.
It allows us to define a modulo operation on the lattice:
\[
  a \pmod{Π(B)} := a - B\floor{B^{-1} x}.
\]

The algorithm requires solving a linear system in each iteration.
However, we do not have to do this in every iteration.
We only have to do this in the first iteration and in the following iterations
we simply update this solution from the old solution.
If $x = (x₁, …, x_d)$ is the solution in the previous iteration,
then $x' = (x₁', …, x_d')$ with
\begin{align*}
  x_i' =
  \begin{cases}
    \frac{1}{\{x_ℓ\}},  & \text{ if } i = ℓ, \\
    -\frac{\{x_i\}}{\{x_ℓ\}} & \text{ otherwise,}
  \end{cases}
\end{align*}
is the solution in the next iteration.
This update rule follows from
\[
  B_ℓ \{x_ℓ\} + \sum_{i ≠ ℓ} B_i \{x_i\} = r
  \iff
  r - \sum_{i ≠ ℓ} B_i \{x_i\} = B_ℓ \{x_ℓ\}
  \iff
  r \frac{1}{\{x_ℓ\}} - \sum_{i ≠ ℓ} B_i \frac{\{x_i\}}{\{x_ℓ\}} = B_ℓ.
\]

% TODO: Should we add a citation for Northshield and explain that continued
% fractions map positive to positive values which seems to be a fundamental
% requirement for the continued fractions to be periodic?

% I think a better wording would be, that the update rule makes the negation
% visible, which is not optimal. The update rule itself doesn't negate the
% variables, even without the update rule we would still have negated
% variables, since the update rule is just an improvement of the original
% algorithm.

Although the update rule speeds up the algorithm considerably, it is not
optimal for the analysis in the following sections.
The rule flips the sign of all elements inside the solution vector in each
iteration.
Instead, I propose a slight modification to the generalized algorithm which
maps each $xᵢ$ to another positive value.
After we replace $B_ℓ$ with $c$, we flip the signs of all vectors $B_i$ with $i ≠ ℓ$.
This leads to the modified update rule, where the values $x_i$ for $i ≠ ℓ$ are
no longer negated:
\begin{align*}
  x_i' =
  \begin{cases}
    \frac{1}{\{x_ℓ\}},  & \text{ if } i = ℓ, \\
    \frac{\{x_i\}}{\{x_ℓ\}} & \text{ otherwise.}
  \end{cases}
\end{align*}
By $\mathrm{pivot}_ℓ(x) = x'$, we denote this modified update rule.
The modified algorithm can be seen in Listing~\ref{lst:modified-generalized-euclidean}.
In the algorithm, first $B_ℓ$ is flipped and then the whole matrix $B$ is flipped,
This is the same as only flipping the vectors $B_i$ for $i ≠ ℓ$.

\begin{Pseudocode}[float=tb, caption={The Modified Algorithm.}, label={lst:modified-generalized-euclidean}]
solve $Bx = c$
while $x$ is not integral do
  find index $ℓ$ for which $x_ℓ$ is not integral
  $c ← B_ℓ$
  $B_ℓ ← -B\{x\}$
  $B ← -B$
  $x ← \mathrm{pivot}_ℓ(x)$
end
\end{Pseudocode}

\begin{lemma}
  The algorithm terminates in at most $\det(B)$ steps.
\end{lemma}

\begin{proof}

\end{proof}

\begin{lemma}
  In each iteration, $\mathcal L(B ∪ c) = \mathcal L(B' ∪ c')$.
\end{lemma}

\begin{proof}

\end{proof}

\begin{theorem}
  The generalized Euclidean algorithm solves the lattice basis reduction problem.
\end{theorem}

\begin{figure}[t]
  \centering
  \includestandalone{figures/pivot-choice}
  \caption{
    Different choices for the remainder of vector $c$. The original algorithm
    always uses $r$ as the remainder, but the modified update rule would also consider $r'$.}
\end{figure}

% ==============================================================================
\section{Extension to Real Numbers}
% ==============================================================================

% ==============================================================================
\section{Comparison to the Jacobi-Perron Algorithm}
% ==============================================================================

Many generalizations to the Euclidean algorithm have been considered.
One of them was proposed by Jacobi to answer Hermite's question.
In his version, he computes the GCD of three numbers by successively dividing
the smallest number from the larger numbers.
This algorithm was later extended by Oskar Perron to arbitrarily many numbers.
The algorithm works as follows:

Given a list of positive integers $a₀, a₁, …, aₙ$, take the smallest number $a_ℓ$
and compute the remainder $a_i'$ resulting from the division of $a_i$ with $a_ℓ$.
The value $a_ℓ$ is kept until the next iteration, i.e. $a_ℓ' = a_ℓ$.
Continue this process until all but one value remains.
\begin{align*}
  a₀' = a₀ \bmod a_ℓ, a₁ = a₁ \bmod a_ℓ, …, a_ℓ' = a_ℓ, …, aₙ' = aₙ \bmod a_ℓ; \\
\end{align*}

Perron modified this algorithm for the purposes of his analysis.
The integers $a₁, …, aₙ$ are kept in a list.
We remove the first element from the list, calculate the remainders for each
remaining element and append the element to the end of the list.
One iteration in this modified version produces the values:
\begin{align*}
  a₀' = a₁ \bmod a₀, a₁' = a₂ \bmod a₀, …, a_{n-1}' = a_n \bmod a₀, aₙ = a₀. \\
\end{align*}
This process is repeated until the first element is zero.

Of course, the termination condition is not sufficient.
When this algorithm terminates, the remaining elements might not all be zero.
Therefore, we remove the first element from the list and continue with the
remaining list.

By allowing real numbers as inputs, this algorithm proceeds infinitely but
always converges to zero.

The Jacobi-Perron algorithm is actually a subset of the generalized Euclidean algorithm.
The generalized Euclidean algorithm is periodic for all real numbers where the Jacobi-Perron algorithm is periodic.
This comes from the fact, that the Jacobi-Perron algorithm is really the
generalized Euclidean algorithm with the specific sequence of pivots $L = \overline{12…d}$.
So in the $i$th iteration, we are choosing index $(i \bmod d) + 1$ as our pivot.

This has the convenient property that if the all inputs which are periodic for
the Jacobi-Perron algorithm must also be periodic for the brute-force algorithm.

\begin{theorem}
  The brute-force algorithm is periodic on input $(1, r, r^2)$ if
  \[
    r = \sqrt[n]{D + d}, \text{ where } d | D.
  \]
\end{theorem}
