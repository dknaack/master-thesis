\chapter{Hermite's Question}

\begin{problem}[Hermite's Question]
  Is there a representation of the real numbers as a sequence of natural
  numbers such that the sequence is eventually periodic if and only if the real
  number is a cubic irrational?
\end{problem}

More formally: Does there exists a function $f$ which maps any $α ∈ ℝ$ to an
infinite sequence $(a_n)_{n ∈ ℕ}$ of natural numbers such that $a_n$ is
eventually periodic if and only if $α$ is a cubic irrational?
The problem can very easily be generalized to higher degrees of algebraic numbers:
The representation is periodic if and only if $x$ is the root of a polynomial of degree $d + 1$.

\section{Comparison to the Jacobi-Perron Algorithm}

Many generalizations to the Euclidean algorithm have been considered.
One of them was proposed by Jacobi to answer Hermite's question.
In his version, he computes the GCD of three numbers by successively dividing
the smallest number from the larger numbers.
This algorithm was later extended by Oskar Perron to arbitrarily many numbers.
The algorithm works as follows:

Given a list of positive integers $a₀, a₁, …, aₙ$, take the smallest number $a_ℓ$
and compute the remainder $a_i'$ resulting from the division of $a_i$ with $a_ℓ$.
The value $a_ℓ$ is kept until the next iteration, i.e. $a_ℓ' = a_ℓ$.
Continue this process until all but one value remains.
\begin{align*}
  a₀' = a₀ \bmod a_ℓ, a₁ = a₁ \bmod a_ℓ, …, a_ℓ' = a_ℓ, …, aₙ' = aₙ \bmod a_ℓ; \\
\end{align*}

Perron modified this algorithm for the purposes of his analysis.
The integers $a₁, …, aₙ$ are kept in a list.
We remove the first element from the list, calculate the remainders for each
remaining element and append the element to the end of the list.
One iteration in this modified version produces the values:
\begin{align*}
  a₀' = a₁ \bmod a₀, a₁' = a₂ \bmod a₀, …, a_{n-1}' = a_n \bmod a₀, aₙ = a₀. \\
\end{align*}
This process is repeated until the first element is zero.

Of course, the termination condition is not sufficient.
When this algorithm terminates, the remaining elements might not all be zero.
Therefore, we remove the first element from the list and continue with the
remaining list.

By allowing real numbers as inputs, this algorithm proceeds infinitely but
always converges to zero.

The Jacobi-Perron algorithm is actually a subset of the generalized Euclidean algorithm.
The generalized Euclidean algorithm is periodic for all real numbers where the Jacobi-Perron algorithm is periodic.
This comes from the fact, that the Jacobi-Perron algorithm is really the
generalized Euclidean algorithm with the specific sequence of pivots $L = \overline{12…d}$.
So in the $i$th iteration, we are choosing index $(i \bmod d) + 1$ as our pivot.

This has the convenient property that if the all inputs which are periodic for
the Jacobi-Perron algorithm must also be periodic for the brute-force algorithm.

\begin{theorem}
  The brute-force algorithm is periodic on input $(1, r, r^2)$ if
  \[
    r = \sqrt[n]{D + d}, \text{ where } d | D.
  \]
\end{theorem}

\section{Finding a Periodic Representation through Brute-Force}

\begin{Pseudocode}
algorithm $\textsc{brute-force-search}(x, N)$
  for $L ∈ \{1, …, d\}^{≤ N}$ do
    $x₀ ← x$
    for $i ∈ \{1, …, |L|\}$ do
      $x_i ← \mathrm{pivot}_{L[i]}(x_{i-1})$
      if $x_i$ occurred twice then
        Find the index $j ≠ i$ where $x_j = x_i$
        $S ← L[1] \,…\, L[j]$
        $P ← L[j+1] \,…\, L[i]$
        return $(S, P)$
  return $ε$
\end{Pseudocode}

We use the generalized Euclidean algorithm to find a representation for $r ∈ ℝ$.
More specifically, we use the update rule from the algorithm to find the representation.
The update rule takes a vector and not a real number, so we use the vector $x_i = r^i$ for $i ≤ d$.

For our input $x ∈ ℝ^d$, we can build up a $d$-ary tree where $x$ is the root and any
two nodes of this tree $x', x''$ are connected if $\mathrm{pivot}(x, i) = x''$
for some $i$.
The brute-force algorithm performs a breadth-first search over this tree to
find a node which points to a higher node in the tree, i.e. the path forms a loop.
As our pivot sequence we use the path from the root to the this node.

\begin{conjecture}
  The brute-force algorithm is periodic if and only if $α$ is a cubic irrational.
\end{conjecture}

\section{Multi-Dimensional Continued Fractions}

\begin{definition}
  Given a sequence of $d$-dimensional vectors $\{rₙ\}_{n ≥ 0}$ and a sequence of
  indices $\{ℓₙ\}_{n ≥ 0}$, the \emph{multi-dimensional fraction} $[r₀; ℓ₁, r₁; …]$ is defined as
  \[
    [r₀] = r₀, \qquad [r₀; ℓ₁, r₁; …; ℓₙ, rₙ] = r₀ + \mathrm{pivot}_{ℓ₁}[r₁; ℓ₂, r₂; …; ℓₙ, rₙ].
  \]
\end{definition}

\begin{remark}~
  \begin{enumerate}
    \item
      The first item has no index.
      The index sequence $ℓₙ$ is always one shorter than the vector sequence $rₙ$.
    \item
      For the generalized Euclidean algorithm, the sequence $r_n$ consists solely of integer vectors.
      However, the MDCF can also be defined over rational or even real vectors.
      To differentiate the two, a sequence $rₙ$ will denote a sequence of real
      vectors and $aₙ$ will denote a sequence of integer vectors.
  \end{enumerate}
\end{remark}

The concepts from one-dimensional continued fractions naturally carry over to its
multi-dimensional counterpart.

\begin{definition}[Complete Quotient, Convergent, Periodicity]~
  \begin{itemize}
    \item The \emph{$k$-th complete quotient} is defined as $[rₖ; r_{k+1}, …]$.
    \item The \emph{$k$-th convergent} of $x$ is defined as the finite fraction $[r₀; ℓ₁, r₁; …; ℓ_k, r_k]$.
    \item The MDCF is \emph{eventually periodic} if there exists $k₀ ≥ 0$ and $ℓ ≥ 1$ such that $rₖ = r_{k+ℓ}$ for every $k ≥ k₀$.
      The MDCF is \emph{purely periodic} if $k₀ = 0$.
  \end{itemize}
\end{definition}

To show that any periodic MDCF contains elements of a field with degree $d + 1$
over the rationals, we proceed similarly to the one-dimensional continued
fraction.
We first show the multi-dimensional analogue of Lemma~\ref{lem:nesting}.

\begin{lemma}[Nesting]
  \label{lem:mdcf-nesting}
  Let $x ∈ ℝ^d$, then
  \[
    [a₀; ℓ₁, a₁; …; ℓₙ, aₙ; ℓ, x]
    = [a₀; ℓ₁, a₁; \cdots; ℓₙ, aₙ + \mathrm{pivot}_{ℓ}(x)]
  \]
\end{lemma}

\begin{proof}
  If $n = 0$, then by definition,
  \[
    [a₀; ℓ, x] = a₀ + \mathrm{pivot}_{ℓ}[x] = a₀ + \mathrm{pivot}_{ℓ}(x) = [a₀ + \mathrm{pivot}_ℓ(x)].
  \]
  Suppose the lemma holds for any $n ≥ 0$, then
  \begin{align*}
    [a₀; ℓ₁, a₁; …; ℓₙ, aₙ; ℓ, x]
    & = a₀ + \mathrm{pivot}_{ℓ₀}[a₁; …; ℓₙ, aₙ; ℓ, x] \\
    & = a₀ + \mathrm{pivot}_{ℓ₀}[a₁; …; ℓₙ, aₙ + \mathrm{pivot}_ℓ(x)] \\
    & = [a₀; ℓ₁, a₁; …; ℓₙ, aₙ + \mathrm{pivot}_ℓ(x)]. \qedhere
  \end{align*}
\end{proof}

In Lemma~\vref{lem:wallis}, we had to define two sequences $pₙ$ and $qₙ$ over
the sequence of the continued fraction $aₙ$.
Each sequence would only return a single scalar.
This time we define two matrix sequences $P^{(n)}, Q^{(n)}$ over the sequences $aₙ$ and $ℓₙ$ as
\begin{align*}
  P_{ℓₙ}^{(n)} & = P_{n-1} a_n + p_{n-1}, & P_i^{(n)} & = P_i^{(n)}, & P^{(-1)}   & = I_d, \\
  Q_{ℓₙ}^{(n)} & = Q_{n-1}^T a_n + q_{n-1}, & Q_i^{(n)} & = Q_i^{(n)}, & Q^{(-1)}_j & = 0,   \\
  p^{(n)}      & = P_{ℓₙ}^{(n-1)},            &           &              & p^{(-1)}_j & = 0,   \\
  p^{(n)}      & = P_{ℓₙ}^{(n-1)},            &           &              & q^{(-1)}   & = 1.
\end{align*}
where $i ≠ ℓ_n$.
What this sequence effectively does is reconstructing the lattice from an
initial solution vector $x ∈ ℝ^d$ and its coefficient vectors $a_n$.

\begin{lemma}[Wallis]
  \label{lem:mdcf-wallis}
  Let $x ∈ ℝ^d$, then
  \[
    [a₀; ℓ₁, a₁; …; ℓ_{n-1}, a_{n-1}; ℓ, x]
    = \frac{P x + p}{Q^T x + q}.
  \]
\end{lemma}

\begin{proof}
  If $n = 0$, then
  \[
    [x] = x = \frac{I_d x + 0}{0^T x + 1}.
  \]
  Suppose the lemma holds for $n ≥ 0$, then there exists a matrix $P$, vectors
  $Q, p$ and scalar $q$ such that
  \begin{align*}
    y & = [a₀; ℓ₁, a₁; …; ℓ_{n-1}, a_{n-1}; ℓ, x]                              \\
      & = [a₀; ℓ₁, a₁; …; ℓ_{n-1}, a_{n-1} + \mathrm{pivot}_ℓ(x)]              \\
      & = \frac{P (a + \mathrm{pivot}_ℓ(x)) + p}{Q^T (aₙ + \mathrm{pivot}_ℓ(x)) + q} \\
      & = \frac{x_ℓ}{x_ℓ} · \frac{P (a + \mathrm{pivot}_ℓ(x)) + p}{Q^T (aₙ + \mathrm{pivot}_ℓ(x)) + q}.
  \end{align*}
  The numerator has the following form:
  \begin{align*}
    x_ℓ (P (a + \mathrm{pivot}(x, ℓ)) + p)
    & = x_ℓ (P a + P_ℓ \frac{1}{x_ℓ} + \sum_{i ≠ ℓ} P_i \frac{x_i}{x_ℓ} + p) \\
    & = \underbrace{(P a + p)}_{P_ℓ'} x_ℓ + \sum_{i ≠ ℓ} \underbrace{P_i}_{P_i'} x_i + \underbrace{P_ℓ}_{p'} \\
    & = P' x + p'.
  \end{align*}
  Analogously, the denominator has the following form:
  \begin{align*}
    x_ℓ (Q^T (a + \mathrm{pivot}(x, ℓ)) + q)
    & = x_ℓ (Q^T a + Q_ℓ \frac{1}{x_ℓ} + \sum_{i ≠ ℓ} Q_i \frac{x_i}{x_ℓ} + q) \\
    & = \underbrace{(Q^T a + q)}_{Q_ℓ'} x_ℓ + \sum_{i ≠ ℓ} \underbrace{Q_i}_{Q_i'} x_i + \underbrace{Q_ℓ}_{q'} \\
    & = Q' x + q'.
  \end{align*}
  Hence,
  \begin{align*}
    y & = \frac{P(a + \mathrm{pivot}(x, ℓ)) + p}{Q(a + \mathrm{pivot}(x, ℓ)) + q} \\
      & = \frac{P' x + p'}{Q'^T x + q'}. \qedhere
  \end{align*}
\end{proof}

\begin{proposition}
  Given $r ∈ ℝ$, let $x = (r¹, r², …, r^d)$.
  If the MDCF representation of $x$ is purely periodic, then $[ℚ(r) : ℚ] ≤ d + 1$.
\end{proposition}

\begin{proof}
  Suppose the algorithm is purely periodic on input $x$ with period $ℓ$.
  Let $y$ be the $ℓ$-th complete quotient of $x$, then $x = y$.
  By Lemma~\ref{lem:mdcf-wallis},
  \[
    rⁱ = \frac{\sum_{j=1}^d P_{ij} rʲ + pᵢ}{\sum_{j=1}^d Qⱼ rʲ + qᵢ}, \text{ for every } i ≤ d.
  \]
  Multiplying both sides with the denominator results in the polynomial equation
  \[
    \sum_{j=1}^d (Q_j r^{i+j} - P_{ij} r^j) + r^i q_i - p_i = 0.
  \]
  For $i = 1$, the maximum degree of this polynomial is $d + 1$.
  Hence, $[ℚ(r) : ℚ] ≤ d + 1$.
\end{proof}

\section{Homogeneous Coordinates}

The pivot operation is quite cumbersome to write.
We'll always need to differentiate the cases $i = ℓ$ and $i ≠ ℓ$.
Homogeneous coordinates allow us to simplify the whole pivot operation as a single matrix.

Instead of an $d$-dimensional vector space, we project each vector into a $(d+1)$-dimensional vector space.
Each vector $x = (x₁, …, x_d) ∈ ℝ^d$ is extended by a new coordinate $x₀ = 1$.
We denote this vector as $\hat x = [1, x₁, …, x_d]$.
Two such vectors $\hat x, \hat y$ are considered equivalent if they are collinear.
Stated differently, each vector $[x₀, x₁, …, x_d]$ represents a line in the direction $(x₀, x₁, …, x_d)$.

% TODO: Explain mapping from and back to the original vector space.
\begin{center}
  \begin{tikzpicture}
    \matrix[
      column sep=2cm,
      nodes={text width=3cm, align=center},
    ] {
      \node (L0) {$\mathbb{R}^d$}; &
      \node (R0) {$\mathbb{RP}^{d+1}$}; \\
      \node (L1) {$(x₁, …, x_d)$}; &
      \node (R1) {$[1, x₁, …, x_d]$}; \\
      \node (L2) {$(x₁/x₀, …, x_d/x₀)$}; &
      \node (R2) {$[x₀, x₁, …, x_d]$}; \\
    };

    \draw[->] (L1) -- node[above] {} (R1);
    \draw[<-] (L2) -- node[above] {} (R2);
  \end{tikzpicture}
\end{center}

For example, consider the vector $[1, x₁, x₂]$ with $0 ≤ x₁, x₂ < 1$.
A pivot operation with $ℓ = 1$ would result in the vector $[1, 1/x₁, x₂/x₁]$.
This vector is equivalent to $[x₁, 1, x₂]$.
Therefore, we can reformulate this operation as a coordinate swap of $x_ℓ$ with
the new coordinate $x₀$:
\[
  \begin{bmatrix}
    0 & 1 & 0 \\
    1 & 0 & 0 \\
    0 & 0 & 1 \\
  \end{bmatrix}
  ·
  \begin{bmatrix} 1 \\ x₁ \\ x₂ \\ \end{bmatrix}
  =
  \begin{bmatrix} x₁ \\ 1 \\ x₂ \\ \end{bmatrix}.
\]
Similarly, subtracting the integer part of each value in $[1, x₁, x₂]$ is
equivalent to a series of skew operations:
\[
  \begin{bmatrix}
    1 & 0 & 0 \\
    -\floor{x₁} & 1 & 0 \\
    0 & 0 & 1 \\
  \end{bmatrix}
  ·
  \begin{bmatrix}
    1 & 0 & 0 \\
    0 & 1 & 0 \\
    -\floor{x₂} & 0 & 1 \\
  \end{bmatrix}
  ·
  \begin{bmatrix} 1 \\ x₁ \\ x₂ \\ \end{bmatrix}
  =
  \begin{bmatrix} 1 \\ x₁ - \floor{x₁} \\ x₂ - \floor{x₂} \\ \end{bmatrix}.
\]
Importantly, each of those matrices with
determinant $1$.
Therefore, the whole operation can be reversed by inverting the matrix.
This is the equivalent of the inverse pivot operation in homogeneous
coordinates.

We can also reformulate the MDCF as a series of matrix multiplications.
In the following $T(a)$ denotes the translation by a vector $a ∈ ℝ^d$
and the matrix $S(ℓ)$ denotes the swap of $x_\ell$ with $x_0$.
The MDCF can then be written as
\[
  [a₀] = \hat a₀, \qquad
  [a₀; ℓ₁, a₁; …; ℓₙ, aₙ] = T(a₀) · S(ℓ_1) · [a₁; ℓ_2, a_2; …; ℓ_n, a_n].
\]

This allows us to drastically simplify Lemma~\ref{lem:mdcf-wallis}.
Now, we only have a single matrix sequence $P_n$, defined as follows:
\begin{align*}
  P_n = P_{n-1} A_n, \qquad P_0 = I_{d+1}.
\end{align*}

\begin{lemma}
  \label{lem:mdcf-wallis'}
  Let $x ∈ ℝ^d$, then
  \[
    [a₀; ℓ₁, a₁; …; ℓ_{n-1}, a_{n-1}; ℓ, x] = P_{n-1} \hat x
  \]
\end{lemma}

\begin{proof}
  For $n = 0$, this is clearly true.
  Suppose the lemma is true for $n ≥ 0$, then
  \begin{align*}
    [a₀; ℓ₁, a₁; …; ℓ_n, a_n; ℓ, x]
    & = [a₀; ℓ₁, a₁; …; ℓ_n, a_n + \mathrm{pivot}_ℓ(x)] \\
    & = P_{n-1}
    \begin{pmatrix}
      a_n + \mathrm{pivot}_ℓ(x) \\ 1
    \end{pmatrix} \\
    & = P_{n-1} A_n \hat{x} \\
    & = P_n \hat{x} \qedhere
  \end{align*}
\end{proof}

\begin{theorem}
  Let $A ∈ ℤ^{d×d}, B ∈ ℤ^d$ and $C ∈ ℤ$.
  If $x^\top A x + B x + C = 0$ for some vector $x ∈ ℝ^d$,
  then the MDCF of $x$ is eventually periodic.
\end{theorem}

\begin{proof}

\end{proof}

\begin{corollary}
  If $r$ is the root of a polynomial of degree $2d$,
  then the MDCF of $x = (r^1, …, r^d)$ is eventually periodic.
\end{corollary}
